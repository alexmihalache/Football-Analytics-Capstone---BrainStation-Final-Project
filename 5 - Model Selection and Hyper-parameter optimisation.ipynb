{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plotting liibs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "#Football libs\n",
    "import socceraction\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from mplsoccer import Pitch, Sbopen, VerticalPitch\n",
    "import socceraction.spadl as spadl\n",
    "import matplotsoccer as mps\n",
    "import socceraction.xthreat as xthreat\n",
    "import socceraction.spadl as spadl\n",
    "from socceraction.vaep import VAEP\n",
    "\n",
    "# utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "# fuzz is used to compare TWO strings\n",
    "from fuzzywuzzy import fuzz\n",
    "# process is used to compare a string to MULTIPLE other strings\n",
    "from fuzzywuzzy import process\n",
    "import load_data\n",
    "import pre_processing_utils as ppu\n",
    "from itertools import cycle\n",
    "\n",
    "# ML libs\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, label_binarize, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Model scoring \n",
    "from sklearn.metrics import classification_report, roc_auc_score, plot_roc_curve, confusion_matrix, confusion_matrix, plot_confusion_matrix, mean_squared_error, r2_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pre_processing_utils' from '/Users/alexmihalache/Library/CloudStorage/OneDrive-Personal/BrainStation/Capstone/Capstone Project - FAWSL Analysis/pre_processing_utils.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(ppu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "xt, xt_test, vaep, vaep_test, games, games_test, players, players_test, target_players = load_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_train_df = vaep.copy()\n",
    "modeling_test_df = vaep_test.copy()\n",
    "modeling_xt_train_df = xt.copy()\n",
    "modeling_xt_test_df = xt_test.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-vaep')\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>minutes_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24239</td>\n",
       "      <td>Jemma Elizabeth Purfield</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15579</td>\n",
       "      <td>Inessa Kaagman</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5076</td>\n",
       "      <td>Emily Louise van Egmond</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5074</td>\n",
       "      <td>Shelina Laura Zadorsky</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31534</td>\n",
       "      <td>Ella Toone</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_id               player_name  minutes_played\n",
       "0      24239  Jemma Elizabeth Purfield            2016\n",
       "1      15579            Inessa Kaagman            2015\n",
       "2       5076   Emily Louise van Egmond            1940\n",
       "3       5074    Shelina Laura Zadorsky            1930\n",
       "4      31534                Ella Toone            1887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>jersey_number</th>\n",
       "      <th>is_starter</th>\n",
       "      <th>starting_position_id</th>\n",
       "      <th>starting_position_name</th>\n",
       "      <th>minutes_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>19810</td>\n",
       "      <td>966</td>\n",
       "      <td>24239</td>\n",
       "      <td>Jemma Elizabeth Purfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>Left Back</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     game_id  team_id  player_id               player_name nickname  \\\n",
       "360    19810      966      24239  Jemma Elizabeth Purfield      NaN   \n",
       "\n",
       "     jersey_number  is_starter  starting_position_id starting_position_name  \\\n",
       "360             23        True                     6              Left Back   \n",
       "\n",
       "     minutes_played  \n",
       "360              96  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players[players['player_id']==24239].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>jersey_number</th>\n",
       "      <th>is_starter</th>\n",
       "      <th>starting_position_id</th>\n",
       "      <th>starting_position_name</th>\n",
       "      <th>minutes_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3775636</td>\n",
       "      <td>973</td>\n",
       "      <td>24239</td>\n",
       "      <td>Jemma Elizabeth Purfield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>Left Back</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     game_id  team_id  player_id               player_name nickname  \\\n",
       "371  3775636      973      24239  Jemma Elizabeth Purfield      NaN   \n",
       "\n",
       "     jersey_number  is_starter  starting_position_id starting_position_name  \\\n",
       "371             23        True                     6              Left Back   \n",
       "\n",
       "     minutes_played  \n",
       "371             103  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_test[players_test['player_id']==24239].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAEP Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling \n",
    "\n",
    "**Approach to modeling:**\n",
    "\n",
    "1. Pick a player to replace in a team\n",
    "2. Get the top players in their cluster as potential replacements \n",
    "3. Fit a model for each of the scouted players \n",
    "    - use only that player's data to fit the model\n",
    "    - the models will predict their next location and the action they take \n",
    "    - the parameters in the model should cover the player characteristics and team characteristics. For example, the 5 past moves cover what the team does, and how then the player reacts to those. The player action is the predicted target \n",
    "\n",
    "**Model validation and testing approach:**\n",
    "\n",
    "- Of the scouted players, find those that have undergone a transfer in season 3 in our data set - use season 3 data to test our predictions. \n",
    "- Score the model based on the real data from their new team\n",
    "\n",
    "\n",
    "**Models to train and test:**\n",
    "\n",
    "- Baseline model for logistic regression for next action and end pitch location\n",
    "- Random Forest classifier for end pitch location and next action \n",
    "- xGBoost classifier for end pitch location and next action \n",
    "- Random Forest regressor for end_x and end_y location \n",
    "- xGBoost regressor for enx_x and end_y location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a class that:**\n",
    "\n",
    "1. Takes in a player id \n",
    "2. Slices the dataset for this player\n",
    "3. Clusters most similar players \n",
    "4. Take the top 3 players \n",
    "5. Slices the datasets for each player\n",
    "6. Fits a model for each \n",
    "7. Run a prediction based on the original player dataset\n",
    "8. Scores the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add in:\n",
    "\n",
    "kNN\n",
    "SVM\n",
    "DT\n",
    "Random Forest\n",
    "xGBoost\n",
    "\n",
    "with a cv 5\n",
    "\n",
    "Run it for End-zone \n",
    "Run it for Next Action\n",
    "Run it for VAEP Regression \n",
    "Run it for xT regression (build the dataset)\n",
    "\n",
    "add in kbest\n",
    "add in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "cachedir = mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach:**\n",
    "\n",
    "- Try a few manual models - with different feature combinations, mainly focusing on regularisation, learning rate and depth of trees\n",
    "- Try to identify ranges for the hyperparams \n",
    "- Run a gridsearch in the ranges identified for the features identified\n",
    "- Review results and if needed re-run manual checks\n",
    "- Re-do gridsearch with new params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Team - VAEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'vaep_value')\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-vaep')\n",
    "\n",
    "# define column transformed for pipeline\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer for GridSearchCV\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Regressor - Depth 5 ***\n",
      "Random Forest Train Score:  0.8160415586816594\n",
      "Random Forest Test Score:  0.7333054326388806\n",
      " \n",
      "*** Random Forest Regressor - Depth 10 ***\n",
      "Random Forest Train Score:  0.9252032890968886\n",
      "Random Forest Test Score:  0.7696565710141716\n",
      " \n",
      "*** Random Forest Regressor - Depth 15 ***\n",
      "Random Forest Train Score:  0.9572404369298733\n",
      "Random Forest Test Score:  0.770458041532036\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 ***\n",
      "XGB Regressor Train Score:  0.9773771604640682\n",
      "XGB Regressor Test Score:  0.7774353046416602\n",
      " \n",
      "*** xGBoost Regressor - Depth 10 ***\n",
      "XGB Regressor Train Score:  0.9996424598218189\n",
      "XGB Regressor Test Score:  0.7722946268899323\n",
      " \n",
      "*** xGBoost Regressor - Depth 15 ***\n",
      "XGB Regressor Train Score:  0.9997710007647611\n",
      "XGB Regressor Test Score:  0.7744886387854324\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Random Forest Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 10 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 15 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=15))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 10 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 15 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=15))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Regressor - Depth 17 ***\n",
      "Random Forest Train Score:  0.9614962650539055\n",
      "Random Forest Test Score:  0.7760280656011058\n",
      " \n",
      "*** Random Forest Regressor - Depth 20 ***\n",
      "Random Forest Train Score:  0.9645378642352276\n",
      "Random Forest Test Score:  0.7728209532690797\n",
      " \n",
      "*** Random Forest Regressor - Depth 25 ***\n",
      "Random Forest Train Score:  0.9710229219176514\n",
      "Random Forest Test Score:  0.7733866093735826\n",
      " \n",
      "*** xGBoost Regressor - Depth 2 ***\n",
      "XGB Regressor Train Score:  0.8462431898067477\n",
      "XGB Regressor Test Score:  0.7393302816944547\n",
      " \n",
      "*** xGBoost Regressor - Depth 3 ***\n",
      "XGB Regressor Train Score:  0.9242034953688028\n",
      "XGB Regressor Test Score:  0.769936203996455\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Random Forest Regressor - Depth 17 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=17))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 20 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=20))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 25 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=25))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 2 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=2))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 3 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=3))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 91 candidates, totalling 455 fits\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   3.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   6.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   6.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   7.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   7.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   9.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=  11.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=  11.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   9.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  12.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  15.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  14.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  16.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  19.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  13.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  20.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  23.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  25.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  25.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  24.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  24.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  16.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  16.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  17.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  17.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  17.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  20.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  24.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  28.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  30.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  30.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  29.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  29.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  18.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  23.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  27.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  29.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  29.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  29.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  28.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  20.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  21.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  22.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  22.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  22.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  26.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  31.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  32.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  33.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  32.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  32.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  36.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  37.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  38.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  37.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  38.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   6.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.7s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid = [\n",
    "     {\n",
    "        'model': [RandomForestRegressor(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(2, 17, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBRegressor(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid = GridSearchCV(estimator, param_grid, cv = 5, verbose = 2)\n",
    "fitted_grid = grid.fit(X_train, y_train)\n",
    "\n",
    "# fitted_grid.best_estimator_\n",
    "# fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4.399968</td>\n",
       "      <td>0.042012</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.435324</td>\n",
       "      <td>-0.058706</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>0.375228</td>\n",
       "      <td>0.399281</td>\n",
       "      <td>0.277238</td>\n",
       "      <td>0.181177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4.374043</td>\n",
       "      <td>0.068614</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.430918</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>0.267397</td>\n",
       "      <td>0.375161</td>\n",
       "      <td>0.258771</td>\n",
       "      <td>0.149852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3.211093</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.030821</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>0.212421</td>\n",
       "      <td>0.138343</td>\n",
       "      <td>0.122829</td>\n",
       "      <td>0.291122</td>\n",
       "      <td>0.237063</td>\n",
       "      <td>0.109554</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5.688128</td>\n",
       "      <td>0.137392</td>\n",
       "      <td>0.033125</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.430948</td>\n",
       "      <td>-0.143982</td>\n",
       "      <td>0.245534</td>\n",
       "      <td>0.256299</td>\n",
       "      <td>0.393311</td>\n",
       "      <td>0.236422</td>\n",
       "      <td>0.203784</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.655732</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.032792</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.404752</td>\n",
       "      <td>-0.167093</td>\n",
       "      <td>0.231453</td>\n",
       "      <td>0.184793</td>\n",
       "      <td>0.389565</td>\n",
       "      <td>0.208694</td>\n",
       "      <td>0.206619</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4.329026</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.031671</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.881851</td>\n",
       "      <td>-47.209353</td>\n",
       "      <td>-27.040913</td>\n",
       "      <td>-16.651056</td>\n",
       "      <td>-20.219825</td>\n",
       "      <td>-27.400600</td>\n",
       "      <td>10.601310</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.279602</td>\n",
       "      <td>0.104560</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.889016</td>\n",
       "      <td>-47.184387</td>\n",
       "      <td>-27.089479</td>\n",
       "      <td>-16.645945</td>\n",
       "      <td>-20.237177</td>\n",
       "      <td>-27.409201</td>\n",
       "      <td>10.590153</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3.260674</td>\n",
       "      <td>0.093230</td>\n",
       "      <td>0.031827</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.889016</td>\n",
       "      <td>-47.184387</td>\n",
       "      <td>-27.108559</td>\n",
       "      <td>-16.628963</td>\n",
       "      <td>-20.237177</td>\n",
       "      <td>-27.409620</td>\n",
       "      <td>10.593496</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4.338018</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>0.032612</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.875187</td>\n",
       "      <td>-47.395441</td>\n",
       "      <td>-26.959851</td>\n",
       "      <td>-16.655387</td>\n",
       "      <td>-20.211795</td>\n",
       "      <td>-27.419532</td>\n",
       "      <td>10.671940</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.541271</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.890679</td>\n",
       "      <td>-47.723160</td>\n",
       "      <td>-26.919237</td>\n",
       "      <td>-16.636442</td>\n",
       "      <td>-20.194735</td>\n",
       "      <td>-27.472851</td>\n",
       "      <td>10.800773</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "83       4.399968      0.042012         0.032239        0.000499   \n",
       "74       4.374043      0.068614         0.033129        0.001972   \n",
       "73       3.211093      0.032683         0.030821        0.002246   \n",
       "75       5.688128      0.137392         0.033125        0.001207   \n",
       "84       5.655732      0.085976         0.032792        0.002939   \n",
       "..            ...           ...              ...             ...   \n",
       "71       4.329026      0.062792         0.031671        0.001793   \n",
       "67       3.279602      0.104560         0.031089        0.000804   \n",
       "70       3.260674      0.093230         0.031827        0.001571   \n",
       "65       4.338018      0.036118         0.032612        0.000850   \n",
       "66       5.541271      0.065275         0.032733        0.001396   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "83  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "74  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "73  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "75  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "84  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "..                                                ...                    ...   \n",
       "71  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "67  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "70  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "65  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "66  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "\n",
       "   param_model__max_features param_model__n_estimators param_model__eta  \\\n",
       "83                       NaN                       NaN              0.3   \n",
       "74                       NaN                       NaN              0.1   \n",
       "73                       NaN                       NaN              0.1   \n",
       "75                       NaN                       NaN              0.1   \n",
       "84                       NaN                       NaN              0.3   \n",
       "..                       ...                       ...              ...   \n",
       "71                       NaN                       NaN             0.01   \n",
       "67                       NaN                       NaN             0.01   \n",
       "70                       NaN                       NaN             0.01   \n",
       "65                       NaN                       NaN             0.01   \n",
       "66                       NaN                       NaN             0.01   \n",
       "\n",
       "   param_model__gamma                                             params  \\\n",
       "83                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "74                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "73                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "75                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "84                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "..                ...                                                ...   \n",
       "71                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "67                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "70                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "65                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "66                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "83           0.435324          -0.058706           0.235063   \n",
       "74           0.430918          -0.001321           0.221700   \n",
       "73           0.420600           0.212421           0.138343   \n",
       "75           0.430948          -0.143982           0.245534   \n",
       "84           0.404752          -0.167093           0.231453   \n",
       "..                ...                ...                ...   \n",
       "71         -25.881851         -47.209353         -27.040913   \n",
       "67         -25.889016         -47.184387         -27.089479   \n",
       "70         -25.889016         -47.184387         -27.108559   \n",
       "65         -25.875187         -47.395441         -26.959851   \n",
       "66         -25.890679         -47.723160         -26.919237   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "83           0.375228           0.399281         0.277238        0.181177   \n",
       "74           0.267397           0.375161         0.258771        0.149852   \n",
       "73           0.122829           0.291122         0.237063        0.109554   \n",
       "75           0.256299           0.393311         0.236422        0.203784   \n",
       "84           0.184793           0.389565         0.208694        0.206619   \n",
       "..                ...                ...              ...             ...   \n",
       "71         -16.651056         -20.219825       -27.400600       10.601310   \n",
       "67         -16.645945         -20.237177       -27.409201       10.590153   \n",
       "70         -16.628963         -20.237177       -27.409620       10.593496   \n",
       "65         -16.655387         -20.211795       -27.419532       10.671940   \n",
       "66         -16.636442         -20.194735       -27.472851       10.800773   \n",
       "\n",
       "    rank_test_score  \n",
       "83                1  \n",
       "74                2  \n",
       "73                3  \n",
       "75                4  \n",
       "84                5  \n",
       "..              ...  \n",
       "71               87  \n",
       "67               88  \n",
       "70               89  \n",
       "65               90  \n",
       "66               91  \n",
       "\n",
       "[91 rows x 19 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.DataFrame(fitted_grid.cv_results_)\n",
    "grid_search_results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='/var/folders/t5/kc4tlr5n2yn5jkkh1t9rk9500000gn/T/tmpieqziszu',\n",
      "         steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['start_x', 'start_y',\n",
      "                                                   'end_x', 'end_y', 'x_dif',\n",
      "                                                   'y_dif', 'time_seconds',\n",
      "                                                   'n-1_x_distance',\n",
      "                                                   'n-1_y_distance',\n",
      "                                                   'n-1_start_x', 'n-1_start_y',\n",
      "                                                   'n-1_end_x', 'n-1_end_y',\n",
      "                                                   'n-2_x_di...\n",
      "                              importance_type=None, interaction_constraints='',\n",
      "                              learning_rate=0.300000012, max_delta_step=0,\n",
      "                              max_depth=3, min_child_weight=1, missing=nan,\n",
      "                              monotone_constraints='()', n_estimators=100,\n",
      "                              n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                              random_state=1, reg_alpha=0, reg_lambda=1,\n",
      "                              scale_pos_weight=1, subsample=1,\n",
      "                              tree_method='exact', validate_parameters=1,\n",
      "                              verbosity=None))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22566229633244372"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fitted_grid.best_estimator_)\n",
    "fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Max_features sqrt has a big impact on accuracy - therefore, none or auto are the best options \n",
    "- for xgb reg_alpha helps with regularisation - small increments above 1 have a big impact in reducing train scores, without reducing test scores by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Regressor - Depth 17 ***\n",
      "Random Forest Train Score:  0.9605924868379286\n",
      "Random Forest Test Score:  0.7727033214856343\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 ***\n",
      "XGB Regressor Train Score:  0.9773771604640682\n",
      "XGB Regressor Test Score:  0.7774353046416602\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Random Forest Regressor - Depth 17 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=150, oob_score=True, n_jobs=-1, random_state=1))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower gamma, and introduce alpha for regularisation - What does lower gamma mean, and what would regularisation do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search - Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  24.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  22.7s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  23.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  23.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  23.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  21.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  22.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  22.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  22.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  23.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  26.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  29.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  32.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  31.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  31.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  28.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.2s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  31.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  33.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  33.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  29.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  28.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  26.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.2s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  29.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  30.7s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  30.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  30.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  31.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  29.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.2s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  30.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  32.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  31.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  31.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  30.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  31.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  31.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  32.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  32.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  34.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  36.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  37.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  36.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  36.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  37.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  36.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  37.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  36.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  36.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   6.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   6.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   8.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   8.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   9.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   9.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=  11.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  12.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  11.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  10.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  11.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=   9.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  10.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  11.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  11.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  25.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  11.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  11.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  10.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  10.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  12.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  13.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  14.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  12.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  14.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  13.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  13.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  15.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  13.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  12.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  13.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  14.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  13.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  13.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   7.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   9.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   8.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   9.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   9.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=  10.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=   9.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=   9.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=  10.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=   9.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=   9.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=  10.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=  10.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=   9.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=  10.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  11.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  12.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  11.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  12.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  13.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  10.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  13.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  13.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  15.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  16.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  16.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  16.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  17.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  17.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  16.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  17.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  16.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  16.5s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid = [\n",
    "     {\n",
    "        'model': [RandomForestRegressor(random_state=1, oob_score=True, n_estimators=120, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(10, 17, 1)),\n",
    "        'model__max_features': [None, 'auto']},\n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBRegressor(random_state=1, gamma=0.01)],\n",
    "        'model__max_depth': list(range(4, 8, 1)),\n",
    "        'model__eta': [0.1, 0.3],\n",
    "        'model__reg_alpha': [1, 1.1, 1.2]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid = GridSearchCV(estimator, param_grid, cv = 5, verbose = 2)\n",
    "fitted_grid = grid.fit(X_train, y_train)\n",
    "\n",
    "# fitted_grid.best_estimator_\n",
    "# fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='/var/folders/t5/kc4tlr5n2yn5jkkh1t9rk9500000gn/T/tmpieqziszu',\n",
      "         steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('standardscaler',\n",
      "                                                  StandardScaler(),\n",
      "                                                  ['start_x', 'start_y',\n",
      "                                                   'end_x', 'end_y', 'x_dif',\n",
      "                                                   'y_dif', 'time_seconds',\n",
      "                                                   'n-1_x_distance',\n",
      "                                                   'n-1_y_distance',\n",
      "                                                   'n-1_start_x', 'n-1_start_y',\n",
      "                                                   'n-1_end_x', 'n-1_end_y',\n",
      "                                                   'n-2_x_distance',\n",
      "                                                   'n-2_y_dis...\n",
      "                              importance_type=None, interaction_constraints='',\n",
      "                              learning_rate=0.100000001, max_delta_step=0,\n",
      "                              max_depth=4, min_child_weight=1, missing=nan,\n",
      "                              monotone_constraints='()', n_estimators=100,\n",
      "                              n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                              random_state=1, reg_alpha=1.1, reg_lambda=1,\n",
      "                              scale_pos_weight=1, subsample=1,\n",
      "                              tree_method='exact', validate_parameters=1,\n",
      "                              verbosity=None))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31658251673709203"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fitted_grid.best_estimator_)\n",
    "fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__reg_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.970470</td>\n",
       "      <td>0.146105</td>\n",
       "      <td>0.042224</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.489041</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>0.249863</td>\n",
       "      <td>0.339120</td>\n",
       "      <td>0.394873</td>\n",
       "      <td>0.316988</td>\n",
       "      <td>0.128581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.990853</td>\n",
       "      <td>0.103030</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.488619</td>\n",
       "      <td>0.053167</td>\n",
       "      <td>0.242089</td>\n",
       "      <td>0.338860</td>\n",
       "      <td>0.404852</td>\n",
       "      <td>0.305518</td>\n",
       "      <td>0.149806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.665684</td>\n",
       "      <td>0.233123</td>\n",
       "      <td>0.039346</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.496290</td>\n",
       "      <td>0.019671</td>\n",
       "      <td>0.259478</td>\n",
       "      <td>0.380897</td>\n",
       "      <td>0.361093</td>\n",
       "      <td>0.303486</td>\n",
       "      <td>0.160606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.143548</td>\n",
       "      <td>0.299014</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.454715</td>\n",
       "      <td>0.078265</td>\n",
       "      <td>0.201029</td>\n",
       "      <td>0.354615</td>\n",
       "      <td>0.422365</td>\n",
       "      <td>0.302198</td>\n",
       "      <td>0.142007</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.461165</td>\n",
       "      <td>0.257819</td>\n",
       "      <td>0.055376</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.451530</td>\n",
       "      <td>0.050477</td>\n",
       "      <td>0.220305</td>\n",
       "      <td>0.379015</td>\n",
       "      <td>0.398107</td>\n",
       "      <td>0.299887</td>\n",
       "      <td>0.146590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.697891</td>\n",
       "      <td>0.684169</td>\n",
       "      <td>0.051127</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.473782</td>\n",
       "      <td>-0.053094</td>\n",
       "      <td>0.257793</td>\n",
       "      <td>0.432291</td>\n",
       "      <td>0.386083</td>\n",
       "      <td>0.299371</td>\n",
       "      <td>0.190560</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14.547758</td>\n",
       "      <td>0.213805</td>\n",
       "      <td>0.059216</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.455640</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.227711</td>\n",
       "      <td>0.353132</td>\n",
       "      <td>0.411260</td>\n",
       "      <td>0.292239</td>\n",
       "      <td>0.159035</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.172207</td>\n",
       "      <td>0.245823</td>\n",
       "      <td>0.044415</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.485158</td>\n",
       "      <td>-0.014924</td>\n",
       "      <td>0.231482</td>\n",
       "      <td>0.334761</td>\n",
       "      <td>0.409253</td>\n",
       "      <td>0.289146</td>\n",
       "      <td>0.173615</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.948411</td>\n",
       "      <td>0.566847</td>\n",
       "      <td>0.056049</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.459045</td>\n",
       "      <td>-0.025285</td>\n",
       "      <td>0.236809</td>\n",
       "      <td>0.388240</td>\n",
       "      <td>0.378042</td>\n",
       "      <td>0.287370</td>\n",
       "      <td>0.172150</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.755482</td>\n",
       "      <td>0.280951</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.461504</td>\n",
       "      <td>-0.077909</td>\n",
       "      <td>0.259754</td>\n",
       "      <td>0.372114</td>\n",
       "      <td>0.371115</td>\n",
       "      <td>0.277316</td>\n",
       "      <td>0.188787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.473103</td>\n",
       "      <td>0.916867</td>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.494848</td>\n",
       "      <td>-0.030843</td>\n",
       "      <td>0.219688</td>\n",
       "      <td>0.323455</td>\n",
       "      <td>0.374493</td>\n",
       "      <td>0.276328</td>\n",
       "      <td>0.177297</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14.228845</td>\n",
       "      <td>0.422806</td>\n",
       "      <td>0.054930</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.472827</td>\n",
       "      <td>0.035152</td>\n",
       "      <td>0.168870</td>\n",
       "      <td>0.333253</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.271148</td>\n",
       "      <td>0.152469</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16.462852</td>\n",
       "      <td>0.493183</td>\n",
       "      <td>0.060337</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.457436</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>0.155508</td>\n",
       "      <td>0.290716</td>\n",
       "      <td>0.379315</td>\n",
       "      <td>0.268982</td>\n",
       "      <td>0.144156</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.578927</td>\n",
       "      <td>0.142364</td>\n",
       "      <td>0.041213</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.498142</td>\n",
       "      <td>-0.067118</td>\n",
       "      <td>0.214198</td>\n",
       "      <td>0.344013</td>\n",
       "      <td>0.351429</td>\n",
       "      <td>0.268133</td>\n",
       "      <td>0.190212</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.311747</td>\n",
       "      <td>0.926352</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.494764</td>\n",
       "      <td>-0.041594</td>\n",
       "      <td>0.214933</td>\n",
       "      <td>0.318742</td>\n",
       "      <td>0.349703</td>\n",
       "      <td>0.267310</td>\n",
       "      <td>0.178513</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16.760272</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.061917</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.441854</td>\n",
       "      <td>-0.066077</td>\n",
       "      <td>0.229616</td>\n",
       "      <td>0.380083</td>\n",
       "      <td>0.347994</td>\n",
       "      <td>0.266694</td>\n",
       "      <td>0.180144</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.386537</td>\n",
       "      <td>0.788227</td>\n",
       "      <td>0.056386</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.479611</td>\n",
       "      <td>-0.042436</td>\n",
       "      <td>0.235961</td>\n",
       "      <td>0.281458</td>\n",
       "      <td>0.365138</td>\n",
       "      <td>0.263946</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.931450</td>\n",
       "      <td>0.323952</td>\n",
       "      <td>0.047563</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.483524</td>\n",
       "      <td>-0.051109</td>\n",
       "      <td>0.222735</td>\n",
       "      <td>0.282292</td>\n",
       "      <td>0.370284</td>\n",
       "      <td>0.261545</td>\n",
       "      <td>0.179325</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.887010</td>\n",
       "      <td>5.664058</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.488489</td>\n",
       "      <td>-0.081432</td>\n",
       "      <td>0.210590</td>\n",
       "      <td>0.317260</td>\n",
       "      <td>0.364586</td>\n",
       "      <td>0.259899</td>\n",
       "      <td>0.192583</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14.322789</td>\n",
       "      <td>0.319564</td>\n",
       "      <td>0.057813</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.450281</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>0.177970</td>\n",
       "      <td>0.292480</td>\n",
       "      <td>0.330662</td>\n",
       "      <td>0.256672</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14.105374</td>\n",
       "      <td>0.916028</td>\n",
       "      <td>0.058856</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.489366</td>\n",
       "      <td>-0.121584</td>\n",
       "      <td>0.224825</td>\n",
       "      <td>0.320796</td>\n",
       "      <td>0.366251</td>\n",
       "      <td>0.255931</td>\n",
       "      <td>0.207053</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16.372869</td>\n",
       "      <td>0.214013</td>\n",
       "      <td>0.061697</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.454933</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.159301</td>\n",
       "      <td>0.255663</td>\n",
       "      <td>0.369403</td>\n",
       "      <td>0.248279</td>\n",
       "      <td>0.158718</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.511820</td>\n",
       "      <td>0.389142</td>\n",
       "      <td>0.053139</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.483234</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.221793</td>\n",
       "      <td>0.246593</td>\n",
       "      <td>0.370094</td>\n",
       "      <td>0.240128</td>\n",
       "      <td>0.203389</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.301066</td>\n",
       "      <td>0.921592</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.467521</td>\n",
       "      <td>-0.106890</td>\n",
       "      <td>0.227051</td>\n",
       "      <td>0.266799</td>\n",
       "      <td>0.345308</td>\n",
       "      <td>0.239958</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33.953997</td>\n",
       "      <td>0.725346</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.442721</td>\n",
       "      <td>0.073010</td>\n",
       "      <td>0.150109</td>\n",
       "      <td>0.047272</td>\n",
       "      <td>0.335539</td>\n",
       "      <td>0.209730</td>\n",
       "      <td>0.154112</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33.980948</td>\n",
       "      <td>0.857570</td>\n",
       "      <td>0.036574</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.442721</td>\n",
       "      <td>0.073010</td>\n",
       "      <td>0.150109</td>\n",
       "      <td>0.047272</td>\n",
       "      <td>0.335539</td>\n",
       "      <td>0.209730</td>\n",
       "      <td>0.154112</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.583106</td>\n",
       "      <td>0.550561</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.434824</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>0.134774</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>0.326637</td>\n",
       "      <td>0.200261</td>\n",
       "      <td>0.154235</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.658470</td>\n",
       "      <td>0.656271</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>14</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.434824</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>0.134774</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>0.326637</td>\n",
       "      <td>0.200261</td>\n",
       "      <td>0.154235</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.113632</td>\n",
       "      <td>0.868880</td>\n",
       "      <td>0.036556</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.446799</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.122834</td>\n",
       "      <td>0.065182</td>\n",
       "      <td>0.313062</td>\n",
       "      <td>0.200250</td>\n",
       "      <td>0.154481</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.941752</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>16</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.446799</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.122834</td>\n",
       "      <td>0.065182</td>\n",
       "      <td>0.313062</td>\n",
       "      <td>0.200250</td>\n",
       "      <td>0.154481</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.512605</td>\n",
       "      <td>0.622566</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444562</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.133035</td>\n",
       "      <td>0.060128</td>\n",
       "      <td>0.320523</td>\n",
       "      <td>0.199847</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.072868</td>\n",
       "      <td>0.439424</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>13</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444562</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.133035</td>\n",
       "      <td>0.060128</td>\n",
       "      <td>0.320523</td>\n",
       "      <td>0.199847</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.208310</td>\n",
       "      <td>0.710552</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>11</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444629</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>0.044967</td>\n",
       "      <td>0.314886</td>\n",
       "      <td>0.196638</td>\n",
       "      <td>0.158036</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.987358</td>\n",
       "      <td>2.188787</td>\n",
       "      <td>0.038094</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444629</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>0.044967</td>\n",
       "      <td>0.314886</td>\n",
       "      <td>0.196638</td>\n",
       "      <td>0.158036</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.817038</td>\n",
       "      <td>0.668538</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441234</td>\n",
       "      <td>0.044871</td>\n",
       "      <td>0.113632</td>\n",
       "      <td>0.058471</td>\n",
       "      <td>0.315847</td>\n",
       "      <td>0.194811</td>\n",
       "      <td>0.156866</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.419379</td>\n",
       "      <td>2.237077</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441234</td>\n",
       "      <td>0.044871</td>\n",
       "      <td>0.113632</td>\n",
       "      <td>0.058471</td>\n",
       "      <td>0.315847</td>\n",
       "      <td>0.194811</td>\n",
       "      <td>0.156866</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.395389</td>\n",
       "      <td>0.720538</td>\n",
       "      <td>0.039316</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441763</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.308431</td>\n",
       "      <td>0.191760</td>\n",
       "      <td>0.158913</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.655425</td>\n",
       "      <td>0.723017</td>\n",
       "      <td>0.036653</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441763</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.308431</td>\n",
       "      <td>0.191760</td>\n",
       "      <td>0.158913</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15       6.970470      0.146105         0.042224        0.002061   \n",
       "16       6.990853      0.103030         0.041237        0.001504   \n",
       "14       6.665684      0.233123         0.039346        0.003204   \n",
       "31      11.143548      0.299014         0.051227        0.002575   \n",
       "30      11.461165      0.257819         0.055376        0.002785   \n",
       "26       8.697891      0.684169         0.051127        0.005480   \n",
       "34      14.547758      0.213805         0.059216        0.001967   \n",
       "19      10.172207      0.245823         0.044415        0.004373   \n",
       "28       9.948411      0.566847         0.056049        0.004292   \n",
       "27       9.755482      0.280951         0.054687        0.005319   \n",
       "17       9.473103      0.916867         0.046530        0.004487   \n",
       "32      14.228845      0.422806         0.054930        0.003807   \n",
       "35      16.462852      0.493183         0.060337        0.002324   \n",
       "20      10.578927      0.142364         0.041213        0.002588   \n",
       "23      13.311747      0.926352         0.049187        0.006349   \n",
       "37      16.760272      0.367647         0.061917        0.002259   \n",
       "18      11.386537      0.788227         0.056386        0.007012   \n",
       "22      10.931450      0.323952         0.047563        0.005462   \n",
       "21      13.887010      5.664058         0.051313        0.011814   \n",
       "33      14.322789      0.319564         0.057813        0.003183   \n",
       "24      14.105374      0.916028         0.058856        0.009900   \n",
       "36      16.372869      0.214013         0.061697        0.002934   \n",
       "25      13.511820      0.389142         0.053139        0.006965   \n",
       "29      12.301066      0.921592         0.058332        0.003976   \n",
       "11      33.953997      0.725346         0.036767        0.001670   \n",
       "10      33.980948      0.857570         0.036574        0.000763   \n",
       "8       31.583106      0.550561         0.036543        0.000892   \n",
       "9       31.658470      0.656271         0.036400        0.000922   \n",
       "12      36.113632      0.868880         0.036556        0.001107   \n",
       "13      36.941752      0.297908         0.038325        0.002188   \n",
       "6       30.512605      0.622566         0.036400        0.001333   \n",
       "7       30.072868      0.439424         0.037346        0.001080   \n",
       "3       30.208310      0.710552         0.036697        0.000827   \n",
       "2       29.987358      2.188787         0.038094        0.001315   \n",
       "5       27.817038      0.668538         0.038829        0.006366   \n",
       "4       31.419379      2.237077         0.037332        0.001180   \n",
       "0       23.395389      0.720538         0.039316        0.004975   \n",
       "1       22.655425      0.723017         0.036653        0.000759   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "15  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "16  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "14  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "31  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "30  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "26  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "34  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "19  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "28  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "27  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "17  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "32  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "35  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "20  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "23  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "37  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "18  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "22  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "21  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "33  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "24  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "36  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "25  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "29  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "11  RandomForestRegressor(n_estimators=120, n_jobs...                     15   \n",
       "10  RandomForestRegressor(n_estimators=120, n_jobs...                     15   \n",
       "8   RandomForestRegressor(n_estimators=120, n_jobs...                     14   \n",
       "9   RandomForestRegressor(n_estimators=120, n_jobs...                     14   \n",
       "12  RandomForestRegressor(n_estimators=120, n_jobs...                     16   \n",
       "13  RandomForestRegressor(n_estimators=120, n_jobs...                     16   \n",
       "6   RandomForestRegressor(n_estimators=120, n_jobs...                     13   \n",
       "7   RandomForestRegressor(n_estimators=120, n_jobs...                     13   \n",
       "3   RandomForestRegressor(n_estimators=120, n_jobs...                     11   \n",
       "2   RandomForestRegressor(n_estimators=120, n_jobs...                     11   \n",
       "5   RandomForestRegressor(n_estimators=120, n_jobs...                     12   \n",
       "4   RandomForestRegressor(n_estimators=120, n_jobs...                     12   \n",
       "0   RandomForestRegressor(n_estimators=120, n_jobs...                     10   \n",
       "1   RandomForestRegressor(n_estimators=120, n_jobs...                     10   \n",
       "\n",
       "   param_model__max_features param_model__eta param_model__reg_alpha  \\\n",
       "15                       NaN              0.1                    1.1   \n",
       "16                       NaN              0.1                    1.2   \n",
       "14                       NaN              0.1                      1   \n",
       "31                       NaN              0.3                    1.2   \n",
       "30                       NaN              0.3                    1.1   \n",
       "26                       NaN              0.3                      1   \n",
       "34                       NaN              0.3                    1.2   \n",
       "19                       NaN              0.1                    1.2   \n",
       "28                       NaN              0.3                    1.2   \n",
       "27                       NaN              0.3                    1.1   \n",
       "17                       NaN              0.1                      1   \n",
       "32                       NaN              0.3                      1   \n",
       "35                       NaN              0.3                      1   \n",
       "20                       NaN              0.1                      1   \n",
       "23                       NaN              0.1                      1   \n",
       "37                       NaN              0.3                    1.2   \n",
       "18                       NaN              0.1                    1.1   \n",
       "22                       NaN              0.1                    1.2   \n",
       "21                       NaN              0.1                    1.1   \n",
       "33                       NaN              0.3                    1.1   \n",
       "24                       NaN              0.1                    1.1   \n",
       "36                       NaN              0.3                    1.1   \n",
       "25                       NaN              0.1                    1.2   \n",
       "29                       NaN              0.3                      1   \n",
       "11                      auto              NaN                    NaN   \n",
       "10                      None              NaN                    NaN   \n",
       "8                       None              NaN                    NaN   \n",
       "9                       auto              NaN                    NaN   \n",
       "12                      None              NaN                    NaN   \n",
       "13                      auto              NaN                    NaN   \n",
       "6                       None              NaN                    NaN   \n",
       "7                       auto              NaN                    NaN   \n",
       "3                       auto              NaN                    NaN   \n",
       "2                       None              NaN                    NaN   \n",
       "5                       auto              NaN                    NaN   \n",
       "4                       None              NaN                    NaN   \n",
       "0                       None              NaN                    NaN   \n",
       "1                       auto              NaN                    NaN   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'model': XGBRegressor(base_score=None, booste...           0.489041   \n",
       "16  {'model': XGBRegressor(base_score=None, booste...           0.488619   \n",
       "14  {'model': XGBRegressor(base_score=None, booste...           0.496290   \n",
       "31  {'model': XGBRegressor(base_score=None, booste...           0.454715   \n",
       "30  {'model': XGBRegressor(base_score=None, booste...           0.451530   \n",
       "26  {'model': XGBRegressor(base_score=None, booste...           0.473782   \n",
       "34  {'model': XGBRegressor(base_score=None, booste...           0.455640   \n",
       "19  {'model': XGBRegressor(base_score=None, booste...           0.485158   \n",
       "28  {'model': XGBRegressor(base_score=None, booste...           0.459045   \n",
       "27  {'model': XGBRegressor(base_score=None, booste...           0.461504   \n",
       "17  {'model': XGBRegressor(base_score=None, booste...           0.494848   \n",
       "32  {'model': XGBRegressor(base_score=None, booste...           0.472827   \n",
       "35  {'model': XGBRegressor(base_score=None, booste...           0.457436   \n",
       "20  {'model': XGBRegressor(base_score=None, booste...           0.498142   \n",
       "23  {'model': XGBRegressor(base_score=None, booste...           0.494764   \n",
       "37  {'model': XGBRegressor(base_score=None, booste...           0.441854   \n",
       "18  {'model': XGBRegressor(base_score=None, booste...           0.479611   \n",
       "22  {'model': XGBRegressor(base_score=None, booste...           0.483524   \n",
       "21  {'model': XGBRegressor(base_score=None, booste...           0.488489   \n",
       "33  {'model': XGBRegressor(base_score=None, booste...           0.450281   \n",
       "24  {'model': XGBRegressor(base_score=None, booste...           0.489366   \n",
       "36  {'model': XGBRegressor(base_score=None, booste...           0.454933   \n",
       "25  {'model': XGBRegressor(base_score=None, booste...           0.483234   \n",
       "29  {'model': XGBRegressor(base_score=None, booste...           0.467521   \n",
       "11  {'model': RandomForestRegressor(n_estimators=1...           0.442721   \n",
       "10  {'model': RandomForestRegressor(n_estimators=1...           0.442721   \n",
       "8   {'model': RandomForestRegressor(n_estimators=1...           0.434824   \n",
       "9   {'model': RandomForestRegressor(n_estimators=1...           0.434824   \n",
       "12  {'model': RandomForestRegressor(n_estimators=1...           0.446799   \n",
       "13  {'model': RandomForestRegressor(n_estimators=1...           0.446799   \n",
       "6   {'model': RandomForestRegressor(n_estimators=1...           0.444562   \n",
       "7   {'model': RandomForestRegressor(n_estimators=1...           0.444562   \n",
       "3   {'model': RandomForestRegressor(n_estimators=1...           0.444629   \n",
       "2   {'model': RandomForestRegressor(n_estimators=1...           0.444629   \n",
       "5   {'model': RandomForestRegressor(n_estimators=1...           0.441234   \n",
       "4   {'model': RandomForestRegressor(n_estimators=1...           0.441234   \n",
       "0   {'model': RandomForestRegressor(n_estimators=1...           0.441763   \n",
       "1   {'model': RandomForestRegressor(n_estimators=1...           0.441763   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.112044           0.249863           0.339120   \n",
       "16           0.053167           0.242089           0.338860   \n",
       "14           0.019671           0.259478           0.380897   \n",
       "31           0.078265           0.201029           0.354615   \n",
       "30           0.050477           0.220305           0.379015   \n",
       "26          -0.053094           0.257793           0.432291   \n",
       "34           0.013450           0.227711           0.353132   \n",
       "19          -0.014924           0.231482           0.334761   \n",
       "28          -0.025285           0.236809           0.388240   \n",
       "27          -0.077909           0.259754           0.372114   \n",
       "17          -0.030843           0.219688           0.323455   \n",
       "32           0.035152           0.168870           0.333253   \n",
       "35           0.061936           0.155508           0.290716   \n",
       "20          -0.067118           0.214198           0.344013   \n",
       "23          -0.041594           0.214933           0.318742   \n",
       "37          -0.066077           0.229616           0.380083   \n",
       "18          -0.042436           0.235961           0.281458   \n",
       "22          -0.051109           0.222735           0.282292   \n",
       "21          -0.081432           0.210590           0.317260   \n",
       "33           0.031966           0.177970           0.292480   \n",
       "24          -0.121584           0.224825           0.320796   \n",
       "36           0.002093           0.159301           0.255663   \n",
       "25          -0.121073           0.221793           0.246593   \n",
       "29          -0.106890           0.227051           0.266799   \n",
       "11           0.073010           0.150109           0.047272   \n",
       "10           0.073010           0.150109           0.047272   \n",
       "8            0.049659           0.134774           0.055411   \n",
       "9            0.049659           0.134774           0.055411   \n",
       "12           0.053375           0.122834           0.065182   \n",
       "13           0.053375           0.122834           0.065182   \n",
       "6            0.040985           0.133035           0.060128   \n",
       "7            0.040985           0.133035           0.060128   \n",
       "3            0.048304           0.130403           0.044967   \n",
       "2            0.048304           0.130403           0.044967   \n",
       "5            0.044871           0.113632           0.058471   \n",
       "4            0.044871           0.113632           0.058471   \n",
       "0            0.040049           0.129182           0.039375   \n",
       "1            0.040049           0.129182           0.039375   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.394873         0.316988        0.128581                1  \n",
       "16           0.404852         0.305518        0.149806                2  \n",
       "14           0.361093         0.303486        0.160606                3  \n",
       "31           0.422365         0.302198        0.142007                4  \n",
       "30           0.398107         0.299887        0.146590                5  \n",
       "26           0.386083         0.299371        0.190560                6  \n",
       "34           0.411260         0.292239        0.159035                7  \n",
       "19           0.409253         0.289146        0.173615                8  \n",
       "28           0.378042         0.287370        0.172150                9  \n",
       "27           0.371115         0.277316        0.188787               10  \n",
       "17           0.374493         0.276328        0.177297               11  \n",
       "32           0.345635         0.271148        0.152469               12  \n",
       "35           0.379315         0.268982        0.144156               13  \n",
       "20           0.351429         0.268133        0.190212               14  \n",
       "23           0.349703         0.267310        0.178513               15  \n",
       "37           0.347994         0.266694        0.180144               16  \n",
       "18           0.365138         0.263946        0.174190               17  \n",
       "22           0.370284         0.261545        0.179325               18  \n",
       "21           0.364586         0.259899        0.192583               19  \n",
       "33           0.330662         0.256672        0.142076               20  \n",
       "24           0.366251         0.255931        0.207053               21  \n",
       "36           0.369403         0.248279        0.158718               22  \n",
       "25           0.370094         0.240128        0.203389               23  \n",
       "29           0.345308         0.239958        0.191872               24  \n",
       "11           0.335539         0.209730        0.154112               25  \n",
       "10           0.335539         0.209730        0.154112               25  \n",
       "8            0.326637         0.200261        0.154235               27  \n",
       "9            0.326637         0.200261        0.154235               28  \n",
       "12           0.313062         0.200250        0.154481               29  \n",
       "13           0.313062         0.200250        0.154481               30  \n",
       "6            0.320523         0.199847        0.157271               31  \n",
       "7            0.320523         0.199847        0.157271               32  \n",
       "3            0.314886         0.196638        0.158036               33  \n",
       "2            0.314886         0.196638        0.158036               33  \n",
       "5            0.315847         0.194811        0.156866               35  \n",
       "4            0.315847         0.194811        0.156866               36  \n",
       "0            0.308431         0.191760        0.158913               37  \n",
       "1            0.308431         0.191760        0.158913               38  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.DataFrame(fitted_grid.cv_results_)\n",
    "grid_search_results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a parameter grid\n",
    "# param_grid = [\n",
    "#      {\n",
    "#         'model': [RandomForestRegressor(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "#         'model__max_depth': list(range(2, 17, 2)),\n",
    "#         'model__max_features': ['sqrt', 'auto', 'log2'],\n",
    "#         'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "#      {\n",
    "#         'model': [xgb.XGBRegressor(random_state=1)],\n",
    "#         'model__max_depth': list(range(2, 5, 1)),\n",
    "#         'model__gamma': [0.1, 0.5, 0.9],\n",
    "#         'model__eta': [0.01, 0.1, 0.3]\n",
    "#         },\n",
    "\n",
    "# ]\n",
    "\n",
    "# # Instantiate a gridsearch\n",
    "# grid = RandomizedSearchCV(estimator, param_grid, cv = 5, n_jobs=-1,verbose = 2)\n",
    "# fitted_grid = grid.fit(X_train, y_train)\n",
    "\n",
    "# # fitted_grid.best_estimator_\n",
    "# # fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search_results = pd.DataFrame(fitted_grid.cv_results_)\n",
    "# # random_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Team - xT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_xt_train_df, modeling_xt_test_df, 'xT_value')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-xt')\n",
    "\n",
    "# pipeline column transformer\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define gridsearch column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Decision Tree Regressor ***\n",
      "DT Train Score:  0.9999999999999997\n",
      "DT Test Score:  0.8941230264107702\n",
      " \n",
      "*** Decision Tree Regressor - Depth 10 ***\n",
      "DT Train Score:  0.9679232190410411\n",
      "DT Test Score:  0.881375744651935\n",
      " \n",
      "*** Random Forest Regressor - Depth 17 ***\n",
      "Random Forest Train Score:  0.9548638157772583\n",
      "Random Forest Test Score:  0.8336408872610948\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 ***\n",
      "XGB Regressor Train Score:  0.9958911469867335\n",
      "XGB Regressor Test Score:  0.8942143933500908\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 Optimised ***\n",
      "XGB Regressor Train Score:  0.9265065158190492\n",
      "XGB Regressor Test Score:  0.8085949010492468\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Decision Tree Regressor ***')\n",
    "pipe = make_pipeline(ct, DecisionTreeRegressor())\n",
    "pipe.fit(X_train, y_train)\n",
    "print('DT Train Score: ', pipe.score(X_train, y_train))\n",
    "print('DT Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Decision Tree Regressor - Depth 10 ***')\n",
    "pipe = make_pipeline(ct, DecisionTreeRegressor(max_depth=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('DT Train Score: ', pipe.score(X_train, y_train))\n",
    "print('DT Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 17 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=150, oob_score=True, n_jobs=-1, random_state=1))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 Optimised ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5, reg_lambda=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 89 candidates, totalling 445 fits\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   6.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   9.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   9.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  17.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=  10.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  16.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  17.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  17.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  16.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  17.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  14.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  14.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  19.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  19.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  19.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  18.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  18.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  18.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  19.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  19.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  18.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  18.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  17.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  18.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  20.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  21.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  21.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  20.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  21.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  17.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  20.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  21.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  21.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  20.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  21.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid_xt = [\n",
    "     {\n",
    "        'model': [DecisionTreeRegressor(random_state=1)],\n",
    "        'model__max_depth': list(range(5, 10, 2)),\n",
    "        'model__max_features': [None, 'auto']}, \n",
    "     \n",
    "     {\n",
    "        'model': [RandomForestRegressor(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(5, 18, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBRegressor(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid_xt = GridSearchCV(estimator, param_grid_xt, cv = 5, verbose = 2)\n",
    "fitted_grid_xt = grid_xt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>17.939394</td>\n",
       "      <td>0.260279</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.412713</td>\n",
       "      <td>0.285764</td>\n",
       "      <td>0.200786</td>\n",
       "      <td>0.353443</td>\n",
       "      <td>0.249308</td>\n",
       "      <td>0.300403</td>\n",
       "      <td>0.075067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>18.023579</td>\n",
       "      <td>0.201526</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.412713</td>\n",
       "      <td>0.285764</td>\n",
       "      <td>0.200786</td>\n",
       "      <td>0.353443</td>\n",
       "      <td>0.249308</td>\n",
       "      <td>0.300403</td>\n",
       "      <td>0.075067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>21.065515</td>\n",
       "      <td>0.283021</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.411430</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.201698</td>\n",
       "      <td>0.352688</td>\n",
       "      <td>0.245080</td>\n",
       "      <td>0.299732</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>21.081727</td>\n",
       "      <td>0.222234</td>\n",
       "      <td>0.031277</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.411430</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.201698</td>\n",
       "      <td>0.352688</td>\n",
       "      <td>0.245080</td>\n",
       "      <td>0.299732</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>12.171634</td>\n",
       "      <td>0.142245</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.409540</td>\n",
       "      <td>0.253771</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.347294</td>\n",
       "      <td>0.270464</td>\n",
       "      <td>0.295795</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.294630</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>0.022757</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.987896</td>\n",
       "      <td>0.022096</td>\n",
       "      <td>0.022176</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2.472307</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.022557</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2.289520</td>\n",
       "      <td>0.052499</td>\n",
       "      <td>0.022625</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.985148</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "56      17.939394      0.260279         0.029468        0.000626   \n",
       "60      18.023579      0.201526         0.029104        0.000494   \n",
       "61      21.065515      0.283021         0.030969        0.000760   \n",
       "57      21.081727      0.222234         0.031277        0.000760   \n",
       "58      12.171634      0.142245         0.026271        0.000666   \n",
       "..            ...           ...              ...             ...   \n",
       "69       2.294630      0.061198         0.022757        0.000798   \n",
       "68       1.987896      0.022096         0.022176        0.000888   \n",
       "67       2.472307      0.062073         0.022557        0.000865   \n",
       "66       2.289520      0.052499         0.022625        0.000850   \n",
       "65       1.985148      0.014928         0.023185        0.001693   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "56  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "60  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "61  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "57  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "58  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "..                                                ...                    ...   \n",
       "69  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "68  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "67  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "66  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "65  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "\n",
       "   param_model__max_features param_model__n_estimators param_model__eta  \\\n",
       "56                      None                       120              NaN   \n",
       "60                      auto                       120              NaN   \n",
       "61                      auto                       140              NaN   \n",
       "57                      None                       140              NaN   \n",
       "58                      auto                        80              NaN   \n",
       "..                       ...                       ...              ...   \n",
       "69                       NaN                       NaN             0.01   \n",
       "68                       NaN                       NaN             0.01   \n",
       "67                       NaN                       NaN             0.01   \n",
       "66                       NaN                       NaN             0.01   \n",
       "65                       NaN                       NaN             0.01   \n",
       "\n",
       "   param_model__gamma                                             params  \\\n",
       "56                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "60                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "61                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "57                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "58                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "..                ...                                                ...   \n",
       "69                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "68                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "67                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "66                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "65                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "56           0.412713           0.285764           0.200786   \n",
       "60           0.412713           0.285764           0.200786   \n",
       "61           0.411430           0.287766           0.201698   \n",
       "57           0.411430           0.287766           0.201698   \n",
       "58           0.409540           0.253771           0.197908   \n",
       "..                ...                ...                ...   \n",
       "69        -170.761104        -230.994639        -428.074352   \n",
       "68        -170.761104        -230.994639        -428.074352   \n",
       "67        -170.761104        -230.994639        -428.074352   \n",
       "66        -170.761104        -230.994639        -428.074352   \n",
       "65        -170.761104        -230.994639        -428.074352   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "56           0.353443           0.249308         0.300403        0.075067   \n",
       "60           0.353443           0.249308         0.300403        0.075067   \n",
       "61           0.352688           0.245080         0.299732        0.074862   \n",
       "57           0.352688           0.245080         0.299732        0.074862   \n",
       "58           0.347294           0.270464         0.295795        0.074269   \n",
       "..                ...                ...              ...             ...   \n",
       "69        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "68        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "67        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "66        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "65        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "\n",
       "    rank_test_score  \n",
       "56                1  \n",
       "60                1  \n",
       "61                3  \n",
       "57                3  \n",
       "58                5  \n",
       "..              ...  \n",
       "69               84  \n",
       "68               84  \n",
       "67               84  \n",
       "66               84  \n",
       "65               84  \n",
       "\n",
       "[89 rows x 19 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results_xt = pd.DataFrame(fitted_grid_xt.cv_results_)\n",
    "grid_search_results_xt.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Team - Next Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'type_name_encoded')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-action')\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   7.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   8.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   8.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   7.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   8.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   6.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  11.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  10.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  11.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  10.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  10.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.7s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.6s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  12.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  12.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.6s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.6s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.7s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   6.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  11.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  12.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  12.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   9.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  15.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  15.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  21.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  14.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  14.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  22.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  18.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  22.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  22.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  23.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  23.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  23.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  25.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  26.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  24.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  24.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  25.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  25.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  24.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  29.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  29.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  30.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  30.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  30.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  34.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  34.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  35.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  35.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  32.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  21.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  22.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  23.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  28.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  29.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  29.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  30.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  29.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  35.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  35.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  36.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  37.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  37.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  42.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  43.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  44.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  45.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  44.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.7s\n",
      "[18:40:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=   9.6s\n",
      "[18:40:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=   9.9s\n",
      "[18:41:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=   9.9s\n",
      "[18:41:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  10.0s\n",
      "[18:41:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  10.2s\n",
      "[18:41:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  14.9s\n",
      "[18:41:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  15.6s\n",
      "[18:42:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  15.9s\n",
      "[18:42:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  16.1s\n",
      "[18:42:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  16.2s\n",
      "[18:42:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  20.6s\n",
      "[18:43:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  21.3s\n",
      "[18:43:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  21.2s\n",
      "[18:44:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  20.9s\n",
      "[18:44:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  21.2s\n",
      "[18:44:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  10.6s\n",
      "[18:44:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.6s\n",
      "[18:45:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.9s\n",
      "[18:46:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  16.0s\n",
      "[18:46:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.8s\n",
      "[18:46:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.9s\n",
      "[18:46:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  20.4s\n",
      "[18:47:16] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.0s\n",
      "[18:47:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.4s\n",
      "[18:47:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.1s\n",
      "[18:48:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.3s\n",
      "[18:48:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  10.6s\n",
      "[18:48:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.1s\n",
      "[18:49:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.3s\n",
      "[18:49:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.1s\n",
      "[18:49:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.1s\n",
      "[18:49:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.5s\n",
      "[18:49:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.4s\n",
      "[18:50:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.3s\n",
      "[18:50:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.3s\n",
      "[18:50:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.2s\n",
      "[18:50:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  20.6s\n",
      "[18:51:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.2s\n",
      "[18:51:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.2s\n",
      "[18:52:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.2s\n",
      "[18:52:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.4s\n",
      "[18:52:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  10.7s\n",
      "[18:52:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.2s\n",
      "[18:53:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.2s\n",
      "[18:53:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.1s\n",
      "[18:53:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.1s\n",
      "[18:53:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  15.9s\n",
      "[18:53:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.2s\n",
      "[18:54:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.4s\n",
      "[18:54:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.4s\n",
      "[18:54:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.4s\n",
      "[18:55:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.0s\n",
      "[18:55:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.6s\n",
      "[18:55:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.5s\n",
      "[18:56:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.4s\n",
      "[18:56:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.4s\n",
      "[18:56:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.5s\n",
      "[18:56:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.7s\n",
      "[18:57:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.6s\n",
      "[18:57:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.7s\n",
      "[18:57:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.8s\n",
      "[18:57:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  14.9s\n",
      "[18:57:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.0s\n",
      "[18:58:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.0s\n",
      "[18:58:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.0s\n",
      "[18:58:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.1s\n",
      "[18:58:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  22.4s\n",
      "[18:59:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  26.9s\n",
      "[18:59:46] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  28.5s\n",
      "[19:00:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  24.8s\n",
      "[19:00:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  23.4s\n",
      "[19:01:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.4s\n",
      "[19:01:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.6s\n",
      "[19:01:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.7s\n",
      "[19:01:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.9s\n",
      "[19:01:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.7s\n",
      "[19:02:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  18.1s\n",
      "[19:02:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  18.1s\n",
      "[19:02:36] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  17.6s\n",
      "[19:02:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  17.2s\n",
      "[19:03:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  16.9s\n",
      "[19:03:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  21.7s\n",
      "[19:03:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  22.5s\n",
      "[19:04:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  22.5s\n",
      "[19:04:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  23.0s\n",
      "[19:04:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  22.8s\n",
      "[19:05:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.2s\n",
      "[19:05:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.5s\n",
      "[19:05:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.6s\n",
      "[19:05:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.4s\n",
      "[19:06:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.4s\n",
      "[19:06:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.4s\n",
      "[19:06:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.8s\n",
      "[19:06:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  17.0s\n",
      "[19:07:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.8s\n",
      "[19:07:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.9s\n",
      "[19:07:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  22.1s\n",
      "[19:08:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  23.2s\n",
      "[19:08:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  23.1s\n",
      "[19:08:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  23.1s\n",
      "[19:09:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  22.5s\n",
      "[19:09:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  11.1s\n",
      "[19:09:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.9s\n",
      "[19:09:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.9s\n",
      "[19:10:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.8s\n",
      "[19:10:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.9s\n",
      "[19:10:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.4s\n",
      "[19:10:46] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.8s\n",
      "[19:11:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.6s\n",
      "[19:11:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.7s\n",
      "[19:11:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.6s\n",
      "[19:11:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.2s\n",
      "[19:12:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.8s\n",
      "[19:12:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.8s\n",
      "[19:12:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.8s\n",
      "[19:13:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.6s\n",
      "[19:13:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.1s\n",
      "[19:13:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.3s\n",
      "[19:13:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.5s\n",
      "[19:14:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.3s\n",
      "[19:14:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.4s\n",
      "[19:14:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  14.9s\n",
      "[19:14:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.3s\n",
      "[19:14:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.3s\n",
      "[19:15:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.2s\n",
      "[19:15:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.2s\n",
      "[19:15:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  19.9s\n",
      "[19:15:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  20.5s\n",
      "[19:16:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  20.7s\n",
      "[19:16:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  21.8s\n",
      "[19:17:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  21.3s\n",
      "[19:17:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.4s\n",
      "[19:17:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.6s\n",
      "[19:17:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.7s\n",
      "[19:17:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.6s\n",
      "[19:18:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.7s\n",
      "[19:18:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  15.5s\n",
      "[19:18:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  12.8s\n",
      "[19:18:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  13.1s\n",
      "[19:18:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  12.1s\n",
      "[19:19:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  11.8s\n",
      "[19:19:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  16.9s\n",
      "[19:19:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  17.4s\n",
      "[19:19:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  17.3s\n",
      "[19:20:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  16.8s\n",
      "[19:20:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  18.1s\n",
      "[19:20:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   8.7s\n",
      "[19:20:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.2s\n",
      "[19:21:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.3s\n",
      "[19:21:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.3s\n",
      "[19:21:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.5s\n",
      "[19:21:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  13.5s\n",
      "[19:21:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  14.5s\n",
      "[19:22:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  15.9s\n",
      "[19:22:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  15.9s\n",
      "[19:22:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  15.0s\n",
      "[19:22:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  18.5s\n",
      "[19:23:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  19.7s\n",
      "[19:23:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  20.2s\n",
      "[19:23:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  20.1s\n",
      "[19:24:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  20.7s\n",
      "[19:24:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   9.9s\n",
      "[19:24:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.8s\n",
      "[19:24:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.4s\n",
      "[19:25:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.2s\n",
      "[19:25:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.6s\n",
      "[19:25:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.8s\n",
      "[19:25:36] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.5s\n",
      "[19:25:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.7s\n",
      "[19:26:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  16.1s\n",
      "[19:26:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.5s\n",
      "[19:26:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  20.2s\n",
      "[19:26:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  19.4s\n",
      "[19:27:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  20.1s\n",
      "[19:27:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  18.5s\n",
      "[19:27:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  19.5s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid_action = [\n",
    "     {\n",
    "        'model': [svm.SVC(random_state=1)],\n",
    "        'dim_reducer': [PCA()], \n",
    "        'dim_reducer__n_components': [0.8, 0.85, 0.9, 0.95],\n",
    "        'model__C': [0.001, 0.01, 0.1, 1]},\n",
    "     \n",
    "     {\n",
    "        'model': [RandomForestClassifier(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(2, 17, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBClassifier(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0, 0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid_action = GridSearchCV(estimator, param_grid_action, cv = 5, verbose = 2)\n",
    "fitted_grid_action = grid_action.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dim_reducer</th>\n",
       "      <th>param_dim_reducer__n_components</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>...</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.455999</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>2.045810</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.95</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.775779</td>\n",
       "      <td>0.795763</td>\n",
       "      <td>0.789768</td>\n",
       "      <td>0.739408</td>\n",
       "      <td>0.812550</td>\n",
       "      <td>0.782654</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>13.017176</td>\n",
       "      <td>1.312634</td>\n",
       "      <td>0.037486</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.770184</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>0.736611</td>\n",
       "      <td>0.811751</td>\n",
       "      <td>0.774580</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>20.770916</td>\n",
       "      <td>0.654539</td>\n",
       "      <td>0.049602</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.774580</td>\n",
       "      <td>0.777378</td>\n",
       "      <td>0.779376</td>\n",
       "      <td>0.731415</td>\n",
       "      <td>0.808553</td>\n",
       "      <td>0.774261</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>20.585251</td>\n",
       "      <td>0.226014</td>\n",
       "      <td>0.047692</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.772582</td>\n",
       "      <td>0.779776</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.737410</td>\n",
       "      <td>0.797762</td>\n",
       "      <td>0.773621</td>\n",
       "      <td>0.019906</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>25.132153</td>\n",
       "      <td>2.251778</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.772982</td>\n",
       "      <td>0.782174</td>\n",
       "      <td>0.777378</td>\n",
       "      <td>0.735412</td>\n",
       "      <td>0.797362</td>\n",
       "      <td>0.773062</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.883615</td>\n",
       "      <td>0.086223</td>\n",
       "      <td>0.042993</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.554357</td>\n",
       "      <td>0.602318</td>\n",
       "      <td>0.598321</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>0.599520</td>\n",
       "      <td>0.573381</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.026851</td>\n",
       "      <td>0.102224</td>\n",
       "      <td>3.036139</td>\n",
       "      <td>0.074396</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.046372</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>3.211035</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.95</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.426208</td>\n",
       "      <td>0.068349</td>\n",
       "      <td>3.032837</td>\n",
       "      <td>0.123106</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.85</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.256927</td>\n",
       "      <td>0.082737</td>\n",
       "      <td>2.805307</td>\n",
       "      <td>0.032524</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15        5.455999      0.031822         2.045810        0.028411   \n",
       "108      13.017176      1.312634         0.037486        0.002990   \n",
       "106      20.770916      0.654539         0.049602        0.001100   \n",
       "103      20.585251      0.226014         0.047692        0.001775   \n",
       "94       25.132153      2.251778         0.065572        0.009444   \n",
       "..             ...           ...              ...             ...   \n",
       "18        5.883615      0.086223         0.042993        0.001623   \n",
       "8         9.026851      0.102224         3.036139        0.074396   \n",
       "12        9.046372      0.208015         3.211035        0.041036   \n",
       "4         8.426208      0.068349         3.032837        0.123106   \n",
       "0         9.256927      0.082737         2.805307        0.032524   \n",
       "\n",
       "          param_dim_reducer param_dim_reducer__n_components  \\\n",
       "15   PCA(n_components=0.95)                            0.95   \n",
       "108                     NaN                             NaN   \n",
       "106                     NaN                             NaN   \n",
       "103                     NaN                             NaN   \n",
       "94                      NaN                             NaN   \n",
       "..                      ...                             ...   \n",
       "18                      NaN                             NaN   \n",
       "8    PCA(n_components=0.95)                             0.9   \n",
       "12   PCA(n_components=0.95)                            0.95   \n",
       "4    PCA(n_components=0.95)                            0.85   \n",
       "0    PCA(n_components=0.95)                             0.8   \n",
       "\n",
       "                                           param_model param_model__C  \\\n",
       "15                            SVC(C=1, random_state=1)              1   \n",
       "108  XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "106  XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "103  XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "94   XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "..                                                 ...            ...   \n",
       "18   RandomForestClassifier(n_jobs=-1, oob_score=Tr...            NaN   \n",
       "8                             SVC(C=1, random_state=1)          0.001   \n",
       "12                            SVC(C=1, random_state=1)          0.001   \n",
       "4                             SVC(C=1, random_state=1)          0.001   \n",
       "0                             SVC(C=1, random_state=1)          0.001   \n",
       "\n",
       "    param_model__max_depth param_model__max_features  ... param_model__gamma  \\\n",
       "15                     NaN                       NaN  ...                NaN   \n",
       "108                      3                       NaN  ...                0.1   \n",
       "106                      4                       NaN  ...                  0   \n",
       "103                      4                       NaN  ...                0.9   \n",
       "94                       4                       NaN  ...                  0   \n",
       "..                     ...                       ...  ...                ...   \n",
       "18                       2                      None  ...                NaN   \n",
       "8                      NaN                       NaN  ...                NaN   \n",
       "12                     NaN                       NaN  ...                NaN   \n",
       "4                      NaN                       NaN  ...                NaN   \n",
       "0                      NaN                       NaN  ...                NaN   \n",
       "\n",
       "                                                params split0_test_score  \\\n",
       "15   {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.775779   \n",
       "108  {'model': XGBClassifier(base_score=None, boost...          0.777778   \n",
       "106  {'model': XGBClassifier(base_score=None, boost...          0.774580   \n",
       "103  {'model': XGBClassifier(base_score=None, boost...          0.772582   \n",
       "94   {'model': XGBClassifier(base_score=None, boost...          0.772982   \n",
       "..                                                 ...               ...   \n",
       "18   {'model': RandomForestClassifier(n_jobs=-1, oo...          0.554357   \n",
       "8    {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "12   {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "4    {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "0    {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.795763           0.789768           0.739408   \n",
       "108          0.770184           0.776579           0.736611   \n",
       "106          0.777378           0.779376           0.731415   \n",
       "103          0.779776           0.780576           0.737410   \n",
       "94           0.782174           0.777378           0.735412   \n",
       "..                ...                ...                ...   \n",
       "18           0.602318           0.598321           0.512390   \n",
       "8            0.430855           0.414468           0.369305   \n",
       "12           0.430855           0.414468           0.369305   \n",
       "4            0.430855           0.414468           0.369305   \n",
       "0            0.430855           0.414468           0.369305   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15            0.812550         0.782654        0.024632                1  \n",
       "108           0.811751         0.774580        0.023903                2  \n",
       "106           0.808553         0.774261        0.024689                3  \n",
       "103           0.797762         0.773621        0.019906                4  \n",
       "94            0.797362         0.773062        0.020541                5  \n",
       "..                 ...              ...             ...              ...  \n",
       "18            0.599520         0.573381        0.035283              112  \n",
       "8             0.404476         0.405436        0.020204              113  \n",
       "12            0.404476         0.405436        0.020204              113  \n",
       "4             0.404476         0.405436        0.020204              113  \n",
       "0             0.404476         0.405436        0.020204              113  \n",
       "\n",
       "[116 rows x 22 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results_action = pd.DataFrame(fitted_grid_action.cv_results_)\n",
    "grid_search_results_action.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='/var/folders/t5/kc4tlr5n2yn5jkkh1t9rk9500000gn/T/tmpieqziszu',\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['start_x', 'start_y',\n",
       "                                                   'time_seconds',\n",
       "                                                   'n-1_x_distance',\n",
       "                                                   'n-1_y_distance',\n",
       "                                                   'n-1_start_x', 'n-1_start_y',\n",
       "                                                   'n-1_end_x', 'n-1_end_y',\n",
       "                                                   'n-1_offensive_value',\n",
       "                                                   'n-1_defensive_valu...\n",
       "                                                   'team_id', 'end_x', 'end_y',\n",
       "                                                   'type_id', 'result_id',\n",
       "                                                   'bodypart_id', 'action_id',\n",
       "                                                   'type_name', 'result_name',\n",
       "                                                   'bodypart_name',\n",
       "                                                   'offensive_value',\n",
       "                                                   'defensive_value',\n",
       "                                                   'vaep_value', 'x_dif',\n",
       "                                                   'y_dif', 'n-1_same_player',\n",
       "                                                   'n-2_same_player',\n",
       "                                                   'n-3_same_player',\n",
       "                                                   'n-4_same_player',\n",
       "                                                   'n-5_same_player'])])),\n",
       "                ('dim_reducer', PCA(n_components=0.95)),\n",
       "                ('model', SVC(C=1, random_state=1))])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_action.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_action.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL SVM NEXT ACTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Support Vector Machine ***\n",
      "SVM Train Score:  0.8457234212629896\n",
      "SVM Test Score:  0.7791626717801214\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Support Vector Machine ***')\n",
    "pipe_svm = make_pipeline(ct, PCA(n_components=0.95), svm.SVC(C=1, probability=True))\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "print('SVM Train Score: ', pipe_svm.score(X_train, y_train))\n",
    "print('SVM Test Score: ', pipe_svm.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915067856814977"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pipe_svm.predict_proba(X_test), multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_svm.predict(X_test)\n",
    "y_proba = pipe_svm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     dribble       0.80      0.88      0.83      8378\n",
      "       other       0.64      0.62      0.63      4117\n",
      "        pass       0.83      0.76      0.79      9408\n",
      "\n",
      "    accuracy                           0.78     21903\n",
      "   macro avg       0.75      0.75      0.75     21903\n",
      "weighted avg       0.78      0.78      0.78     21903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAEGCAYAAAA3yh0OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvVklEQVR4nO3dd5wV1f3/8dd779J7702lCAgoRUFF7GIJtgiW2AsqMfmqUaKJGo0l9sqPoDFojKIiCiqKiiBVpYg0RQmIdFiqFIHd/fz+mAHuLsvuXe7d3QE+zzzuI3dmzpw5M6yfe87MnHNkZjjnnNt3aSVdAOec2995IHXOuSR5IHXOuSR5IHXOuSR5IHXOuSSll3QBSpLSy5lKVyrpYkRW+8Mbl3QRIs9rIgWbPn1ahpnV2tf9Y5WbmGVuTSitbV09yszO2Ndj7auDO5CWrkSZlheVdDEi64uJz5Z0ESKvdLqH0oKUK6VFyexvmb9SplWfhNL++s1zNZM51r46qAOpc24/IEAq6VLkywOpcy76FO2avwdS51z0eY3UOeeSIUiLlXQh8uWB1DkXbcKb9s45lxx5094555LmNVLnnEuS10idcy4Z8hqpc84lRfhTe+ecS47XSJ1zLnlpfo/UOef2nb9H6pxzKeBP7Z1zLhnR7yIa7fqyc85B0LRP5JNIVtIZkuZJmi+pfx7bq0h6X9K3kuZIuqqgPD2QOueiTUr8U2BWigEvAD2B1sDFklrnSnYzMNfM2gM9gCcklc4vXw+kzrnoS12NtAsw38wWmNl2YAjQK1caAypJElARWAtk5pep3yN1zkVf4g+bakqaGrc8yMwGxS03ABbHLS8Bjs6Vx/PACGAZUAnobWbZ+R3UA6lzLuIK9UJ+hpl1yj+zPViu5dOBGcBJwKHAp5LGm9nGvWXqTXvnXLTt7CKayKdgS4BGccsNCWqe8a4ChllgPrAQaJVfph5InXMRp1TeI50CNJfULHyA1IegGR/vZ+BkAEl1gJbAgvwy9aa9cy76UvRCvpllSuoHjAJiwMtmNkdS33D7QOABYLCkWQT14TvNLCO/fD2QOueiL4VdRM1sJDAy17qBcd+XAacVJk8PpM656PMuos45lwT5MHrOOZc0pXkgdc65fSZA3rR3zrkkiLxfo48QD6TOuYiT10hd4OSuh/PwbRcSS0vjP8Mn8fQrn+bYXrlCWf75wBU0rFONWHqM518bzevvfwnAjRefyO/O7QZmzJ2/jJvvf41t2/MdQ2G/8Pnkufzl6WFkZWVz6W+6csvlp+bYbmbc/dQ7jJ40l3JlS/PsXy+lXctGzF+0kuv/OnhXukVLM7jjujO5oc+JPPbSSF4bPpka1SoCcFffszmlW5viPK2U+mzSXP78xFCysrP5Xa9u/N+VOd/KMTP6PzGUTyfOoVzZ0gy493e0b7W7405WVjYnXv4o9WpX4c2nbgRg1g9LuO2RIWzaso3G9Wow6IErqFyxXLGeV2FFPZAW2x1cSfdJuj2P9X0lXR5+Hytpj36y+ezbVNLsoilx6qSlicfuuIjf/mEAx1z0dy44rSMtm9XNkeba33Zn3oIVHH/pI5xzwzP8/Q/nUSo9Rr1aVbih9wmcdPmjdOvzEGlpaZx/WscSOpPUycrKpv8Tb/P6k30Z/8ZdvPvpNOYtXJ4jzejJc1m4eDVfvv1XHu/fmzsefQuAw5rU4fNX7+TzV+/k03//iXJlS3PmCe137XdDnx67tu/PQTQrK5s/PfoWbz9zE1++9Rfe+WQa3y/IeY0+nTSX//28mmnD7uXpuy7mtkeG5Ng+cMgYWjSrk2PdH/7+Ovfe3ItJQ+7m7BPb89x/Rhf5uSQrLS0toU+Jla/EjgxISjezgWb2akmWo6h1bNOUBYszWLR0DTsysxj26XTOPKFdjjQGVKxQBoAK5cuwbuMWMrOCAWfS02OULVOKWCyN8mVLs2L1huI+hZSbPncRzRrWommDmpQulc65pxzFx+Nm5Ujz8bhZ/LZnFyTRqW0zNm7aysqMnOc+fuo8mjaoSaN61Yuz+MVi2pyfOKRRTZo2DK7R+acexcgvZuZIM/KLmfQ5K7hGnY9oxoZftrIivEZLV67jkwlzuLxXtxz7zP95Fd2OOgyAHl1a8f6YGcVyPvtMhfiUkCINpJLuDkei/oygv+rOWudDkr4A/pBHbfMySZMkzZbUJW59e0mfS/pR0nV5HCsm6TFJUyTNlHRDUZ5bYdSrVYWlK9ftWl62ch31alXJkebFt76gRdO6fPfRg0x84y7+/MRQzIzlqzfw3GujmfX+A3z/0YNs3LyVMV99X9ynkHIrVq+nfu2qu5br1666xw/E8tUbaFBnd5p6taqyPFeadz+dznmn5qyhvzx0PD0ue4Q//P2/rN+4JeVlLy7B+VfbtVy/TrU9zn/56vU509SuyvJV6wG468l3+Nst55KWawbOVofU46PwR2v46Ok5/jajSOE90kQ+JaXIAqmkjgQDAhwJnA90jttc1cxOMLMn8ti1gpl1A24CXo5b3w44C+gK3COpfq79rgE2mFnn8FjXSWqWmrNJTl7/wJZr4K6TjjmcWT8s4fCed9P90od59E+/pVKFslSpVI4zux9Bh173cnjPuylftjQX9ey8R377m9znD+TRe2XPRPFJtu/I5JMJsznn5A671l1x/nF8NfQePn/1DurUrMK9z76bkvKWBMvjIuW+RHldR0l8PH4WNatVosPhjffY/vw9l/LS2+Po8bt/sGnLNkqVivZ8SEDkA2lRPmw6HnjXzLYASIofYeXNfPZ7A8DMxkmqLKlquH64mW0FtkoaQzDS9Yy4/U4D2km6MFyuAjQnGAJrF0nXA9cDUKpi4c9qHyxbtX6PmsWKXE3US885ZtcDqIVLMli0bA3Nm9ShUb3qLFq2hjXrNwHw/phv6dKuGW99NKVYyl5U6tWuyrKw5gTBNapbs3LONLWqsnTl7jTLV6+nbs3dNfnRk+dyRMuG1K6+e7/475f16splt8eP6bt/qV+76h4tmfjzzzPNqvXUrVWF4aO/4ePxs/h00hy2bdvBL5t/5fq/vsKgB66gRdO6DHu+HwDzF63kkwlziueEknCwP2zKq94BsLkQ+1gB63cS8Hsz6xB+mpnZJ3tkbjbIzDqZWSelF8+TyulzF3Fo41o0rl+DUukxzj/1KD4al/Ne15IV6+jeuSUAtapX4rAmdfhpaQZLVqyl0xHNKFemFAAndG7JvIUri6XcRenIwxuzYPFqFi1bw/Ydmbz32XROP/6IHGlOP/4I3v7oa8yMqbMXUqlCWerEBZK8mvXx91BHjp1Jq0PqFe2JFKGjWjfhfz+vZtHSDLbvyGTYp9Pp2T3nvfWe3Y9gyIfBNZoyayGVK5ajbs0q3NuvF3M+/DszR9zPvx66iuM7t2DQA1cAsHrtLwBkZ2fz+MujuOqC44r93ArrYK6RjiMYiuqR8DjnAP9MYL/ewBhJxxE01TeEF6iXpIeBCgQTUvUH4iekGgXcKOlzM9shqQWw1MzyC9rFIisrmzsefYt3nr2ZWEz8d8SXfL9gBVedH/wB/3vYBB7718e8cO9lTHzjLiT42/PDWbthM2s3bGbE6G8Y+9qdZGVlM3PeEl55d2IJn1Hy0tNjPHzbhfT54wCysrO5+OxjaHVIPV4ZNgEImuindGvN6ElzOPq391OuTGme+culu/bf8ut2xn39PY/f2TtHvve/MJzZPyxFEo3qVd9j+/4kPT3Go3dcxAW3vEBWlnHpb47h8EPr8fI74wG4+oLjOe3YNnw6cQ5Hnfc3ypUtxQv3XFZgvu+MmspLQ8cBcHaPDlx6zjFFeh5JEygt2jVS5XUfJmWZS3cDlwOLCEamngucDdxuZlPDNPcBm8zscUljgcnACUBl4Goz+zpMU59g2P/GwKNm9qKkpsAHZtZWUhrwd4KALWA1cK6Z7fURd1r52lam5UUpP+8DxcrJz5Z0ESKvdHq0+4BHQblSmlbA9B/5KlXzUKt6zkMJpc0Y3CepY+2rIn0h38weBB7MtfrxXGnui/veYy/53LeX9T8BbcPv2cBd4cc5dwCJ+j1S79nknIu+aMdRD6TOuYhT9GukfoPHORd5qXxqL+mMsKPQfEn989j+J0kzws9sSVmS8u065zVS51ykCaWsH72kGPACcCrBA/ApkkaY2dydaczsMeCxMP05wP+Z2dr88vUaqXMu+lLX174LMN/MFpjZdmAI0Cuf9BcTdhLKjwdS51y0qVBN+5qSpsZ9rs+VWwNgcdzyknDdnoeVygNnAO8UVERv2jvnIq8QD5syCniPNK+M9vYy/TnAxIKa9eCB1Dm3H0jhU/slQKO45YbAsr2k7UMCzXrwpr1zbj+gNCX0ScAUoLmkZpJKEwTLEbkTSapC0MNyeCKZeo3UORdpqRyQxMwyJfUjGJsjBrxsZnMk9Q23DwyTngd8kuhYHR5InXORl8oX8s1sJDAy17qBuZYHA4MTzdMDqXMu8qLes8kDqXMu+qIdRz2QOueiz2ukzjmXBIk9JvCLGg+kzrmIK9lpRBLhgdQ5F3kRj6MeSJ1z0ec1UuecS4a8Ruqcc0kR/rDJOeeS5oHUOeeS4U1755xLjvCHTc45lyR/j9Q555IW8TjqgdQ5F3HeRdQ555Lj90idcy4FIh5Hfc4m51z0FWI65kTyOkPSPEnzJfXfS5oekmZImiPpi4Ly9Bqpcy7yUlUjlRQDXgBOJZhRdIqkEWY2Ny5NVWAAcIaZ/SypdkH5eo3UORdtSmmNtAsw38wWmNl2YAjQK1eaS4BhZvYzgJmtKijTg7pGekTLRnw05smSLkZk9Xh0bEkXIfKe7XNkSRfhgCdUmKf2NSVNjVseZGaD4pYbAIvjlpcAR+fKowVQStJYoBLwjJm9mt9BD+pA6pzbPxSiaZ9hZp3yyyqPdZZrOR3oCJwMlAMmS/rSzH7YW6YeSJ1zkZfC15+WAI3ilhsCy/JIkxHOab9Z0jigPbDXQOr3SJ1z0RYOWpLIJwFTgOaSmkkqDfQBRuRKMxw4XlK6pPIETf/v8svUa6TOuUhL5Qv5ZpYpqR8wCogBL5vZHEl9w+0Dzew7SR8DM4Fs4CUzm51fvh5InXORl8qeTWY2EhiZa93AXMuPAY8lmqcHUudc5Hlfe+ecS4YP7Oycc8mRj0fqnHPJi3gc9UDqnIu+tIhHUg+kzrlIkw/s7JxzyYt4HPVA6pyLvv32YZOk59izM/8uZnZLkZTIOedyiXgczbdGOjWfbc45VyxE8ApUlO01kJrZK/HLkiqEo6E451yxivo90gJHf5LUVdJcwtFPJLWXNKDIS+accwAKBnZO5FNSEhlG72ngdGANgJl9C3QvwjI559wuIniPNJFPSUnoqb2ZLc711CyraIrjnHN72p8fNu20WFI3wMKBUG+hgEFOnXMulaL++lMiTfu+wM0Ek0YtBTqEy845V+QSHR2/JGNtgTVSM8sALi2GsjjnXJ5i+3uNVNIhkt6XtFrSKknDJR1SHIVzzjlI6bz2SDpD0jxJ8yX1z2N7D0kbJM0IP/cUlGci90hfB14AzguX+wBvsOdc0M45l3LBU/sU5SXFCOLZqQSzhU6RNMLM5uZKOt7Mzk4030TukcrM/mNmmeHnNfLpOuqccymVYG00wRppF2C+mS0ws+3AEKBXskXcayCVVF1SdWCMpP6SmkpqIukO4MNkD+ycc4kqxMOmmpKmxn2uz5VVA2Bx3PKScF1uXSV9K+kjSW0KKl9+TftpBDXPnWH+hrhtBjxQUObOOZcKhXj9KcPMOuWXVR7rcrewpwNNzGyTpDOB94Dm+R00v772zfLb0TnnioOAWOq6fy4BGsUtNwSWxScws41x30dKGiCpZvgGU54S6tkkqS3QGigbd4BXEyy4c84lJYUvP00BmktqRvBefB/gkhzHkuoCK83MJHUhuAW6Jr9MCwykku4FehAE0pFAT2AC4IHUOVfkpNTN2WRmmZL6AaOAGPCymc2R1DfcPhC4ELhRUiawFehjZvk+YE+kRnoh0B74xsyuklQHeCmJc3HOuUJJ5fv4ZjaSoFIYv25g3PfngecLk2cigXSrmWVLypRUGVgF+Av5hfTF19/xwPPvkZWVTe+zjqHvJSfn2P6/n1dy5z+GMOfHJdx6zZlc1/tEAJatWsftD79OxtpfSJPofXZXrrrwwBt86+hDqvPHU5sTk3j/2+X8Z/KiPdIc2bgqfzi1OelpYsPWHdz82jfUrlSGv/6mNTUqlCbbjBEzlvHWlCUlcAZFb8qMHxkw+EOys42eJ3Wkz7k5/w5Gj/+WN0eMB6Bc2dLccs05HNq0HgCbNm/lyX++x0+LVwFw+43n0bpF4+I9gSREva99IoF0qqSqwIsET/I3AV8XRWHC41xiZgPC5R7A7YV5MTaKsrKyue+ZYbzyWF/q1qrCeX2f4uRubWjetO6uNFUqleee35/HJxNm59g3PRbjrht70bZFQzZt+ZVeNzzFcZ1a5Nh3f5cmuP30lvzhjW9YtXEb/7qqE+N/XM1PGVt2palYJp3bz2jJrUNmsHLjNqqVLwVAVrbx3Gc/8sPKTZQvHePlqzrz9cK1OfY9EGRlZ/Pcy+/zj7uvpGaNyvT780C6dmpFk4a1d6WpW7saT9x7DZUqluPrb37g6RdH8NyDwcs2AwaPpFP75txz68XsyMxk27YdJXUq+yTicbTgF/LN7CYzWx9WfU8FrjCzq4qoPFWBm1KVmaRITO737fc/06R+TRrXr0HpUumcfdKRfDYxZ8CsWa0S7Vo1plR6zn+S2jUq07ZFQwAqli/LYY1rszJjQ7GVvTi0rl+ZJeu2sGz9r2RmG5/NXcXxzWvlSHNamzp8MW81KzduA2DdliAQrNm8nR9WbgJgy/YsFq3ZTK2KZYr3BIrBvPlLqF+nBvXqVKdUejo9uh3BpCk5B2Fr07IxlSqWA+Dw5o1YvSb4O9m85VdmffcTPU/qCECp9HQqVihXvCeQBEnE0hL7lJT8Jr87Kr9tZjY92YNLuhW4Olx8CTgGOFTSDOBTghf/K0oaCrQlqBFfFj5N6wg8CVQEMoArzWy5pLHAJOBYYATwRLLlTNbKjA3Uq11113LdWlX59rs9m64FWbJiLXPmL6X94U1SWLqSV6tSmV0BEmD1L9toXb9yjjSNqpcnPSaev/RIypeO8daUJXw8e0WONHWrlKV5nUrMWbaRA03G2o3UqlFl13LNGlX4fv7eb2F8PGYanTu0AGD5qnVUqVyBx/7fuyxYtJzmzRpw05VnUq5s6SIvd6rsz037/AKQASclc+AwEF5F0GdfwFfAZUBbM+sQpukBHAm0IXjXayJwrKSvgOeAXma2WlJv4EF2B+WqZnbCXo57PXA9QIOGxXOPKM8HfoX8w9i8dRs33TOYv958LpUqlC14h/2c5XpHOpYmWtatxC2vf0OZ9BiDrujInGUbWLx2KwDlSsV46Py2PPPZj2zZfuCNO57nn9Be0s6YvYCPPp/G0/dfBwS3ln5cuJybrzqLw5s34oXBH/Lm8HFc2fuUoitwiiXSl70k5fdC/olFfOzjgHd3TqgnaRhwfB7pvjazJWGaGUBTYD1BDfXT8JcqBiyP2+fNvR3UzAYBgwDaH9mxWMYMqFurKstXrd+1vGL1eurUqLz3HXLZkZnFzfcMptcpR3F693ZFUMKStfqXbdSpvLs5XqtSGTJ+2b5Hmg1bd/Drjmx+3ZHNjJ/Xc1jtiixeu5VYmnjogrZ8MmclX8xbXdzFLxa1alTe1VQHyFizgRrVKu2RbsGiFTw56D0e6n85lSuV37VvrRqVObx58B5696PbMGT4+OIpeAqI6NdISzLQJ3pltsV9zyII/gLmmFmH8HOEmZ0Wly5Ss522a9WIn5auZvHyNWzfkckHn3/Dyd3aJrSvmdH/0Tc5tEltrrmoR9EWtIR8t+wXGlYrT70qZUlPE6e0rs2EH3N2Ihn3w2raN6pCTKJMehptGlRm0ZrggdJdZ7Xip4wtDPl6cV7ZHxBaHtqApSvWsHzVOnZkZjJ20iy6dmqVI82qjPX87Yk3uPPmC2lYv+au9dWrVqJWjSosXhb8yHwzewFNGua8Bx11aUrsU1JK8mHMOGCwpEcIAuN5wBXAbQnsOw+oJamrmU2WVApoYWZziq64+y49FuPeW87nyjsGkZ2dzYU9u9CiWV1eHzEJgEt+043Vazdy7g1PsWnLr0hi8NBxfDz4TuYtWMZ7n06l5SH1OPvaxwG47dozOfGY1iV5SimVZcaTn/zAU306EEsTH3y7jIUZmzn3yPoAvPfNMhat2cKX/1vLq9d1wcLXnBas3ky7hlXoeUQ95q/axOBrOgPwz7ELmPy/fDui7HdisRj9rj6bPz/0CtnZ2Zze4yiaNqrD+58GL9Ccc2oX/jN0LBs3beHZf70f7pPGgIdvBODmq87i4eeGkpmZRb3a1bj9xvNL7FwKS0ppF9EioQJe2C/ag+d62GRmT0t6HWgHfETwsGnX60+SngemmtlgSR2AZ4EqBD8IT5vZi+HDptvNbGpBx29/ZEf7aMzkVJ/WAePsZyeUdBEi79k+R5Z0ESLv+JbVpxUwkEi+6jZva7976p2E0j5+TqukjrWvEukiKoKpRg4xs/slNQbqmlnS75Ka2ZMET97j112SK9nYuG394r7PII9poc2sR7Llcs5FS8RvkSZ0j3QA0BW4OFz+hWCEaeecK3IHyrz2R5vZUZK+ATCzdeG0zM45Vyz229ef4uwI5zkxAEm1gOwiLZVzzsWJetM+kUD6LPAuUFvSgwSjQf2lSEvlnHOhnV1EoyyRee3/K2kacDLB7Ypzzey7AnZzzrmUiXgcTeipfWNgC/B+/Doz+7koC+acc7D7YVOUJdK0/5Ddk+CVBZoRvBBf4Mx6zjmXChGPowkNo3eEmbUL/785wbzQ/qa2c654JNg9NNHmv6QzJM2TNF9S/3zSdZaUJenCgvIs9FsF4fB5nQu7n3PO7Ssl+L8C8wneQHqBYO651sDFkvbobx2m+wfB3E4FSuQe6a1xi2nAUcCBOcSOcy5yBKSn7kXSLsB8M1sAIGkI0AuYmyvd74F3SLDSmMg90vixujIJ7pkm1vHVOedSIIXD6DUA4ocJW0IwJnL8sRoQDKJ0EqkIpGH1tqKZ/alQRXXOuRQJntonnLympPgBiwaFYxDHZ5db7pGbngbuNLOsRAN4flONpIdzQO91yhHnnCtyKtRT+4wCRn9aAjSKW25IMPtGvE7AkDCI1gTOlJRpZu/tLdP8aqRfE9wPnSFpBPA2cQMmm9mwfPZ1zrmUSeF7pFOA5pKaAUuBPkCOEefMrNnO75IGAx/kF0QhsXuk1YE1BPcLdr5PaoAHUudckRMQS9HDprCV3Y/gaXwMeNnM5kjqG24fuC/55hdIa4dP7GezO4DuKs++HMw55wpPpCU8M1HBzGwkMDLXujwDqJldmUie+QXSGMFUx4ncnHXOuSIRTH5X0qXIX36BdLmZ3V9sJXHOubyU8MR2icgvkEa86M65g8X+PGjJycVWCuec24v9umlvZmuLsyDOObc3+/3Azs45V5LEgTFnk3POlRyltK99kfBA6pyLvGiHUQ+kzrmIO1CmGnHOuRIV7TDqgdQ5F3kizZ/aO+fcvvOn9s45lwL+1N4555IU7TB6kAdSM9iemV3SxYisz27rXtJFiLyGV7xa0kU48Pl7pM45lxwBMQ+kzjmXnGiHUQ+kzrn9QMQrpJF/q8A5d5ALXn9SQp+E8pPOkDRP0nxJ/fPY3kvSTEkzJE2VdFxBeXqN1DkXeamqkUqKAS8ApxJMzTxF0ggzmxuXbDQwwsxMUjvgLaBVfvl6jdQ5F3FK+H8J6ALMN7MFZrYdGAL0ik9gZpvMbOe8dBVIYI46r5E65yKtkE/ta0qaGrc8yMwGxS03ABbHLS8Bjt7jmNJ5wMNAbeCsgg7qgdQ5F20qVNM+w8w65Z/bHvaocZrZu8C7kroDDwCn5HdQb9o75yJPSuyTgCVAo7jlhsCyvSU2s3HAoZJq5pepB1LnXOSl8B7pFKC5pGaSSgN9gBE5jiUdprArlaSjgNLAmvwy9aa9cy7SgoGdU5OXmWVK6geMAmLAy2Y2R1LfcPtA4ALgckk7gK1A77iHT3nyQOqci7xUjpBvZiOBkbnWDYz7/g/gH4XJ0wOpcy7yEmy2lxgPpM65SEtl076oeCB1zkVcwg+SSowHUudctBXuPdIS4YHUORd5EY+jHkidc9HmAzs751wqRDuOeiB1zkWfP2xyzrkkRbxl74HUORd9EY+jHkidc/uBiEdSD6TOuUiTUtvXvih4IHXORV60w6gHUufc/iDikdQDqXMu4ryvvXPOJS3it0g9kDrnok1EP5D6nE3OuchL4ZxNSDpD0jxJ8yX1z2P7pZJmhp9JktoXlKfXSJ1zkZeqGqmkGPACcCrBjKJTJI0ws7lxyRYCJ5jZOkk9gUHA0fnl64G0mIyf8j0PDRhOdnY2F/Y8muv6nJRj+4KfV3HX428yd/4S/nhVT67+bY9d206+7EEqlCtDLC2NWCyNoQP+WLyFLyJjvvyOe54ZRna2cfHZx9DvdzmnDjcz7nlmGJ9P/o5yZUvx1F2XcETLYCbdQW+O5Y33v0SCVofU48m7LqFsmVLM/nEJ/R97m23bd5Aei/HQbRdyZOsmJXF6KXdy+wY8dMUxxNLEfz7/gWdGzMyx/fdnt+XC4w4FID2WRosGVWh+3eus37ydyuVL8+wNx9KqYbUg7cDxTPlxdbGfw75KYcu+CzDfzBYASBoC9AJ2BVIzmxSX/kuCKZvz5YG0GGRlZfPAc+/yr39cT52aVbio3zOc2LU1hzWpuytNlUrluPvmXoyeOCfPPF55/EaqValQXEUucllZ2dz95FDeeOpG6tWuypnXPslpx7WlRbPd1+TzL79j4eLVTBhyN9PnLOLPj7/NBy/eyvLV63l56DjGvNafcmVKc8NfBzN89HR6n3k0Dw54n1uvOp2TurZm9OS5PDhgBEOf/30JnmlqpEk8enVXzn9wFMvWbGb0Q7/h42k/M2/p+l1pnvtgNs99MBuA049qxI1ntmH95u0APHzF0YyesZQrnxpDqVga5crsR//pi8JE0pqSpsYtDzKzQXHLDYDFcctLyL+2eQ3wUUEH9XukxWDmvJ9pXL8GjerVoHSpdM7s0YHPJ+UMmDWqVeKIlo1JTz84/km++W4RTRvWpEmDmpQulU6vU45k1IRZOdKMGj+LC8/ojCQ6tm3Khk1bWZmxAYDMrGx+3baDzMwstm7bTt2aVYCgCfjLll8B+GXTVuqE6/d3HQ+rycIVG1m06hd2ZGUzbNICenZqvNf0Fxx7CMMmLQCgUrlSdDu8Lv8Z8wMAO7Ky2bhle7GUO1UKcY80w8w6xX0G7ZHVnvKcalnSiQSB9M6CyheZnyVJTYGPga+AI4EfgMuB24FzgHLAJOAGMzNJtwB9gUxgrpn1kXQC8EyYpQHdzeyXYj2RPKzK2EDdWlV3LdepWZWZ3y9KeH8Jruk/CAl6n9WVi846pghKWbxWrN5A/drVdi3Xq1WVb+bmvCYrMnKlqV2VFRkbaN+qMX37nEiXC/5G2TKlOKFzK07o0gqAv91yHpfcOpAHXhiBZRvDB/6heE6oiNWrXoGlazbvWl62djMdD6uVZ9pypWOc3L4hd7w8GYAmtSuRsfFXnr/xeNo2rs63CzP48ytfsWVbZrGUPVkpnvxuCdAobrkhsGyPY0rtgJeAnma2pqBMo1b9aUlQFW8HbARuAp43s85m1pYgmJ4dpu0PHBmm7Ruuux242cw6AMcDW4uz8HtjefzeqRB3z19/qh/D/t//MejBa3l9xESmzPxfCktXMhK5JnmmQazfuIVRE2bz5Vv3MP29+9ny6zbeGRW05l59byL33XIeU4fdx72/P5fbHh5SFMUvdnlWo/KsR8EZHRvz1byVu5r16THRvlkN/v3p9/T483C2bMvkj73aFV1hi4IS/BRsCtBcUjNJpYE+wIgch5IaA8OA35nZD4lkGrVAutjMJobfXwOOA06U9JWkWcBJQJtw+0zgv5IuI6iVAkwEngxrq1XNbI+fXEnXS5oqaeqaNcVzs71OrSqsWL1+1/LKjPXUrlE54f1rh83TGtUqccqxbZk1b3EBe0RfvdpVWLZq3a7l5avXU6dmzmtSr1auNKuCNOOn/kDjetWpUa0ipdJj9OzejqmzFgLw9kdTOPOEIEicc1IHZnyXeM0/ypat3UyDGrvvkdevXoEV67bkmfa8rofwTtisB1i2ZgvL1m5m2vzg7334Vz/RrmmNoi1wiqXq9acwJvQDRgHfAW+Z2RxJfSXtrJDdA9QABkiakeuea56iFkhz/8YaMAC40MyOAF4EyobbziJ4jaEjME1Supk9AlxLUHP9UlKrPQ5gNmjn/ZMaNfJuGqXaES0bsWhpBkuWr2H7jkxGjp3BiV3bFLwjsGXrNjaH9/y2bN3GxGk/0Lxp3QL2ir4OrRqzcHEGPy8Lrsnwz77htGPb5khz2nFtGfrxFMyMabN/onLFctSpWYUGdaoyfc4itv66HTNjwrQfad60DgB1alZm8jfzAZgw7UeaNSyef+OiNv1/GRxStwqNa1WkVCyN87sdwsfTft4jXaVypTi2dV0+mrp726oNW1m6ZjOH1Qt+qE5oWz/HQ6r9gZTYJxFmNtLMWpjZoWb2YLhuoJkNDL9fa2bVzKxD+OlUUJ6RuUcaaiypq5lNBi4GJgDdgAxJFYELgaGS0oBGZjZG0gTgEqCipBpmNguYJakr0Ar4vmROZbf0WIy/9DuPa//8ItnZxvmnd6Z507oMeT94y6LPOd1YvXYjv735GTZt+ZU0iVeHjeeDl/7Euo2b+f19g4HgAcvZJx7J8Z33+H3Y76Snx/j7rRdwya0Dyc7OpvdZR9PykHq8+l7QILn83GM5uWtrPp/8Hcf2/jvlypbmybsuBuCoNk0568T2nH7146TH0mjToiGX/qYbAI/d0Yd7nhlGZlY2ZUun8+gdvUvsHFMpK9u449+TGXrX6cTSxH/H/Mj3S9Zz5SktARj82TwAzu7ShDEzl+5x//POf3/JP/v1oHR6Gj+t+oV+A8cX+zkkI+Idm5Dt7UZLMQsfNo0ExhEEzx+B3wF3EdzH+IngtYVFwIPAGKAKwTV+zcwekfQccCKQRfBe2JVmtm1vx2zXoaON+Gzi3jYf9CqXi9rvbPQ0vOLVki5C5G1955ppidTq9qZt+6Ns2CcTEkrbsm6FpI61r6L2X0q2mfXNte4v4Se343KvMLP9/4VB51wOPrCzc86lQLTDaIQCqZn9BLQtKJ1z7iAU8UgamUDqnHN584GdnXMuaRG/ReqB1DkXbfvDwM4eSJ1zkedNe+ecS5LXSJ1zLkkRj6MeSJ1zEVeIfvQlxQOpc24/EO1I6oHUORdpKR7YuUh4IHXORZ437Z1zLkn++pNzziUr2nE0ciPkO+fcHlI3ZRNIOkPSPEnzJfXPY3srSZMlbZN0eyJ5eo3UORdphZlGpOC8FCOYouhUghlFp0gaYWZz45KtBW4Bzk00X6+ROuciT1JCnwR0Aeab2QIz2w4MAXrFJzCzVWY2BdiRaPk8kDrnIq8QTfuaO2cJDj/X58qqAcGURTstCdclxZv2zrnIK0TTPqOAOZvyyinpies8kDrnIi6lAzsvARrFLTcEliWbqTftnXORtnM80hTNaz8FaC6pmaTSBDMUj0i2jF4jdc5FXqqe2ptZpqR+wCggBrxsZnMk9Q23D5RUF5gKVAayJf0RaG1mG/eWrwdS51zkpbJnk5mNBEbmWjcw7vsKgiZ/wjyQOueizYfRc8655BSm11JJ8UDqnIu+iEdSD6TOucjz0Z+ccy5JPrCzc84lywOpc84lx5v2zjmXhJ09m6JMZkn3199vSVoNLCrpcsSpCWSUdCEizq9R/qJ4fZqYWa193VnSxwTnlYgMMztjX4+1rw7qQBo1kqYWMHLNQc+vUf78+pQMH7TEOeeS5IHUOeeS5IE0WgaVdAH2A36N8ufXpwT4PVLnnEuS10idcy5JHkidcy5JHkiLiKT7JN2ex/q+ki4Pv4+VtMerKvns21TS7KIpcTRIqirpprjlHpI+KMkyOVcQD6TFSFK6mQ00s1dLuiwRVhW4qaBEiZLkvfdckfNAmkKS7pY0T9JnQMtw3VhJD0n6AvhDHrXNyyRNkjRbUpe49e0lfS7pR0nX5XGsmKTHJE2RNFPSDUV7dkVD0q3huc8O58Z5BDhU0gxJj4XJKkoaKul7Sf+Vgg6DkjpK+kLSNEmjJNUL1+e45iVyYikWtka+l/RK+O89VFJ5SfeEfwOzJQ2Kuza3SJobph0SrjshvK4zJH0jqVLJntUBxMz8k4IP0BGYBZQnmDRrPnA7MBYYEJfuPuD28PtY4MXwe3dgdlyab4FyBF3jFgP1gaZxaa4H/hJ+L0MwWVezkr4O+3jNKgAVgTnAkTvPMUzTA9hAMIdOGjAZOA4oBUwCaoXpehNMZLbzug4o7vMp4mvVlGD+9WPD5ZfDv6/qcWn+A5wTfl8GlAm/Vw3///24/SsC6SV9XgfKx5s9qXM88K6ZbQGQFD/F65v57PcGgJmNk1RZUtVw/XAz2wpslTQG6ALMiNvvNKCdpAvD5SpAc2BhsidSjI4juGabASQNI7iOuX1tZkvCNDMIgsp6oC3waVgJiwHL4/bJ75rvrxab2cTw+2vALcBCSXcQ/IBXJ/gxeh+YCfxX0nvAe+E+E4EnJf0XGLbzmrrkeSBNrb29lLu5EPtYAet3EvB7MxuVYNmiKNExfbbFfc8i+LsVMMfMuu5ln/yu+f4qr7+JAUAnM1ss6T6gbLjtLIJWzm+Av0pqY2aPSPoQOBP4UtIpZvZ9MZX9gOb3SFNnHHCepHLhvadzEtyvN4Ck44ANZrYhXN9LUllJNQiat1Ny7TcKuFFSqXD/FpIqJHsSxWwccG54r68CcB5BrSmRe3fzgFqSugJIKiWpTdEVNRIa7zxf4GJgQvg9Q1JF4EIASWlAIzMbA9xB8ACvoqRDzWyWmf2D4FZQq2It/QHMa6QpYmbTJb1J0PxeBIxPcNd1kiYR3Fe9Om7918CHQGPgATNbJqlp3PaXCJq408MHDKuBc5M4hWIXXrPBBOcK8JKZTZM0MXzN6yOCa5DXvtvD2xrPSqpC8Lf8NEHT9kD1HXCFpH8CPwL/D6hGcJ/5J3b/2MaA18LrIuApM1sv6QFJJxLU6ucSXF+XAt5F1Ln9QPgj+oGZtS3psrg9edPeOeeS5DVS55xLktdInXMuSR5InXMuSR5InXMuSR5IXb4kZYV9s2dLeltS+STyGryzJ5aklyS1zidtD0nd9uEYP0naY8bJva3PlWZTIY+V5yhd7uDjgdQVZKuZdQhfu9kO9I3fKCm2L5ma2bVmNjefJD2AQgdS50qCB1JXGOOBw8La4hhJrwOz9jYSlQLPh6MQfQjU3pmR4sZilXSGpOmSvpU0Onxnsi/wf2Ft+HhJtSS9Ex5jiqRjw31rSPokHM3onyTQ7VTSewpGjJoj6fpc254IyzJaUq1w3aGSPg73GS/JewS5HLxnk0uIgnE9ewIfh6u6AG3NbGEYjDaYWWdJZYCJkj4hGMmpJXAEUIegN83LufKtBbwIdA/zqm5mayUNBDaZ2eNhutcJeuhMkNSYoIvs4cC9wAQzu1/SWQSjYhXk6vAY5YApkt4xszUEo1BNN7PbJN0T5t2PYEK5vmb2o6SjCfq3n7QPl9EdoDyQuoKUC0dcgqBG+i+CJvfXZrZzpKm9jUTVHXjDzLKAZZI+zyP/Y4BxO/Mys7V7KccpQOtwpCeAyuGYBt2B88N9P5S0LoFzukXSeeH3RmFZ1wDZ7B416jVgWNiHvRvwdtyxyyRwDHcQ8UDqCrLVzDrErwgDSvzoSnmORCXpTPY+Ilb8von0CkkDuoZDC+YuS8K9SiT1IAjKXc1si6Sx7B4xKTcLj7s+9zVwLp7fI3WpsLeRqMYBfcJ7qPWAE/PYdzJwgqRm4b7Vw/W/kHMUqE8ImtmE6TqEX8cBl4brehIM4pGfKsC6MIi2IqgR75RGOIIScAnBLYONBGN+/jY8hiS1L+AY7iDjgdSlwksE9z+nh6M2/ZOgtfMuwShFswhGKvoi945mtprgvuYwSd+yu2n9PsGwhDMkHU8wiHGn8GHWXHa/PfA3oLuk6QS3GH4uoKwfA+mSZgIPAF/GbdsMtJE0jeAe6P3h+kuBa8LyzQF6JXBN3EHE+9o751ySvEbqnHNJ8kDqnHNJ8kDqnHNJ8kDqnHNJ8kDqnHNJ8kDqnHNJ8kDqnHNJ+v+YD9NC1dWstQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(pipe_svm, X_test, y_test, cmap='Blues', normalize='true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_bin_test = label_binarize(y_test, classes = ['pass','dribble','other'])\n",
    "n_classes = y_bin_test.shape[1]\n",
    "\n",
    "y_score = pipe_svm.decision_function(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "lw = 2\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Team - End Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'end_pitch_zone')\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-end')\n",
    "\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "\n",
    "# define column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   6.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   4.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   9.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   7.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  11.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  11.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  11.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  15.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  15.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  14.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  12.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  15.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  18.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  19.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  19.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  19.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  12.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  15.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  18.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  13.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  16.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  18.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  24.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  26.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  14.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  15.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  16.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  15.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  15.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  18.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  22.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  23.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  24.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  27.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  28.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  26.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  25.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  25.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  15.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  16.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  16.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  20.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  22.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  22.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  23.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  24.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  26.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  26.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  28.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  30.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  31.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  30.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  28.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  28.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.4s\n",
      "[22:31:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  19.3s\n",
      "[22:31:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  20.1s\n",
      "[22:31:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  20.4s\n",
      "[22:32:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  20.8s\n",
      "[22:32:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  21.0s\n",
      "[22:32:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.0s\n",
      "[22:33:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.0s\n",
      "[22:33:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.5s\n",
      "[22:34:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.6s\n",
      "[22:34:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  29.8s\n",
      "[22:35:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  34.9s\n",
      "[22:35:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  35.2s\n",
      "[22:36:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  34.8s\n",
      "[22:37:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  35.5s\n",
      "[22:37:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[22:38:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  16.9s\n",
      "[22:38:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.5s\n",
      "[22:38:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.1s\n",
      "[22:39:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.1s\n",
      "[22:39:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.7s\n",
      "[22:39:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  25.7s\n",
      "[22:40:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.8s\n",
      "[22:40:36] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.5s\n",
      "[22:41:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.9s\n",
      "[22:41:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.9s\n",
      "[22:41:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  35.7s\n",
      "[22:42:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.2s\n",
      "[22:43:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.1s\n",
      "[22:43:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.6s\n",
      "[22:44:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.7s\n",
      "[22:45:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.1s\n",
      "[22:45:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.7s\n",
      "[22:45:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.4s\n",
      "[22:45:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.4s\n",
      "[22:46:16] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.4s\n",
      "[22:46:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  26.5s\n",
      "[22:47:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  27.9s\n",
      "[22:47:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  27.8s\n",
      "[22:47:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  28.1s\n",
      "[22:48:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  28.0s\n",
      "[22:48:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  36.2s\n",
      "[22:49:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  37.9s\n",
      "[22:50:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  37.6s\n",
      "[22:50:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  38.0s\n",
      "[22:51:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  37.9s\n",
      "[22:52:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  17.7s\n",
      "[22:52:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  20.2s\n",
      "[22:52:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  18.5s\n",
      "[22:52:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  18.7s\n",
      "[22:53:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  18.6s\n",
      "[22:53:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  27.5s\n",
      "[22:54:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  29.1s\n",
      "[22:54:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  28.3s\n",
      "[22:54:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  28.4s\n",
      "[22:55:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  28.8s\n",
      "[22:55:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  36.9s\n",
      "[22:56:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.3s\n",
      "[22:57:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.0s\n",
      "[22:57:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.3s\n",
      "[22:58:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.3s\n",
      "[22:59:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  18.1s\n",
      "[22:59:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  18.5s\n",
      "[22:59:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  17.7s\n",
      "[23:00:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  17.2s\n",
      "[23:00:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  17.1s\n",
      "[23:00:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  25.2s\n",
      "[23:01:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  27.9s\n",
      "[23:01:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  28.2s\n",
      "[23:01:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  27.9s\n",
      "[23:02:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  27.6s\n",
      "[23:02:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[23:03:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.3s\n",
      "[23:04:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.3s\n",
      "[23:04:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.5s\n",
      "[23:05:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[23:05:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  16.8s\n",
      "[23:06:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.3s\n",
      "[23:06:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.5s\n",
      "[23:06:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.3s\n",
      "[23:06:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.3s\n",
      "[23:07:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  24.8s\n",
      "[23:07:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.8s\n",
      "[23:08:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.6s\n",
      "[23:08:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.6s\n",
      "[23:08:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.5s\n",
      "[23:09:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  33.4s\n",
      "[23:09:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  34.4s\n",
      "[23:10:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  34.8s\n",
      "[23:11:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  35.1s\n",
      "[23:11:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  34.8s\n",
      "[23:12:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  16.4s\n",
      "[23:12:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  17.0s\n",
      "[23:12:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  16.8s\n",
      "[23:13:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  17.0s\n",
      "[23:13:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  17.1s\n",
      "[23:13:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  24.9s\n",
      "[23:14:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.8s\n",
      "[23:14:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.9s\n",
      "[23:14:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.9s\n",
      "[23:15:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.8s\n",
      "[23:15:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  33.8s\n",
      "[23:16:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  35.3s\n",
      "[23:16:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  34.5s\n",
      "[23:17:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  34.3s\n",
      "[23:18:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  34.0s\n",
      "[23:18:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  15.9s\n",
      "[23:18:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.5s\n",
      "[23:19:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.5s\n",
      "[23:19:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.6s\n",
      "[23:19:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.5s\n",
      "[23:20:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.0s\n",
      "[23:20:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.5s\n",
      "[23:20:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.9s\n",
      "[23:21:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  26.0s\n",
      "[23:21:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.8s\n",
      "[23:22:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  33.6s\n",
      "[23:22:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  34.8s\n",
      "[23:23:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  36.0s\n",
      "[23:23:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  34.1s\n",
      "[23:24:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  33.9s\n",
      "[23:25:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  15.8s\n",
      "[23:25:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.6s\n",
      "[23:25:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.7s\n",
      "[23:25:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.7s\n",
      "[23:26:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.7s\n",
      "[23:26:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  24.5s\n",
      "[23:26:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.8s\n",
      "[23:27:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.5s\n",
      "[23:27:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.6s\n",
      "[23:28:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.8s\n",
      "[23:28:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  33.8s\n",
      "[23:29:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  35.2s\n",
      "[23:29:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[23:30:16] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  35.4s\n",
      "[23:30:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  37.4s\n",
      "[23:31:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  18.6s\n",
      "[23:31:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  19.8s\n",
      "[23:32:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  20.0s\n",
      "[23:32:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  20.3s\n",
      "[23:32:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  19.9s\n",
      "[23:33:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  29.4s\n",
      "[23:33:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  30.2s\n",
      "[23:34:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  30.4s\n",
      "[23:34:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  31.3s\n",
      "[23:35:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  30.9s\n",
      "[23:35:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  40.2s\n",
      "[23:36:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  41.7s\n",
      "[23:37:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  37.9s\n",
      "[23:37:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  36.8s\n",
      "[23:38:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  36.9s\n",
      "[23:38:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  17.5s\n",
      "[23:39:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.2s\n",
      "[23:39:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.3s\n",
      "[23:39:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.1s\n",
      "[23:40:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.2s\n",
      "[23:40:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  26.2s\n",
      "[23:40:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.1s\n",
      "[23:41:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.3s\n",
      "[23:41:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.3s\n",
      "[23:42:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.2s\n",
      "[23:42:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  35.3s\n",
      "[23:43:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.5s\n",
      "[23:43:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.3s\n",
      "[23:44:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.8s\n",
      "[23:45:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.4s\n",
      "[23:45:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  16.8s\n",
      "[23:45:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.3s\n",
      "[23:46:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.3s\n",
      "[23:46:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.2s\n",
      "[23:46:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.2s\n",
      "[23:47:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  25.1s\n",
      "[23:47:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.3s\n",
      "[23:47:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.7s\n",
      "[23:48:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.6s\n",
      "[23:48:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.3s\n",
      "[23:49:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  35.6s\n",
      "[23:49:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  37.1s\n",
      "[23:50:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  37.7s\n",
      "[23:51:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  37.8s\n",
      "[23:51:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  38.2s\n",
      "[23:52:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid_end = [\n",
    "   \n",
    "     {\n",
    "        'model': [RandomForestClassifier(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(2, 17, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBClassifier(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0, 0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid_end = GridSearchCV(estimator, param_grid_end, cv = 5, verbose = 2)\n",
    "fitted_grid_end = grid_end.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>30.424726</td>\n",
       "      <td>0.650538</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.683054</td>\n",
       "      <td>0.684253</td>\n",
       "      <td>0.668665</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>0.693046</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>35.460561</td>\n",
       "      <td>1.165587</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.692246</td>\n",
       "      <td>0.685052</td>\n",
       "      <td>0.661871</td>\n",
       "      <td>0.667466</td>\n",
       "      <td>0.695444</td>\n",
       "      <td>0.680416</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>26.958471</td>\n",
       "      <td>0.399852</td>\n",
       "      <td>0.031620</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.681055</td>\n",
       "      <td>0.680256</td>\n",
       "      <td>0.668665</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>0.694644</td>\n",
       "      <td>0.679616</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>19.683138</td>\n",
       "      <td>0.586587</td>\n",
       "      <td>0.032026</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.677458</td>\n",
       "      <td>0.684652</td>\n",
       "      <td>0.667066</td>\n",
       "      <td>0.673062</td>\n",
       "      <td>0.692646</td>\n",
       "      <td>0.678977</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17.141578</td>\n",
       "      <td>0.201692</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.682254</td>\n",
       "      <td>0.687050</td>\n",
       "      <td>0.664668</td>\n",
       "      <td>0.674660</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.678897</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.209941</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>0.032672</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.397282</td>\n",
       "      <td>0.417666</td>\n",
       "      <td>0.354516</td>\n",
       "      <td>0.367306</td>\n",
       "      <td>0.378497</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.022287</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.213472</td>\n",
       "      <td>1.035617</td>\n",
       "      <td>0.034561</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.325739</td>\n",
       "      <td>0.365308</td>\n",
       "      <td>0.271783</td>\n",
       "      <td>0.306155</td>\n",
       "      <td>0.308953</td>\n",
       "      <td>0.315588</td>\n",
       "      <td>0.030420</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.338059</td>\n",
       "      <td>0.064258</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.324940</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.307754</td>\n",
       "      <td>0.314788</td>\n",
       "      <td>0.028941</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.997581</td>\n",
       "      <td>0.098873</td>\n",
       "      <td>0.038319</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.325739</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.272582</td>\n",
       "      <td>0.305356</td>\n",
       "      <td>0.306555</td>\n",
       "      <td>0.314468</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.683861</td>\n",
       "      <td>0.114062</td>\n",
       "      <td>0.041629</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.326139</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.271383</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.314149</td>\n",
       "      <td>0.029583</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "92      30.424726      0.650538         0.033494        0.001955   \n",
       "90      35.460561      1.165587         0.029699        0.001232   \n",
       "95      26.958471      0.399852         0.031620        0.001454   \n",
       "91      19.683138      0.586587         0.032026        0.001173   \n",
       "97      17.141578      0.201692         0.027977        0.001288   \n",
       "..            ...           ...              ...             ...   \n",
       "4        1.209941      0.013858         0.032672        0.000936   \n",
       "0        4.213472      1.035617         0.034561        0.003887   \n",
       "1        4.338059      0.064258         0.035688        0.000977   \n",
       "2        4.997581      0.098873         0.038319        0.001049   \n",
       "3        5.683861      0.114062         0.041629        0.001129   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "92  XGBClassifier(base_score=None, booster=None, c...                      3   \n",
       "90  XGBClassifier(base_score=None, booster=None, c...                      4   \n",
       "95  XGBClassifier(base_score=None, booster=None, c...                      3   \n",
       "91  XGBClassifier(base_score=None, booster=None, c...                      2   \n",
       "97  XGBClassifier(base_score=None, booster=None, c...                      2   \n",
       "..                                                ...                    ...   \n",
       "4   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "0   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "1   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "2   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "3   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "\n",
       "   param_model__max_features param_model__n_estimators param_model__eta  \\\n",
       "92                       NaN                       NaN              0.3   \n",
       "90                       NaN                       NaN              0.3   \n",
       "95                       NaN                       NaN              0.3   \n",
       "91                       NaN                       NaN              0.3   \n",
       "97                       NaN                       NaN              0.3   \n",
       "..                       ...                       ...              ...   \n",
       "4                       auto                        80              NaN   \n",
       "0                       None                        80              NaN   \n",
       "1                       None                       100              NaN   \n",
       "2                       None                       120              NaN   \n",
       "3                       None                       140              NaN   \n",
       "\n",
       "   param_model__gamma                                             params  \\\n",
       "92                0.1  {'model': XGBClassifier(base_score=None, boost...   \n",
       "90                  0  {'model': XGBClassifier(base_score=None, boost...   \n",
       "95                0.5  {'model': XGBClassifier(base_score=None, boost...   \n",
       "91                0.1  {'model': XGBClassifier(base_score=None, boost...   \n",
       "97                0.9  {'model': XGBClassifier(base_score=None, boost...   \n",
       "..                ...                                                ...   \n",
       "4                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "0                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "1                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "2                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "3                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "92           0.683054           0.684253           0.668665   \n",
       "90           0.692246           0.685052           0.661871   \n",
       "95           0.681055           0.680256           0.668665   \n",
       "91           0.677458           0.684652           0.667066   \n",
       "97           0.682254           0.687050           0.664668   \n",
       "..                ...                ...                ...   \n",
       "4            0.397282           0.417666           0.354516   \n",
       "0            0.325739           0.365308           0.271783   \n",
       "1            0.324940           0.362110           0.273381   \n",
       "2            0.325739           0.362110           0.272582   \n",
       "3            0.326139           0.361711           0.271383   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "92           0.673461           0.693046         0.680496        0.008574   \n",
       "90           0.667466           0.695444         0.680416        0.013408   \n",
       "95           0.673461           0.694644         0.679616        0.008788   \n",
       "91           0.673062           0.692646         0.678977        0.008924   \n",
       "97           0.674660           0.685851         0.678897        0.008325   \n",
       "..                ...                ...              ...             ...   \n",
       "4            0.367306           0.378497         0.383054        0.022287   \n",
       "0            0.306155           0.308953         0.315588        0.030420   \n",
       "1            0.305755           0.307754         0.314788        0.028941   \n",
       "2            0.305356           0.306555         0.314468        0.029315   \n",
       "3            0.305755           0.305755         0.314149        0.029583   \n",
       "\n",
       "    rank_test_score  \n",
       "92                1  \n",
       "90                2  \n",
       "95                3  \n",
       "91                4  \n",
       "97                5  \n",
       "..              ...  \n",
       "4                96  \n",
       "0                97  \n",
       "1                98  \n",
       "2                99  \n",
       "3               100  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results_end = pd.DataFrame(fitted_grid_end.cv_results_)\n",
    "grid_search_results_end.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Check for class imbalance for end zone in the prior notebook```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL VAEP MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'vaep_value')\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-vaep')\n",
    "\n",
    "# define column transformed for pipeline\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer for GridSearchCV\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Regressor - Depth 8 ***\n",
      "XGB Regressor Train Score:  0.8406537986332749\n",
      "XGB Regressor Test Score:  0.7623045325905606\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Regressor - Depth 8 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=8, gamma=0.01, reg_alpha=1.1, eta=0.1))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type_name_shot</td>\n",
       "      <td>0.457126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_name_success</td>\n",
       "      <td>0.134707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type_name_cross</td>\n",
       "      <td>0.043451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_name_shot_freekick</td>\n",
       "      <td>0.023027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>end_x</td>\n",
       "      <td>0.017588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Variable  Importance\n",
       "0           type_name_shot    0.457126\n",
       "1      result_name_success    0.134707\n",
       "2          type_name_cross    0.043451\n",
       "3  type_name_shot_freekick    0.023027\n",
       "4                    end_x    0.017588"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL xT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_xt_train_df, modeling_xt_test_df, 'xT_value')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-xt')\n",
    "\n",
    "# pipeline column transformer\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define gridsearch column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Regressor - Depth 5 Optimised ***\n",
      "XGB Regressor Train Score:  0.9265065158190492\n",
      "XGB Regressor Test Score:  0.8085949010492468\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Regressor - Depth 5 Optimised ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5, reg_lambda=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type_name_cross</td>\n",
       "      <td>0.230911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>end_pitch_zone_zone_8</td>\n",
       "      <td>0.100993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start_pitch_zone_zone_8</td>\n",
       "      <td>0.063345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x_dif</td>\n",
       "      <td>0.046887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>end_x</td>\n",
       "      <td>0.044581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Variable  Importance\n",
       "0          type_name_cross    0.230911\n",
       "1    end_pitch_zone_zone_8    0.100993\n",
       "2  start_pitch_zone_zone_8    0.063345\n",
       "3                    x_dif    0.046887\n",
       "4                    end_x    0.044581"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL NEXT ACTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'type_name_encoded')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-action')\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Classifier ***\n",
      "[14:23:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Train Score:  0.872501998401279\n",
      "XGB Test Score:  0.8036798612062275\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Classifier ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBClassifier(max_depth=3, eta=0.3, gamma=0.01))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214789707522385"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pipe.predict_proba(X_test), multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     dribble       0.80      0.91      0.85      8378\n",
      "       other       0.74      0.63      0.69      4117\n",
      "        pass       0.83      0.79      0.81      9408\n",
      "\n",
      "    accuracy                           0.80     21903\n",
      "   macro avg       0.79      0.78      0.78     21903\n",
      "weighted avg       0.80      0.80      0.80     21903\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', normalize='true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-1_type_name_encoded_dribble</td>\n",
       "      <td>0.199941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-1_same_team_False</td>\n",
       "      <td>0.150945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-1_type_name_encoded_pass</td>\n",
       "      <td>0.043632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-1_result_name_success</td>\n",
       "      <td>0.040079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-2_type_name_encoded_dribble</td>\n",
       "      <td>0.030164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Variable  Importance\n",
       "0  n-1_type_name_encoded_dribble    0.199941\n",
       "1            n-1_same_team_False    0.150945\n",
       "2     n-1_type_name_encoded_pass    0.043632\n",
       "3        n-1_result_name_success    0.040079\n",
       "4  n-2_type_name_encoded_dribble    0.030164"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_bin_test = label_binarize(y_test, classes = ['pass','dribble','other'])\n",
    "n_classes = y_bin_test.shape[1]\n",
    "\n",
    "y_score = pipe.predict_proba(X_test)\n",
    "# y_score = pipe_svm.predict_proba(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "lw = 2\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL END ZONE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'end_pitch_zone')\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-end')\n",
    "\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "\n",
    "# define column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Classifier ***\n",
      "[14:23:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Train Score:  0.8621902478017586\n",
      "XGB Test Score:  0.7228690133771629\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Classifier ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBClassifier(max_depth=3, eta=0.3, gamma=0.01))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_end = pipe.predict(X_test)\n",
    "y_proba_end = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625525120169188"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_proba_end, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      zone_1       0.69      0.63      0.66      1589\n",
      "      zone_2       0.64      0.70      0.67      2231\n",
      "      zone_3       0.69      0.67      0.68      1730\n",
      "      zone_4       0.74      0.76      0.75      3383\n",
      "      zone_5       0.65      0.57      0.61      2486\n",
      "      zone_6       0.72      0.76      0.74      3441\n",
      "      zone_7       0.78      0.78      0.78      2293\n",
      "      zone_8       0.79      0.73      0.76      2213\n",
      "      zone_9       0.78      0.81      0.80      2537\n",
      "\n",
      "    accuracy                           0.72     21903\n",
      "   macro avg       0.72      0.71      0.72     21903\n",
      "weighted avg       0.72      0.72      0.72     21903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', normalize='true', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEWCAYAAAAgpUMxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACZCElEQVR4nOydd3gU1feH37ubkBASkhA6odd0elMpUqQpVRALAooKClhAwK+gYldsCPaCCgqKgugPG0Wa9CodBFIoIZBK+u6e3x+z2ewmm0pCSJj3efbJzsydO2cms3Pm3nvu+SgRQUdHR0dH51pjKGsDdHR0dHRuTHQHpKOjo6NTJugOSEdHR0enTNAdkI6Ojo5OmaA7IB0dHR2dMkF3QDo6Ojo6ZYLugK4xSqnflFL3l8FxX1JKXVJKXbjWx3aGUuoWpdSxsrbjekApdUUp1eQaH1OUUs2u5TFLi+L+pirCPaiU6qGUispnewPr/WW8mnpKi2I7IKXUzUqpf5RSCUqpWKXUFqVUh5I07lqilDqjlOpd2scRkf4i8lVpH8cepVR94CkgUERqO9neQyllsd6oSUqpY0qpcaVpk4hsEpGWpXmM6xGl1N9KqQft14mIp4icKiubypKS+N0V9jeV0+kW9x5USj2vlFpc1P2uBTmvp4hEWO8vc1nalRfFckBKqarAr8D7QDWgHvACkF5ypumUIA2ByyJyMZ8y50TEE6gKPAF8qpQqdw5CKeVyIx67rCjj662UUnovTnlGRIr8AdoD8flsNwDPAuHAReBrwNu6rREgwDggEogDHgE6AAeAeGBBjvrGA0esZf8AGuZz7M7AP9Z69gM9rOu7ApeA+tblMGuZVsA3gAVIBa4AT+dXl3Xb38CLwBYgCfgTqG7d5g4sBi5b990J1LLb78EiXKf7gQir7f/L57y9rfvHWOt71lp/b+t5WazntsjJvj2AqBzrLgJ32tk5E/jPek7fA9Xsyt5sd50igbHW9W7APKv90cBHQOWcx7TWvTzH8d8D5tud2+fAeeAs8BJgtG4ba/0fvAPEAi85OT834F3gnPXzLuBmbwfwjPUanwHuybFvvucAzAAuoN1HvmgvZzFo9+uvgL+1/MuAGUiz/i8WWNcL0Mz6fRGwEPg/tPtqO9DUzp6+wDEgAfgA2ID1fnJy3kbref1nrWs32fe/oP3uTljtXAgo67amwDrr//oSsATwsav3jPWcD6C9dLqQfX8kAYeBoTlsmYD2G87a3pbi/+5etv7PU4FmOP6mmlmvSYLV9mXW9Rut55xsPdYoctz3QH3gJ+v/7jI5nkPWMv2ADCDTWs9+6/q6wCq0e/AkMCGf3+oi6//uN2sdW4DaaPdlHHAUaGNX3nZ/2O3/kpPfUa7rSfZzxMVaphrwJdrvIA5Y6ewZkN//M59rrNB+hxet2w4Awfn6kmI6oKrWf9BXQH/A14nDOAk0ATyt/9RvcjxYP0J7UPdF+0GuBGqitaYuAt2t5YdY6wpAu9GfBf7Jw656VrsGoD00+1iXa9g9ANYBla0X57EcP6reRajrb+s/qIW1vr+B16zbHgZ+ATzQHgLtgKpOHFBhrtOn1vrD0H7sAXmc+9fAz4CXdd/jwAN5OZi8HJD1XO9Au5HbWNc9DmwD/NEeyB8D31m3NUC7SUcDroAf0Nq67V20H2U1q12/AK86OWZDIMXuGhnRnE1n6/JK6zGroN0jO4CH7RyQCZiMdn9UdnJ+c6321wRqoD3cXrSzwwS8bT237mgPqZaFPAcT8Lp138rW8x9u/d97AT9g/ZHn/P87e8CgPVxigY7W81kCLLVuqw4kAsOs26aiPQjzckDTgX+BlmgPhzDAz+6YvwI+1v9hDNDP7gHTx3pONdAe3u/m+K3sQ3tgZznjO9Eewga0h3syUMdu21m0l0xlrb/hVfzuIoAg6zVwxfE39R3wP+u+7sDN+TzIe5B9DxrRnN07aPeZw745ruvzwOIc6zagORV3oLX1evbKxwFdQnsuuKM9k04DY6x2vASsL6oDyuN6NsLRAf0fsAztRcmV7Odsznry+386vcbAbWgvOT7W/3NA1j4l6oCsBwuwXogotB/hKrLf8tcCk+zKtkT7objYXZB6dtsvA6Psln8EHrd+/w3rg9TuAZmCk1YQ2lvZNznW/QHcb/3uar1A/wK/Y33jy+MfV1BdfwPP2m2bBPxu/T4e7SEX6sTGv8n+sRTmOvnbbd8B3OWkTiOacwq0W/cw8Lezm8vJ/j3QHE68tR5z1vW3bj+C3Y8JqGNn5yxghZM6FdpNa//23gU4nccNvxkYY/3eB/jP+r2W1abKdmVHY/2BojmgiALu1f+AAXbLtwFn7OwwAVXstn8PzC7kOWQA7vkcuzUQ5+z/b7cupwP6zG7bAOCo9fsYYGuOaxyZsz677ceAwXlsExwfzt8DM/MoOwTYm+O3Mr6Aa74v69hov5upeZQ7Q9F/d3Pz+U19DXyC3e/G2XXOeQ9a/68xWB/UBZzb89g5IDRHbAa87Na9ipPeBrv/8ad2y5OBI3bLIdj1MDmxexHFcEBov1sLORoMzuop4P/p9BoDt6K9+HYGDAVdRxEpfhCCiBwRkbEi4g8Eo3nLd62b66J1A2URbr0AtezWRdt9T3Wy7Gn93hB4TykVr5SKR3s7VGhvSjlpCNyZVdZa/ma0C4+IZKL984KBt8R61fIg37qs2EeUpdjZ/A3aj2apUuqcUuoNpZSrk2MU5jrldQx7qgOVnNTl7BrlxTkR8UFr3c5Hu5myaAissLsOR9B+cLXQfnz/OamvBlorYLfdfr9b1zvjWzTHAnC3dTnr2K7Aebt6PkZrzWQRWcC5ObvOde2W40Qk2cn2wpxDjIikZS0opTyUUh8rpcKVUolorQefgqKQcpDX/7wududqvX/zi1zK63+T73GUUjWVUkuVUmet57AY7R6zx+GaK6XGKKX22V2nYLt9CrLDnsL87vL7fz+N9nzYoZQ6pJQaX8jj1gfCRcRUyPL21AViRSTJbl1Bv7/CPv9KkvpodsYVVLCA/6fTaywi64AFaN250UqpT6zxAnlSIgN4InKU7Ac7aP2LDe2KNEB7y4ym6ESidbf42H0qi8g/eZT9JkfZKiLyGoBSqh7wHFof6FtKKTf70yhKXfkhIpki8oKIBKKNPQ1Ce3vNSUldp0toLZKcdZ0tYj2ISDraW2iIUmqIdXUk0D/HtXAXkbPWbU3zsCkVCLLbx1u0QAdn/AD0UEr5A0PJdkCRaC2g6nb1VBWRIHuzCzgtZ9f5nN2yr1KqipPthTmHnMd+Cq0l20lEqgLdrOtVIW3Nj/No3aBahUop+2Un5PW/KYhX0ewMtZ7DvWTbn4XtPJRSDdG6ih9D6+LzAQ7a7ZOfHcX53eV5DUXkgohMEJG6aL0AHxQy3DwSaFDIoIqcxz8HVFNKedmtK9bvLw9S0F6EssgVyZqPbfZEotnpk9/BCvp/5neNRWS+iLRD6yJtgdYNnCfFjYJrpZR6yvqwyArzHY3Wzw5aH+ETSqnGSilP4BW0garivF18BMxSSgVZj+WtlLozj7KLgduVUrcppYxKKXdriLG/9ce6CG0w+wG0H/OLdvtGo43FFFhXQQYrpXoqpUKsb72JaM7BWRhkiVwn0UIsvwdeVkp5WW+gJ63nUGREJAN4C5hjXfWRte6GAEqpGkqpwdZtS4DeSqmRSikXpZSfUqq1iFjQbuJ3lFI1rfvVU0rdlscxY9C6Ur5E6+I6Yl1/Hi3A4y2lVFWllEEp1VQp1b0Ip/Qd8KzV7urW88p5bV5QSlVSSt2C9sLwQ1HPwYoXmtOKV0pVQ3vhsSfnfVYU/g/ri4H1Qfko+T+MPgNeVEo1t0aMhSql/ApxHC+0Qex460tbvg8RtDETQevCQmkh/MF22z8Dpiml2lntaJZ1L1GCvzvrse+0KxtntSvrt5fftd+B9kx4TSlVxXrcm/IoGw00UtYIPBGJROtyf9W6XyjaM2ZJYWwuBPuAu63Xox/aOGVe5HmO1t/Sb2gOw1cp5aqU6uakaL7/z7yusVKqg1Kqk9J6e5LRxvbzDf8ubgsoCegEbFdKJaM5noNob38AX6B1Q21EG1xLQ+vnLDIisgJtkHep0roDDqIFPjgrGwkMRov8iUHz+NPRznMKWpfRbGvXxThgnPWBA9pb37PWJue0AuoqiNrAcjTncwRtgNKZMyix62TdLxk4hTae8q21/uLyBdob4e1oEWmrgD+VUklo/+9OoM0zQBuneAqte3Qf2mA3aC2pk8A26/9uDVrrIC++RYva+zbH+jFoXYyH0W745Th2yRTES8AutMCTf4E91nVZXLDWew7tofGItVVfnHN4Fy0Y4RLadfo9x/b3gBFKqTil1PwinAMicgltcPgNtHHTQOt55TX94W20F5M/0e7Fz622FcQLaFFqCWhO76cC7DqM9sKyFe0BGIIW2ZW1/Qe0AKBv0Z4dK9GCOqBkf3egBTpsV0pdQbtnp4rIaeu254GvrMcameMczMDtaAESEWhdm6PyOMYP1r+XlVJ7rN9Ho423nANWAM+JyF+FtLkgplptiwfuQbt+eeFwPZ1svw/thfgoWrDX4zkLFPT/JO9rXBXthS0OrQvyMloEaZ5khV3q6NyQKKV6oA0oF+oN+3rC+gYehRY2vr6s7dHRKSr6JC4dnXKEtWvKR2njl8+g9ctvK2A3HZ3rEt0B6eiUL7qgRZRdQuuWGSIiqWVrko5O8dC74HR0dHR0ygS9BaSjo6OjUyaUu+SJ1atXl0aNGpW1GTo6Ojrlit27d18SkbwmgpcJ5c4BNWrUiF27dpW1GTo6OjrlCqVUeMGlri16F5yOjo6OTpmgOyAdHR0dnTJBd0A6Ojo6OmWC7oB0dHR0dMoE3QHp6Ojo6JQJugPS0dHR0SkTSi0MWyn1BVpa+4siEuxku0LLDDwATe9irIjsyVlOR6dCYBHItIDZon1XCqo40ygEYlIgxQQiWqL7mh5Oy0qmGU7EWUVaABcDtNSSTIsIMTEpmM0WzGbBcvQyDbzds3eu6wn1NPma+Pg0Lly4kqVqiU9kEnV87JJmt64JlTQ9vRMnLpOaatLKJmbQ3KLwcLc+RnzcbMdPTs7g6NFLZCVa8biQTKCfneRSS1+oph3j1Kk4oqOvaHanm2mSlEltP6v8TSUjtM9WnNi4Mdx2fkSn0L2end6Zf1VoqC2fPZvI0aOXsk83Jo0Af7uyHeqAm3ZOW7dGkphoTSiemEFnT3e8PStpy77uEKzpsCUmprN1a7YWntfFFLo28M2uM6g6VNfO6eDBi0RFJWrrMy0EpZqoX9MqI+VqhJuytep+//1kdh0Xkrmtvjfa4xFo5A1NfACIjEzg4MGL2ad7MZUQf+/sfW+qB9b/xZYtEdnnlJBO18r20mfXD6WWiseqM3EF+DoPBzQATUJgAFpq//dEpFNB9bZv3170eUA3HiazYLI42XAxGWLTITFde7A384Hq2sMrNd1EQrKJy4mZmK6Y8Fp3hsppJuToZSSkBnJ/KxSpmEyZbN8ehcWUgSEjATkdS5uENCyYsKCIa1sTFVQdEM6ei+fk8VjMYsBiEmqfjqdJFXcwWEjycEW6ZT0ELOzbd4GUKxkIFlSGiTbpgqcClIUMHxfSW2gPpCtJqRw4EA0IiOClhDCEyl5JiMWAsYkbYnUeEWfiuXQ5lSzdsYYGhZ8CJQJGhWpaFWUyIRbh8KEYQGEyGUEUzQ0GMi1GLBagaiXwdkMhJCWmE3s5haxnnqdB2bQSQDDWcMdg0GRdoqNTyMzMlnipYYBKWbJzbi7gqz3oMjLMxMSkoJSgABeDojrKZjfe7lDZiEK4HJfMlSupZOnXeSlFZWvfjFIKqmU7zovWOm3HVwqFaLtWdsFQxYARE2npJpKTM2yKeO5K4WE9QYVAVTcwaLslJKVjMZtBrMc32L2ZVzKgrM7fbLKQmJRu6zYyKKiqFLY3gMqu4KJQQEqqiUyTCQW4GjKphAHbK4RSKM/sd/+kpAyyEbs60ZyV1VFmZphJT8+WCnM1gJtdJ5bycLH1aaUmZ2K2e7ZXMgtjX9m6W0Tacx1Rai0gEdmolGqUT5HBaM5J0LRWfJRSdayiSTqlRIZJOHs5+wESl2zBYsH28MkiIcVCSrpQKa87RAAxYTRdwGiJwdUYR0J6Ei7mBMwGyMCMATOu6ZcRFxcUZgymNLy9zpGc7oKbpBBrqEclQyrJ4ovRkI4LGRiUhfrVD5Gc4kP1auG4uqSRlFEdg7KglBmlLBgwYSAThQkjGRh8M1HVBP96ESQmVUVSFUpZcFFC9SpQw1NQyoJqJdoDUQlubhkOp9NyWCEvYBh5qFHl5u7OhawTYGTBRXR0isN778H8z8raCueUZSaEejhqu0dZ1+VyQEqph4CHABo0aHBNjCtvWES4kiqkZwomM1xKMnMp0cK24+lEx1tITi+4pevhFkfzOltxc0nFxZhOwxr7SEmrglFlYjRk4l3lItWrRtK07l6SUnzx8ihQWv6aU9Urscj7ZGS4Yt8RoH1XKIXWWrCty95mvy57v5zrc5fLq0xWw8C2WhTV/K5wMboqqamVnNqdVZfzjcXYVMAtku/x8t0vv41anWZyP4zyNSe/88t3x+xzKErnT/7nkN/qrFafyrmhWOcnYLtmhd3N2zOdw4cv53e0MqMsHZCzq+j0sovIJ8AnoHXBlaZR1zsiwtZjGWw8lM6ZGBONarjwX7SjgncVt1gqV0rCxZiOr+c5mtTOoI7vcQL8N1C1cgxKCfWrHyQlzQujwYRBmXF1zcjjiM7J6Xzi473x8UkgIqI+FosBEeX04+JiwsXFxMWLNXNsc9zH3T2Vc+fq4uJi5vx5NzIyDNpYhgUsFsHNrTKxsfFcvHgJk8nMxYuXSExIIi1diL8MfhbAbMFiFjBZEAtkJKciJgtY0D5myEiDI2TSG+2GNFg/KsffnOtAEYUQ6l4JLwO4Z5ihkguVqrgR4O6C0QBisVDTGI/RFVx8tV4vv0rgJmA0g6prrTAdTYezst3BqmgHqqkSsw+M9tciYBaFuCkqVbZgutwAY+VEyKiKCgrRdlQGfv/jPywWhSiFMgn9cMHg6QYuRmjoA419QBk4E55AbMRB9kc1wmRxoaUy0M3LQzuYAENaQpVKgIFl3x8m+mIKIlBJMhjq7kNtc00QAzT1g1FBoIxERcXzzItHsIgCFA0z4eXaPtaHp4IJYRBWC1B8/vle/lp7WltvEh4QF/rUqKod29sN3rxVa6JXqkbv277HknWfXExjXfPaGJT14oxqBXcHAvDrr8d5551smaQBiSaeqmc3XvN5P/DTxmsee2w1J07EausT0nnfqwotPK1jJu1qw7NdAG3867HHfrNV0Swhg4X1sjsrmdlJG1sC5s/fzurVJ7T1mRYmp8HAOtbxGm837fhW+vWzE0u+kMxvzWpljwGNaKmdF/DbbyeYP39H9n6JJqban9OHfcCvMpGRkYwZ8zru7prdJKbz5y0p9N5QXLHl0qNU5RisXXC/5jEG9DHwt4h8Z10+BvQoqAvuRh0Dikk08/P2VHacSMOvagRVK8fQoMZ+WtbdQqOae0lOq0bDmvtL5FhJSZ78919TLBYD7u5pnDtXi+TkdEwmhQhERflx+bIHCQnupKUZ8PWtwalTp7BYLFgsBowWX1wssdSs4k1m5Dk8zUmYzRn4pqVS68IF3NLTMYvQUASDCEbr31zfLRZcLBYMaFq/XoCR7Ge0wbocjy+CEcGASyUjJoORGmlRnKzSikspilYSwWbXMOp4ulDHx4SreyKV3BWE1sLdkAktahJ1chepmW40rhNOnKUadatVwuBiAWUBt0hwtTtgJYoVP2qu0gyj0RUMLqBcIPU8VG2JqdrNJFyxYMREplcbDF4N8ateFQyu2se9NigjKCOZJkApjEYDBkPxWiQ6FROTycT8+fOZM2cOycnJbNy4kVtuucW2XSl144wBFYJVwGNKqaVoQQgJN/b4TwaaxtgptA4JExmmDPaeOkrEpUT8/Q4RVB8e7POD072rV43MtS4mphoiRry8kjh9ujGVK6dy7lw9Tp5sRmpqZZKSPDGZXLBYjBw/forw8ChrK8OHKqoSVy6aOHnyHG7KkyhLS+AmtCdwE5pxhm78QyUsNOcgj7Cfxpwt9NnG44NyMeJtusxlv+Ycc6mPIS0ed0Mm++q0p0tgLRrXc0P5VUU1qIehsgHVqCEpZgObjqbgWtkNo3slPOrWoENHfzCnQfQGyIiD+P3gUoVml7bRLCUKpCGDEv5xYsW/tm9N7Xp2qxR0Hi5e0OBO8PDXHIQpGSrXg0q+oAw2Z2H7VGsDHv4Y86oO8CvkdXN13hunc4Ozfft2Hn74Yfbv115Chw8fTpMmTcrYqoIpzSi474AeQHUgGngO7T0SEfnIGoa9AOiHFoY9TkQKbNpUnBaQAMuAmVgs5zAYMou0d2SkJ15emcTF1eH8+bqcOtWExMSqJCd7kJJi7b+xw2QycykmlfqXM8iMukJKfAPWXWxMej1/Ll3yJTa2Eenp2c15b+LxJ4q6nCOAI1Qig0H8SlUSacO+Au2zVHIjrWkA+0L74tagNpXq1MQrtBWNugSAh0fhT1QsELcfrvwHF9aA0QMkEywmiNsHGZe1beIsRM4Jbn5gcAPPplCtHbh6gbK2SjITwa+Dtt2jntZKUS7aNqMHVK6TO1pDR6cMiYuL45lnnuHjjz9GRGjUqBELFixg4MCBucreUC0gERldwHYBHi2t419/bAEexWIRDIYDDlsMdt05CQmQnAxRUZ54ePhQqVJlqlZNJDy8IRkZbsTE1OD48Rakp7uTkxqXFL4mI4YGrjQLbInR6MLDD+/n3DkvtPeApjQytOSMxRuFhSokExx7kOm8zWX86M4GGnEGX+ILfVaWu+/G0KoVpKVB27bQvj00aIBBKTyArkW9TOmXIfEYJB6BM99C9Lqi7e/XCao00BySb2utZeTbBrwDwKMBuHoW1SIdneuWF154gY8++ggXFxemTZvG7Nmz8SjKC14ZU+70gMoXZszmX4iPH4OfXxLg6GwAUlPhf/+DpUs96N53HE3r++Hq4nyAoRLpuKl0XMwmok5eIjrFm2P/uTKqdh2e3mMi3OLFTlNNfmnQkWmHtNZMZXoyg/kEsYPW7MPdkkZzTjqt3ylt2kBkJAQEQGio5mgGDYKuXaFmzeKl0hALxB+AjAStVXNxA1zakn8rpkojcK8FHvWh5i3WlokrWDLBJxiqBoBbdb2FolPhMZlMuLhoj+5nn32W06dP8/LLLxMcnGuo/bqnVIMQSoPrtwsuE61HcTuwjLQ0hbt77mv7wguwYgVcTGhEq64P0szfh/pVE7CYcnfBuZPKLcZ/CHPfTZU9feGDd8GnIQsX7rBG47gBIXi6deVKug/VuUQwB2nCKZ7lJRpzpnCmh4VB1apw111gNGrOJjAQqlcv9tVwwJQCMVu01syV0xCxrOB9at2qOaTqnaDlE1C5VsnYoqNTTklLS+P1119n5cqVbN++nUqVijYgeEN1wd04rAdeADY4rM1yPleuwI4d8MGHlbji8y6+Xu7cOroa3mn7ABNwCYtdFHUrl8M0zjzE6z+F8EXyLXgn+gMjyRADO3+owlu/wc8/d6A1rvRkPf14j5D0B6nDhfzN7NULOnWCBg2gdWto3hyqVct/n6JiToPkSEiLhgt/gjkVjszLu7xnM/BsAqYkaHwf1O4LleuCS+W899HRuQFZu3YtEydO5MQJLbT7jz/+4Pbbby9jq64e3QEVm4NASK61u3bBxx/D+vVw8y0PkNniKWq7nCEkeAdgzeOUFmErX4l06hrPcSykBd9NtnAmMgDQ5jLc0jeI/Rtqsig9AICaD0WzgVb8xLH8TatRA/z8YMwYGDsW6tS5+tN1RmYinF0NB1+AxKMFl/eor43RNHtIa9m4Vi14Hx2dG5jo6GieeuoplixZAkBAQAAffvgh3bt3L2PLSgbdARWZL4AHHNaYzfDOOzB3Lnh7+zN8+HB++usVPl+xh2pJ32sR1na0MB7DVWXS1XULUUmjaDnnS6qYFf835xRENkKLkDMy/c9M3uIpBhPBQP4PVxwnnAIwdCg0bgyDB2vjNV5epXTewJUzcHwBnFmstXLyo3ZvSLsITR8Ar5ZQp68+PqOjUwQWL17M5MmTiY+Px93dnTlz5vDUU08VuevtekZ3QIXmCDAObYwnm169YN06mDZtGufOPcfJ0+dY/NsRVnz9JvYdXEaXTB6t9AG+Bi2DwM/pL1DnnS5sT27F8M+EqAsKaAII97GYr7nfuRm1a8Pjj8OkSaXrbECb35L0n9bCSToB8f/mLmP0AO8gaDRaczZ6q0ZHp0SwWCzEx8fTr18/Fi5cWC7m9RQV3QHliwWYjxZc8J/Dlp494Z9/XGnSpCkbNnxMWloab731FqDN2M/CrbIXgyxfEux60Lbu+P5V3PR/0Yy80oPlGc0gCRQW7uZbPuNB3El3NOOOO7TutO7dSy4wwBkWM5z+GuL2wn+faWM4zqjZTQsMqDsAjBXnbUxHpyy5cuUKW7dupU+fPgDcd9991K1bl169emWn5qlg6A4oT54C3s61dtQo+P57WL16NT169GDhwoWsX7/eoYzJUJW6vk0Y1fAXqh3/nKwp8IvODGDcgtfIOXY0g9d4jVmOB7r5ZnjlFbBLpVFqxO6Gf+7T5t44wzsIks9Ap8/BfzAYc89B0tHRKT4rV65k8uTJxMTEcPDgQZo1a4ZSit69e5e1aaWK7oCcciew3LaUlAR33w379vmzdu1ali5tzm+//cYbb7zhsFdqpYYkVOlG/SoRTIzvCcchw+TKB/9MYvb+Z7kS7th66csf/EE/crF7tzaps7SJXAmbhuZe7+oDLSZB/RFaGhkdHZ1SITw8nClTprBq1SoA2rdvT3p6egF7VRx0B+TARaA19ooQnp5aZoKZM2eyatUrrF+/nu+++85hr1iv3qS4a5Fqu4ZF8OGSnojA07++wbwN03Md5f47Ivng4AA8TmV3yzFiBHzxRemP66Scg4MvwsmPcm9r+w40f0Rv4ejolDKZmZm8++67PP/886SkpODl5cUrr7zCxIkTMRrzyhpY8dAdkI0daDlRNb7/Xmv1mM0QGRlJ9erVmTt3rsMeJkMVon3vRgzuGA2Cb5tP2LvkGRbvvof7vlvsULZmTWHGoN1M2TkBl1X7HA+9fTt07FhK52XHud/h7xxqam7V4ebvoVbP0j++jo4OAFOmTOGjj7SXwJEjR/LOO+9Qt27dMrbq2qM7IAD2Y+98pk6F+fO175cuXcLb25t587InVLq4exNR5U4sBm3CpPHIVj5sOIhl74+i6+YtbA3PzoB2U9t01veai+ubr2gR3Pa8/DI880xpnVQ22x6AM0vAYte0b3AntHtPS7Cpo6NzTXn88cfZsGEDb7/9Nv36OemGv0HQHRBbsU+Z2amTlrnAaDSSlpYGwMsvv2zbXr3FbeyLa2FbPrrhR9Z1nIhhmmPandtZxXeBL1Flz07Yk+OQr74KM2eW+Jk4YDFpXW0H5+beNuAg+ASV7vF1dHQATURy8eLFrF69mm+//RalFC1btuTgwYMYciaHvMG4wR3Ql8B421KHDlomgylTpvDee++RnJzs0PIx1Onu4HzurHeYI+kHqTQte4KoERMX64RR7fxhOGx3qJYttWZV376leUJa3rWfG2hZpe1pMQXCXtLkB3R0dK4Jx44dY+LEibZI2fvuu48BAwYA3PDOB25oB2QGu9DnmjUhJgbWrVvHTTfdxF9//cU//2SLmGVWbU20KdS2/Ib7dzz6gi/f7X3Ptq5j5d/YnjogO4bB2xs++UTLVuDqWrqnk3QSto6BS1sd19cdoHW1eTUr3ePr6OjYSE1N5dVXX+X1118nIyMDPz8/3nrrLfr371/wzjcQN7AD6oamk5cd6fbRRx/RtGlTXn31VYeSl6oOIM2tqW15+sLPaB89nFOXs9ct7TGNUX+/lb3THXfAypWln37mxMew/xnIiHVcX38Y3LxcT3+jo3ONWbNmDY888gj//adNXn/ggQd4/fXX8fMrrO7tjcMN6oBeArTWzcsva87n+++/x83NjS+//NJWKiQkhD/OdbIFG4gFwp7fTcvLT9vKeI1JILzGi/i+Zed89u7VMk6XJqYU+MEbJEd+uE6fQ5OxmjS0jo7ONeeff/7hv//+IygoiI8++oibb765rE26brkB9YC2A50BzfF4esLGjRs5ffo0p0+ftpWaPHkyBjcfpn8VD4BbxhX+75XanInJTj3T/ed1rBk7Ape4uOzq09LAze0q7CuAtBj46yYtN5s9/XZpEtM6OjrXFLPZzMmTJ2nZsiUA6enpfP755zz44IPXVeJQXQ+ozIkly/mcPQv+/pCRkcEbb7yByaS1JOrVq8eDDz6I2SI88lG2Y1n4RAPb984Nt3L7Xat4ZvBrjtXHxJSe84ndDVvuhqTjjusDpkGbN0vnmDo6Ovmyd+9eHnnkEU6dOsWxY8eoVq0abm5uTJo0qaxNKxfcYA7oNtu3W2+Fbdu2sXTpUpvzufnmm+nVqxeAzfmYMmHZ7OzMAO/c8Ti3V/6Fpq+fyq52+nR47bXcetslQWYSbBwK0Wsd1wc9A6Ev6WM8OjplQFJSEnPmzGH+/PlYLBbq1avHf//9R7WSFnms4NxADuhNQOu6GzECevR4CA8PD06d0hxJ7969uemmmwD49M8kABJjDHz/vI+tholdPuDx6PccFRnOnSsdwTdzGux+InfKnIZ3Q+fP9XQ5OjplgIjw008/MXXqVM6ePYvBYOCJJ57ghRdewKu002hVQG4QB7QL0AIHli2DH3+EZct68dNPPwEQGBhocz5REansOJlJapJycD5fjbiPMT8vhky7ajMySj68OiMONtwOMVsc17d4DNq/X7LH0tHRKRKPP/44861pUjp06MDHH39MmzZ6wt7icoOESg22fRszBr777juOHMmWHhgyZAgA4dGZvPBrKmKBJTN9bdtf6TaTMcvtnM8tt5SO89nzFCyv5uh8qgbA7Sd056Ojcx0wdOhQvL29WbhwIVu3btWdz1VyA7SAxgPnAC0yesyYB7lw4QIAtWrV4qGHHsJgMCAivPSj1vW24esqtr0nD3iPWZGvZ1c3Zgx89VXJmnhsAeye7LiuyXjosFDvatPRKUM2b97M+vXrmT17NgA9evQgIiKCqlV15d+SoII7oCHAzwCsXg3798MLLwxi3759uLi4MH78eJvzeejDOERg6WxvkuO0dOgDe69i/p+PQ9ZUm99+g5JKHCgCUT/n1uNx8YRh0eDiUTLH0dHRKTKXL19mxowZfP755wD06tWLrl21nJG68yk5KrADErKcD8DAgXDw4EHbuE+3bt1sMfozvk4A4NB6N5vzcSeVX9dkd91RvTrclh1Fd3WmWeA7J5ofg45B1Ra51+vo6FwTRISvv/6aadOmcenSJVxdXZk5c6be1VZKVGAH9Lvtm6srTJ06laSkJCwWCx4eHrbZyZsOpxGXbCEjFbb9qHW9GRubSDV4wH/WCr7+Gu67r+RM25adAJUqjaD7r3p2ah2dMubIkSNMnDiRDRs2ANCzZ08++OADWrVqVcaWVVwqcBDC/wBITweTCZ577jn++OMPALp27YpSSnvb+TsFgO+ezQ462D8yNNv5zH+15JyPKQV+8IXT1jGkOv1h8Gnd+ejoXAe8/fbbbNiwgRo1avDNN9+wdu1a3fmUMhW0BRQB7AVg8mS48847+fvvv21bw8LCAHhuqdb1djnSSGaaNqGzWZ/jBH1pjZCrWwMml4Buj8UMOx6CUzkU6br9dPV1lzKZmZlERUXZtJF0dCoSFovFJoswdepUxo4di4+PDwaDgaNHj5axdcXD3d0df39/XEs7A38JUEEd0P22b59+CosXD+bAgQMADBgwAE9PT/6LSud8nAWALd9lR70d29gSsoRDf8nuxrsqVodAYnbYNw3uhJuWlYssBlFRUXh5edGoUSNUObBXR6cwZGRkEBkZSWpqKi1btqww2jwiwuXLl4mKiqJx48ZlbU6BVEAHlAn8DcCkSaCU4uTJk7atbdu2JdMsvLYqGYDDG9y4GK5dhlkPvIzhc2vBSQ9B27ZXZ0rKWVjpn71ctSUM+BcM1/+bSRZpaWm689GpMIgIFy9e5OzZs7bWT0pKCp6enmVtWomglMLPz4+YmJiyNqVQVEAH9H+2bx9+CC+//BKZmdoM0t69e2M0Glm5Rut6S01S/PO91vpRrSy88vWz2o4NK8HCj6/OjIgfYPPI7OWqATDocN7lr2N056NTEUhOTiY8PJyUFG3c18fHh/r16+NWmtnry4Dy9Hst1XanUqqfUuqYUuqkUirXYIpSylsp9YtSar9S6pBSatzVHlNE0/O5fFlLm5HlfOrWrWtLt/P7cTMAOz/Nbol8/vC47EwHK9dcnRGxex2dT4cPyq3z0dGpCJw7d44jR46QkpJCpUqVaNasGc2aNatwzqe8UWoOSCllBBYC/YFAYLRSKjBHsUeBwyISBvQA3lJKXYWARjpKrQLg+eer8Oijj9q29LNOII26pM0qjT1r5Ph/1mb3DxbGTfs6u5rWtxTfhCun4He7rrs7TkHzicWvT6dQrFq1itdee63gghWcRYsWUaNGDVq3bk2rVq145513HLZ/8skntGrVilatWtGxY0c2b95s25aZmcnMmTNp3rw5wcHBdOzYkd9+++1an0KBPP7442zcuLFI+2TN+atVqxZBQUH4+PiUgmUau3fvJiQkhGbNmjFlyhScaa5lZGQwbtw4QkJCCAsLcwiSysjI4KGHHqJFixa0atWKH3/8EYAFCxY4CGZWBEqzC64jcFJETgEopZaiJWWzbwoI4KW0NqMnmmCPKWdFhWcYAJcugavrBP7v/7K74+rXrw/AonVaup3d/6epnNIN/j7YA8zWgl9eRdebCKzKlumm7zbwvP4HAotEjQWOyzGPOS/39UF46u/s5fsC4e1bS8sq7rjjDu64445ClRURRKTMBp5NJhMuLqX30xs1ahQLFizg8uXLtGzZkhEjRlC/fn1+/fVXPv74YzZv3kz16tXZs2cPQ4YMYceOHdSuXZvZs2dz/vx5Dh48iJubG9HR0bY5MSWF2WzGaHQyCbuQxMbGsm3bNt599918y6Wnp5OcnEy1atUwmUz4+fnh6emJu3vpp7aaOHEin3zyCZ07d2bAgAH8/vvv9O/f36HMp59+CsC///7LxYsX6d+/Pzt37sRgMPDyyy9Ts2ZNjh8/jsViITY2FoDx48dz0003MW7cVXcUXTeU5i+wHhBptxxlXWfPAiAALVnbv8BUEbHkrEgp9ZBSapdSald+g2siWtjk1q1w7733ER8fD8CDDz5oKxMRnUnsWSPh+7U3oiqvJdL9xU3axppeMPahopyjIyvtTq/L11C9U/Hr0gHgzJkztGrVigcffJDg4GDuuece1qxZw0033UTz5s3ZsWMHoL35P/aY5gyjo6MZOnQoYWFhhIWF8c8//3DmzBkCAgKYNGkSbdu2JTIykunTpxMcHExISAjLli1zevwdO3bQtWtX2rRpQ9euXTl27BgAnTp14tChQ7ZyPXr0YPfu3SQnJzN+/Hg6dOhAmzZt+Pnnn2323Xnnndx+++307duXK1eu0KtXL9q2bUtISIitHMCLL75Iq1at6NOnD6NHj2bevHkA/Pfff/Tr14927dpxyy23FBgm7OfnR7NmzTh//jwAr7/+Om+++SbVq1cHtICc+++/n4ULF5KSksKnn37K+++/b+uWqlWrFiNHjsxV786dO+natSthYWF07NiRpKQkh+sPMGjQINtbvaenJ3PmzKFTp0688sorDnX+/fff3H777QD8+eefdOnShbZt23LnnXdy5cqVXMdevny5rTcDYO7cuXTo0IHg4GAeeughzGYz58+fp2vXrkybNo1bbrmF9957jz179nDbbbfRrl07brvtNts1+fTTT+nQoQNhYWEMHz7cNj5UXM6fP09iYiJdunRBKcWYMWNYuXJlrnKHDx+2aY/VrFkTHx8fspSev/jiC2bNmgWAwWCw/b88PDxo1KiR7Z6vCJSmA3I2EpazLXobsA+oC7QGFiilciVaEpFPRKS9iLSvUaNG3gdUmrbP/Pk1+ffffwGoXLky9eppjuFMeDxidGHHSmvrJxQWL7kPslzewf9yVll4/i8IUrWbmhaToXEJZk64wTl58iRTp07lwIEDHD16lG+//ZbNmzczb948XnnllVzlp0yZQvfu3dm/fz979uwhKEib6Hvs2DHGjBnD3r172bVrF/v27WP//v2sWbOG6dOn2x5K9rRq1YqNGzeyd+9e5s6dyzPPPAPAXXfdxffffw9oD51z587Rrl07Xn75ZW699VZ27tzJ+vXrmT59OsnJWsTl1q1b+eqrr1i3bh3u7u6sWLGCPXv2sH79ep566ilEhF27dvHjjz+yd+9efvrpJ+zl5x966CHef/99du/ezbx58wpU3YyIiCAtLY3Q0FAADh06RLt2jrLt7du359ChQ5w8eZIGDRoUmOcsIyODUaNG8d5779muXeXKlfPdJzk5meDgYLZv386sWbPYtm2b7ZosW7aMUaNGcenSJV566SXWrFnDnj17aN++PW+//XauurZs2eJwDo899hg7d+7k4MGDJCYm8uGHH3L27FmbrevWrWPKlClMnjyZ5cuXs3v3bsaPH8///qdNVB82bBg7d+5k//79BAQE2HK/2bN+/Xpat26d65OVG86es2fP4u+fHfnq7+9vs8eesLAwfv75Z0wmE6dPn2b37t1ERkbaXppnz55tc8TR0dG2/dq3b8+mTZvyvd7lidLsgosC6tst+5OVljqbccBronWSnlRKnQZaAUV28enpcTY1bD+/bpw5cwbAptMO8MryRC7HehN12DrM9IIwZKg2ZkSnxpCPc8uXzSMhwdqzWLsPtJ9fvHp0nNK4cWNCQkIACAoKolevXiilCAkJsf2f7Vm3bh1ff62N6RmNRry9vYmLi6Nhw4Z07qxJsm/evJnRo0djNBqpVasW3bt3Z+fOnbm68RISErj//vs5ceIESilbUMvIkSPp06cPL7zwAt9//z133nknoL3Fr1q1ytZqSUtLIyIiAoA+ffrYFDNFhGeeeYaNGzdiMBg4e/Ys0dHRbN68mcGDB9se6lmtgytXrvDPP//YjgNaN5Mzli1bxvr16zl27Biffvppvt1OIlKkqKljx45Rp04dOnToABQuMafRaGT48OEAuLi40K9fP3755RdGjBjB//3f//HGG2+wYcMGDh8+bAsUysjIoEuXLrnqOn/+PPYvoevXr+f1118nISGBuLg4qlevTvfu3fHw8GDChAm4urpy8OBBDh48SJ8+fQCtG7COVUTy4MGDPPvss8THx3PlyhVuc5LvsWfPnuzbt69Q18fZeI+z6zt+/HiOHDlC+/btadiwIV27dsXFxQWTyURUVBQ33XQTb7/9Nm+//TbTpk3jm2++AbTWUnmdIOuM0nRAO4HmSqnGwFngLuDuHGUigF7AJqVULaAlcIpisHHjN/TpA+Hh0LdvfyIjtd6/wYMHQ3ImJhGksidbv7dmmW4FHx6xCw74rphZCfY8pYVcAzS8C276rnj1lBfyGvPJyZhg7VMC2EcqGQwG27LBYLDJqReGKlWyJxw7e1AALFy40NY/v3r1ambPnk3Pnj1ZsWIFZ86coUePHgDUq1cPPz8/Dhw4wLJly/j4449t9f74448OLz4A27dvdzj+kiVLiImJYffu3bi6utKoUSPS0tLytMtiseDj41OoB2HWGNDWrVsZOHAg/fv3p3bt2gQGBrJ7925uvTV7LG7Pnj0EBgbSrFkzIiIiSEpKylfZMy+H5eLigsWS3XtunznD3d3dYdxn1KhRLFy4kGrVqtGhQwe8vLwQEfr06cN33+X/+6lcubKt7rS0NCZNmsTy5cupXLkyn3zyCW5ubgQFBWE0Gm3XW0QICgpi69atueobO3YsK1euJCwsjEWLFjkEA2Sxfv16nnjiiVzrPTw8+OeffxzW+fv7ExUVZVuOioqibt26ufZ1cXFxCBDp2rUrzZs3x8/PDw8PD4YO1bLk33nnnQ6tsrS0tAJbnOWJUuuCExET8BjwB3AE+F5EDimlHlFKPWIt9iLQVSn1L7AWmCEil4pzvJMnNQdiNte0vRnafmhf/stbr4cTH23gwklr6PWnMPa9Rdr30DrQuHXRD/rfl3DU2k1QyRe6LimO6TolTK9evfjwww8B7W03MTExV5lu3bqxbNkyzGYzMTExbNy4kY4dO/Loo4+yb98+9u3bR926dUlISLB14S5atMihjrvuuos33niDhIQEWwvttttu4/3337c5kr179zq1MSEhgZo1a+Lq6sr69esJDw8H4Oabb+aXX34hLS2NK1eu2AJpqlatSuPGjfnhB+1lR0TYv39/vtehS5cu3Hfffbz33nsAPP3008yYMYPLly8DsG/fPhYtWsSkSZPw8PDggQceYMqUKWRkZABaa2Px4sUOdbZq1Ypz586xc+dOAJKSkjCZTDRq1Ih9+/ZhsViIjIzMd5yiR48e7Nmzh08//ZRRo0YB0LlzZ7Zs2WKbNJ6SksLx48dz7RsQEMDJkycREZsjCg4OxsXFhS1btuDl5ZUruKRly5bExMTYHFBmZqZt/C4pKYk6deqQmZnJkiXOf79ZLaCcn5zOB6BOnTp4eXmxbds2W2btwYMH5yqXkpJi64b866+/cHFxITAwEKUUt99+u80Rrl27lsDA7ODh48ePExxcMi921wOlGgYkIqtFpIWINBWRl63rPhKRj6zfz4lIXxEJEZFgEVmcf415U62aNuZjsbTg4sWLgDZQjAiWZUc5WceP1e9ZuwvcYMbOV3CPtnZhfOJ8ADpfMuJhuzWrtYsnDL8EqmKk8yjvvPfee6xfv56QkBDatWvnECyQxdChQwkNDSUsLIxbb72VN954g9q1a+cq9/TTTzNr1ixuuukmzGazw7YRI0awdOlSh0H12bNnk5mZSWhoKMHBwTYhs5zcc8897Nq1i/bt27NkyRJb0ssOHTpwxx13EBYWxrBhw2jfvj3e3t6A1mr6/PPPCQsLIygoyCFwIS9mzJjBl19+SVJSEnfccQfjx4+na9eutGrVigkTJrB48WJbd9RLL71EjRo1CAwMJDg4mCFDhpBzzLVSpUosW7aMyZMnExYWRp8+fUhLS+Omm26ydZVOmzaNtvlkETEajQwaNIjffvuNQYMGAVCjRg0WLVrE6NGjCQ0NpXPnzk67mvr168fq1as5ceIE3t7eTJgwgQ4dOjBt2jQ6duzo9HiVKlVi+fLlzJgxg7CwMFq3bm1zHi+++CKdOnWiT58+JZZ49MMPP+TBBx+kWbNmNG3a1BYBt2rVKubMmQPAxYsXadu2LQEBAbz++uu2LjbQgkWef/55QkND+eabb3jrrbds27Zs2ULv3r1LxM7rgqyQ1PLyadeuneQkKSlJvvlGK3L8+Dh5/vnn5bXXXtM2/n5KFj66T8bPvyxanLQIb1jEtuDjkqu+ArFYRH6qK7IE7ZN2qeh1lBMOHz5c1ibccCQlJYmISHJysrRr1052795dxhZdH8TFxcn+/fslLCxM1q1bZ7tONwp79uyRe++9t1Blnf1ugV1yHTzD7T8VIhXPzz//jDXQiS1btK4PW4TKpij2Bgax5iPrpFNXmBf3VPbOX71U9AMeew9SrfEUN/8Abn7FtFxHJzcPPfQQhw8fJi0tjfvvvz/f1sSNQEZGBhEREbYIsRkzZlC5cuUKk7+tsFy6dIkXX3yxrM0oUSqEAzp48B/uuUf7fvFiTQBbc/y/RzsjPyUR8a818u1+eOpV6+BfVSPcMaNoBxOBPdYBycZjoMGIqzVfR8eBb7/9tqxNuG64ePEiUVFRtsSh9erVo127duUq31lJkRXFV5GoEA5o+3YtPYXZbCQ11YOqVavaIqVe/i6GE7u9bWW/TrWbn/PJw0U7kAj8WD17uf37xbZZR0enYEwmky0CsEGDBraUOjoVg3LvgOLj47n11lQAzp7Vwh2zut8OHYrB6O7OyR3aTdsv5DfuW2KNc2gNDHimaAfbNBwytLQYBEwH14LnQOjo6BQek8lEWlqarXutdu3aVKlSxRaIoVOxKPdhWxs3bsQ6J474eB8A28z3d77Q0qZkhV7/9u8ArWB14F7AK2dmoHy4chqiVmjfa3aHNm9cpeU6OjpZiAixsbG2rAxZ87sMBoPufCow5d4BHThwgNatte9RUf5Ur14dT09PTCYLqmkgcee0CXAD+TV7pweB4X8W/iAWE6xqkr3ca/1V262jo6ORlpbGiRMnOHXqFJmZmbi7u+cKedepmJR7B7Rt21Zq1dK+HzkSoM3liEvDJVLLen1kszYW9CtaShPqATUM0KgIA3q7H8/+3mt9uZDS1tE5c+YMlStXpnXr1gQGBjJmzBhbKiHQ0hF17NjRJs/wySefOOz/9ddfExwcTFBQEIGBgbb0QiWFxWLh3LlzHDp0iMTERIxGIw0bNqRly5aF1ulZuXIlc+fOLVG7SpLY2Fj69OlD8+bN6dOnD3FxcU7Lvffee7ZrnTPT9/vvv0/Lli0JCgri6aefBrQs2mPHji1l668BhY3XBqqUdcy4OJkHVLt29ubnn39ejh8/LvLeLtl7ywp5cKE296cTW7Pn/TyLyB8TnAfPOyMjMXu+z8YRhd+vgpBzPgE87/DJi48/3uVQbsKEVaVtarExmUxldmyLxSJms7lU6j59+rQEBQWJiHaOPXv2lMWLF4uIyPnz56V+/fq2OUYxMTHStm1b+fXXX0VEZPXq1dKmTRs5e/asiIikpqbKJ598UqL2HTlyRHbu3Ck7d+6UU6dOSUZGRpHr6NKli8TExBS6fGZmZpGPcTVMnz5dXn31VRERefXVV+Xpp5/OVebff/+VoKAgSU5OlszMTOnVq5f2HBORdevWSa9evSQtLU1ERKKjo2379erVS8LDw50et7zMAyqwBaSU6qqUOoyWTgelVJhS6oPSdYuFIz4+nqyUW+npWqBB/fr14f9OsfCubkQd1sZ+1mFNyeML+AA3FSGWfvuE7O9dvrpqm3WKRmHlGPKSTTCbzUybNo2QkBBCQ0N5/30tcrFRo0bMnTuXm2++mR9++IHvvvuOkJAQgoODmTHDeWh+XhIKM2bM4IMPsn8Szz//vG32+ptvvkmHDh0IDQ3lueees51TTmmIiRMn0r59e4KCgmzlQMtH16pVK26++WamTJliyxyQl+xDXhiNRjp27GjLzLxw4ULGjh1rm2NUvXp13njjDZuo36uvvsq8efNseczc3d2ZMGFCrnrzkr6wTxczb948nn/+eUBLw/PMM8/QvXt3W5qaZs2a0bhxYzIzM6lfvz6ZmZmFkp44fvw4bm5uNrmCX375hU6dOtGmTRt69+5tyyL9/PPP89BDD9G3b1/GjBlDTEwMw4cPp0OHDnTo0IEtW7YAed9DV8PPP//M/fffD8D999/vVJrhyJEjdO7cGQ8PD1xcXOjevTsrVmjjzR9++CEzZ860tQhr1qxp2+/2229n6dKlV21jmVKQhwK2o2W13mu37mBZeUz7FtDvv/8ujz6qbTp8uJXMmzdP5GSsJPt/JA8uvCyubhbxJyK79TMGkd/GOn1jcMqOR7NbP9sfKvx+FYiybgGdPn1ajEajHDhwQMxms7Rt21bGjRsnFotFVq5cKYMHDxYRkYSEBNvb7V9//SXDhg0TEZEPPvhAhg0bZtt2+fJlERFp2LChvP766yIicvbsWalfv75cvHhRMjMzpWfPnrJixYpctmRmZkpCQoKIaC2Gpk2bisVikT179ki3bt1s5QICAiQ8PFz++OMPmTBhgq2VM3DgQNmwYYOcPn1alFKydetW2z5ZdplMJunevbvs379fUlNTxd/fX06dOiUiInfddZcMHDhQRERmzZol33zzjYhoGQKaN28uV65cyXXtslpAqamp0qNHD9m/f7+IiAwdOlRWrlzpUD4+Pl58fX1FRMTX11fi4+ML/P+MHDlS3nnnHZvt8fHxDscVEXnzzTdlzpw5cvHiRencubNMnDjRtu2OO+6QdevWiYjI0qVL5YEHHhARkVtvvdXWCti2bZv07Nkz17G/+OILefLJJ23LsbGxYrFYRETk008/tW177rnnpG3btpKSkiIiIqNHj5ZNmzaJiEh4eLi0atVKRPK+h+xJTEyUsLAwp59Dhw7lKu/t7e2w7OPjk6vM4cOHpXnz5nLp0iVJTk6Wzp07y2OPPSYiImFhYTJnzhzp2LGjdOvWTXbs2GHbb/PmzTJo0KBc9WXVmROuwxZQocKwRSQyx8Sv62KE8PTp0zYFhcqVU7WBy3/OsSOsMZGHXMlMV0zlvewdQoHqIYWr/L8v4cRC7XuVhtD23ZI0XacIFEaOIS/ZhDVr1vDII4/YFEiz5BAAWyLMnTt30qNHD1ves3vuuYeNGzcyZMgQBztEnEsotGnThosXL3Lu3DliYmLw9fWlQYMGzJ8/nz///JM2bdoAWgvqxIkTNGjQwEEaAuD777/nk08+wWQycf78eQ4fPozFYqFJkyY0bqyp6o4ePdo2TpOX7ENAQICDzf/99x+tW7fmxIkTjBgxwqYNJOI8q3VRJ3jmJX1hT0ZGBpcvXyY8PJyMjAyH5JyjRo1i2bJl9OzZk6VLlzJp0qRCS0/klGaIiopi1KhRnD9/noyMDNt1A00xNyuL9Jo1azh8OFuYOTExkaSkpDzvIXu8vLwKLc1QWAICApgxYwZ9+vTB09OTsLAw2/1qMpmIi4tj27Zt7Ny5k5EjR3Lq1CmUUtSsWZNz53Iq3JQvCuOAIpVSXQFRSlUCpmDtjitr/vnnH26+WfseE1OD5s2bw9Ag9lf1Z+tDmuzCNKyJ/HpYd2o5quCK4//NTjQKcMdpPfDAishzBRcCHnqoHQ891K7ggoWgMHIMeckm5PWgBRzS9Ttj+/btPPywNll57ty5xMbGOpVQAC0x6fLly7lw4QJ33XWXrd5Zs2bZ6sjizJkzDtIMp0+fZt68eezcuRNfX1/Gjh2brzRDVt3OZB9y0rRpU/bt28f58+fp0aMHq1at4o477iAoKIhdu3Y56B/t3r3blnk5KCgol3RDYcmSZshSJ42MjMRsNuPq6krlypUdXgLuuOMOZs2aRWxsrO14ycnJhZKeqFy5MgkJCbblyZMn8+STT3LHHXfw999/27r9wFGKw2KxsHXr1lyyBpMnT3Z6D9mTlJTELbfc4tSeb7/91iFzNWiqsufPn6dOnTqcP3/eoQvNngceeIAHHngAgGeeecYmaufv78+wYcNQStGxY0cMBgOXLl2iRo0aFUKaoTBRcI8Aj6LFj0WhTeHMX4rxGnHx4kVbCHZsrB8NGzZk+vQ/OXjWTOJFIz7EYc5Kzd4OaHRb4eb+HNL6wXH1gdFm3fmUA/KSTejbty8fffSRzVHFxsbm2rdTp05s2LCBS5cuYTab+e677+jevTudOnWypd6/44478pRQAE2aYenSpSxfvpwRI7T0TLfddhtffPGFTVr67Nmztkzt9iQmJtomW0ZHR/Pbb78BmvTBqVOnbK08e9nwwso+ZFGnTh1ee+01Xn31VQAeffRRFi1aZHvIX758mRkzZtiirGbNmsXTTz/NhQsXAK0FMn9+bqFFZ9IXtWrVIjo6mi1bthAREcHmzZupUqUKQUFBuLi4OLwQeHp60rFjR6ZOncqgQYMwGo2Flp7IkmbIwv4e+OqrvMdr+/bty4IFC2zLWdcgP+mNLLJaQM4+OZ0PaA42y5avvvrKqTQDYLsvIiIi+Omnnxg9ejQAQ4YMYd26dYA25pWRkWEb86oI0gyFcUAtReQeEaklIjVF5F4goMC9rgF//PEHWa391FR36tWrx/LlR0hJ0G7w0epbjBYL0tAN6gD+3QuuNOEohFtzcd36py6xUE7ISzbhwQcfpEGDBjbpBWd51urUqcOrr75Kz549CQsLo23btk4fFHlJKIDWYkhKSqJevXo2eYO+ffty991306VLF0JCQhgxYgRJSUm56g0LC6NNmzYEBQUxfvx4mypo5cqV+eCDD+jXrx8333wztWrVsk3KLKzsgz1DhgwhJSWFTZs2UadOHRYvXsyECRNo1aoVXbt2Zfz48TYF1gEDBvDoo4/Su3dvgoKCaNeunVPxP2fSF66urjz22GPcc889TJs2jbCwMLy9vW3dSjkZNWoUixcvtnWJQuGkJ7p168bevXttTvj555/nzjvv5JZbbrE9pJ0xf/58du3aRWhoKIGBgXz00UdA/tIbxWXmzJn89ddfNG/enL/++ouZM2cCcO7cOQYMGGArN3z4cAIDA7n99ttZuHAhvr6+gKaceurUKYKDg7nrrrv46quvbA58/fr1DBw4sETsLDMKGiQC9hRm3bX6ZAUhnD9/XuzN//LL+2X//vPS6uYf5Oa7rwiI/MJALfigLSLzEEmMzDUw54DFkh108EvL/MveIOhyDGVLluSAxWKRiRMnyttvv13GFjnHYrHYQoVFRDIyMiQ6OtoWFFBaTJkyRf76669SPcb1SFpamnTq1CnPsPJyH4SglOoCdAVqKKWetNtUFTA63+vaERERAYDFAgYD+Pm1ZPPmSLqO7MHPb7phwMwgNDVJQtBaMl7++VdqP+G0+XXRy6hzg/Ppp5/y1VdfkZGRQZs2bXKNJ10PXLlyhfDwcESEwMBADAYDrq6ueY53lCTPPPMM27dvL/XjXG9ERETw2muv5dmqLC/kZ30lwNNaxl4kPhEocw2CrP73rCEei6UhYx9ox46F8VyOdOFpXs8u3ALwaZ5/hckRcNzaxx38HLScUvJG6+gUkSeeeIInnniirM1wislk4uzZs8TExACa8mhGRgbu7u7XzIZatWo5BFLcKDRv3lwLuirn5OmARGQDsEEptUhEwvMqV1YcO3YMLzu3WP2kC3M+uMiJ7drKgVmtn7aAG9D52fwr/KWZ9YuCkMJFeuno3IiIaIlDIyMjMZlMKKWoVasWderUwWgs884RnXJEYdpvKUqpN4EgwPZqIyJFj88sQbZu3UoTa35Qk8lI9f0pJHSuxPmTLriTSjc2aRuzxugC7s67su0TwGKN+e/+ix71pqOTD6dPn7ZFE3p6etKwYcNyHw6sUzYUJsRrCXAUaAy8AJwBdpaiTYVi+/bttjlA8fE+uB7TJqqFH6iU3fpxN4I3UL9n3tFsGXHw32fZy/XKeVSJjk4pU7VqVVxcXGjUqBEtW7bUnY9OsSlMC8hPRD5XSk2165bbUNqGFYS/vz/16iUAJmJiahDjUx8RsJgUfbFKLfTyAy5Cw97OKxGB/wvKXh6VWtpm6+iUOxITE0lPT7dlHfDz88PHx6fcD4DrlD2FaQFl5aM4r5QaqJRqAxQQTlb6HDt2jKFDtR/AmTPNWDeqI9H/acs3oSUXxN866S/kIeeV/Ps8pJ7Xvt+yAozXbvBUp/AYjUZat25NcHAwt99+O/Hx8bZthw4d4tZbb6VFixY0b96cF1980SGDwG+//Ub79u0JCAigVatWTJs2rQzOoHiMHj2a0NBQ3nnnnUKVz1IRLSkyMzM5deoUx44dY/LkyTRt2pTQ0FD27t3r1PmICLfeeiuJiYklakdJ8tVXX9kG8POarBoeHk6vXr0IDQ2lR48eREVFAdq8m9atW9s+7u7utuSid911FydOnLhWp1FxKChOGxiE1pEVDKwHdgO3l1XceNY8IECSk40igqxcOVkeXHhZ2g5IlrpEiS356EuIfN3GaZy8ZF7JnvOzZ7rzMjrXxTygKlWq2L6PGTNGXnrpJRERSUlJkSZNmsgff/whIiLJycnSr18/WbBggYhoae6bNGkiR44cEREtmejChQtL1LbSSu9//vx5adCgQZH2sb9OV4PFYpHo6GjZs2eP7Ny5U959913p2bOnmEwm2bp1q3Ts2NHpfr/++qs8/vjjRTrWtZTCuHz5sjRu3FguX74ssbGx0rhxY4mNjc1VbsSIEbJo0SIREVm7dq3ce++9Tuvy9fWV5ORkERH5+++/5cEHHyzdEygC5WUeUIEtIBH5VUQSROSgiPQUkXZA7nwm1xARLb+XwaAFC0REafMNYiJceBRrAtEaSguZaHK780oiV2Z/D3ul9IytQKhS+hSFLl262CQFvv32W2666Sb69u0LgIeHBwsWLLBJCrzxxhv873//s2UscHFxYdKk3PO7rly5wrhx42ySDT/++CPg2KJYvny5TQBs7NixPPnkk/Ts2ZPp06fTqFEjh1ZZs2bNiI6OzjPtvz1paWm2Y7dp04b16zW13b59+1pTTbVm06ZNDvs4k0DIeT7OZCOSk5MZOHAgYWFhBAcH21L7zJw5k8DAQEJDQ5k6dSpHjx4lIiICs9mMt7c3//77LxMmTMBoNNK5c2fi4+M5f/58rnNZsmSJQwaJIUOG0K5dO4KCghzE7jw9PZkzZw6dOnVi69atLF68mI4dO9K6dWsefvhhWxaCvCQqissff/xBnz59qFatGr6+vvTp04fff/89V7nDhw/Tq1cvAHr27Ok0C8Py5cvp378/Hh5azslbbrmFNWvWOM0WoZM3+U1ENQIj0XLA/S4iB5VSg4BngMpAm2tjYm4uXryIh4fg7q79s49FNISGEHmwErfzi1bI39oNE+qk+00Ett6rfW/2MBj0vuzygNlsZu3atbakjYcOHaJdO8eEp02bNuXKlSskJiZy8OBBnnrqqQLrffHFF20PWiBP1Up7jh8/zpo1azAajVgsFlasWMG4cePYvn07jRo1olatWtx999088cQT3HzzzURERHDbbbdx5IhjHt+FC7UXpn///ZejR4/St29fjh8/zqpVqxg0aJDThJxTpkyxacaYzWZbrrks3N3dWbFiBVWrVuXSpUt07tyZO+64g99//526devyf/+nBekkJCQQGxvLihUrOHr0KEopdu3aRXJyMq6urtSvXx9fX18uXLig6WxZ8ff35+zZs7aUQ1ls2bKFjz/+2Lb8xRdfUK1aNVJTU+nQoQPDhw/Hz8+P5ORkgoODmTt3LkeOHOH1119ny5YtuLq6MmnSJJYsWcKYMWN4+eWXqVatGmazmV69enHgwAFbNu8s3nzzTZYsWZLrGnXr1i1X7rqzZ886PY+chIWF8eOPPzJ16lRWrFhBUlISly9fxs/Pz1Zm6dKlPPlk9vx8g8FAs2bN2L9/f657Uidv8nvyfo6mA7QDmK+UCge6ADNFZOU1sC1PLl26RFam9fT0SkTGVsevLoAQwkFtQ1ZeQGfJR6NWZH9vfF8pWlqxyDs3c+mSmppK69atOXPmDO3ataNPH01OPasl7IyiyAqsWbPGQdgrKw9Xftx55522OS+jRo1i7ty5jBs3jqVLl9pymuWV9t/LbgLb5s2bmTx5MqAlH23YsCHHjx+natWqeR7bmQSCPSLOZSNCQkKYNm0aM2bMYNCgQdxyyy1kZmbi7u7Ogw8+yMCBA+nduzcJCQnUrVvXdn4iuf/zzq5vbGysw7nNnz/fJqwWGRnJiRMn8PPzw2g0Mnz4cADWrl3L7t276dChA6D9r7MyKDiTqMjpgKZPn8706dPzvFY5r0thzmPevHk89thjLFq0iG7dulGvXj2HMa/z58/z77//cttttznslyWPoDugwpOfA2oPhIqIRSnlDlwCmonIhWtjWt6cOXOGNm2MgBkRRcOQQE6fcaE1+7ILhQDGPHTlj1i17au2hBo3lbK1OldL5cqV2bdvHwkJCQwaNIiFCxcyZcoUgoKC2Lhxo0PZU6dO4enpiZeXl01SICwsLN/683Jk9uuyZBeysE/v36VLF06ePElMTAwrV67k2We1Sc95pf3PeeySZsmSJU5lI1q0aMHu3btZvXo1s2bN4tZbb+W+++5j8eLFREREsGzZMhYsWGDLvpyFv78/kZGRtuWoqCibUqo9WTIMBoOBv//+mzVr1rB161Y8PDzo0aOH7Rq6u7s7OLf777/flqU7i7wkKnJSlBaQv78/f//9t8N5OJNcqFu3Lj/99BOgdWf++OOPDk7++++/Z+jQobi6ujrsVxHkEa41+Y0BZYiIBUBE0oDj14PzAThx4gStW2sRa+fP1yHVxYvwf12zxefatdRcq6tH7p1NKXBpq7Vc7vTyOtcv3t7ezJ8/n3nz5pGZmck999zD5s2bWbNmDaC9PU+ZMsUmKTB9+nReeeUVjh8/DmgO4e23385Vb870/FldcLVq1eLIkSO2Lra8UEoxdOhQnnzySQICAmxdNXml/benW7dutgfo8ePHiYiIKFDjx5kEgj15yUacO3cODw8P7r77bh544AE2btzI+fPniY6OplevXrz77rtObbzjjjv4+uuvERG2bduGt7d3ru43gJYtW3Lq1CmbDb6+vnh4eHD06FG2bduW57ksX77cJkcQGxtLeHh4nhIVOZk+fbpTaQRn0hG33XYbf/75J3FxccTFxfHnn3/masWA1sNisVgATZp8/PjxDtu/++47m1yCPcePHycoKCjXep28yc8BtVJKHbB+/rVb/lcpdeBaGegMFxcXAgK0N1BTsvY3Jtwle/zH19qwq1wj984H52Z/r9WrNM3UKQXatGlDWFgYS5cupXLlyvz888+89NJLtGzZkpCQEDp06MBjjz0GQGhoKO+++y6jR48mICCA4OBgp4Pnzz77LHFxcQQHBxMWFmYLBHjttdcYNGgQt956q9MHrj3OJAXySvtvz6RJkzCbzYSEhDBq1CgWLVrkIMDnDGcSCPbkJRvx77//0r59ewIDA3nzzTcZP348rq6uzJo1i44dO9K9e3enId8DBgygSZMmNGvWjAkTJvDBBx84tWvgwIG2Fka/fv0wmUyEhoYye/ZsB/VXewIDA3nppZfo27cvoaGh9OnTh/Pnz+cpUXE1VKtWjdmzZ9uCQubMmWMTx5szZw6rVq0C4O+//6Zly5a0aNGC6Oho/ve//9nqOHPmDJGRkXTv7ijtEh0dTeXKlQu8T3QcUXl1ASilGua3o5RRfrj27dvLXXfdRYsWC7jjjnAOru3Je8eW89mj1ZCsmKoXu0PlDdB2KvR8195o+M7qc6u1g367rrn95Y0jR47kknnWKZ9ERETYWhpubm40aNAg1/jR1XD+/HnGjBnDX3/9VWJ1lhfeeecdqlataguQKWuc/W6VUrtFpH0ZmeSU/JKRXncJSLM4dOgQnTtroZqn4togAi04ll3A1ZqoIWcI9mW7DEJdvi5lK3V0ri+y1Ehr165NnTp1MBgKMw+98NSpU4cJEyaQmJiYbxBFRcTHx4f77tMDmopKqcp9KqX6KaWOKaVOKqVm5lGmh1Jqn1LqUGFT/FSvXh1fXy0EO95Sj6TLBh7gcwDk1h7ZbrV+DgXUjda07d7B4J1bPldHpyKRmppKQkKCbbl27doEBgZSr169Enc+WYwcOfKGcz4A48aN01MTFYNSc0DWeUQLgf5oQdGjlVKBOcr4AB8Ad4hIEHBnYeretm0bvr5a1+EFS13OHXVlONrkQRXSQCtUPcRxfo8ImK253mp2K+5p6ehc91gsFs6ePcvhw4c5ffq0bXKkwWDQo7R0risK5YCUUpWVUvmH5uSmI3BSRE6JSAawFBico8zdwE8iEgEgIhcLU3H16tVxc8sA4EpGTZIuG2jKKetG6xtftRzmRq+FzERw9Yb27xfxVHR0ygcJCQkcOnSI8+fPIyL4+PiUtUk6OnlSoANSSt0O7AN+ty63VkqtKkTd9YBIu+Uo6zp7WgC+Sqm/lVK7lVJjCmN0dHQ0fn5aqGyaxZfT2+1Oo/YZ7a+hkuNOu6wKp9W75C3NoKNTTsnIyOC///7jxIkTpKenU7lyZVq2bEmjRo30riGd65bC3JnPo7Vm/gYQkX1KqUaF2M/ZVPScIXcuQDugF1p6n61KqW0ictyhIqUeAh4CaNCggUNKjHRTVXwStOlJ6W5VcEuyzjyv3yO7gsTjkGhNgRL2UiFM19EpX/z3338kJydjMBioW7cuNWvWLLVxHh2dkqIwd6hJRBIKLpaLKLRUPln4A+eclPldRJJF5BKwEcg1bV1EPhGR9iLSvkaNGiQlRdu2XThbzab/k9GoSbayqb0DOmGdt1DjJi38WqdcocsxOJdjsD9Pf39/unfvTlBQELVr1y5R53P06FG6dOmCm5sb8+bNy7OcVHA5BtBC2fv27UtAQACBgYGcOXMG0OUYik1B6bLRcsLdDRwAmgPvAx8VYj8X4BSakmolYD8QlKNMALDWWtYDOAgE51dvu3btpGtXP9uqDoOT5TmeEwExBQWJzEP7mK1p8i0WkSVKk13Y90yuFOU6+aPLMeRPWcgxmEwmiYiIkNOnTzusLyk5hpxER0fLjh075JlnnpE333wzz3I3ghxD9+7d5c8//xQRkaSkJF2OobTlGIDJQBCQDnwLJACPF8KxmYDHgD+AI8D3InJIKfWIUuoRa5kjaGNLB9CSnn4mIgcLqrtpUy3FTkREQ67EGghBy2JsHNMvu1BWBFz4Mmw9fwHl5+33uuQtVTqfInAjyzGICHFxcWzYsIExY8bYsgeUpByDsxZizZo16dChQ67cZzmp6HIMhw8fxmQy2ZLhenp66nIMV0lhxoBaisj/gP8VWDIHIrIaWJ1j3Uc5lt8E3ixKvbVqaaGkqelVOLHdjfpZsQ41XDSlIlc7Zcjd1uCDJuOhUsFZjnWuX25kOYb09HQiIiJISEjg1VdfpXPnzsyePRs3N7cSlWOwd6RFpaLLMRw/fhwfHx+GDRvG6dOn6d27N6+99hpGo1GXYygmhXFAbyul6gA/AEtF5FBBO5QmFouFatW0EOzkVG9cKgmBGdbAA89UzQGFTdSWL++C9Bjte9Az197YisZTZSPIcCPLMYgIFy5c4Pz581gsFoxGI3v37uWXX37B3V1LyHs1cgwmk8lBjmHQoEGFvm45qehyDCaTiU2bNrF3714aNGhgy92X9UKkyzEUncIoovYEegAxwCfWZKTPlrZheWGxWKhTR2vmxl2pS/CV3XiSjFSuAilW5Ugv61vOkTesy83Bq2kZWKtTEmTJMYSHh5ORkWFrNQQFBbFrl2M+P2dyDAWRlyMrrhzDsGHDgGw5hqwMzWfPnnV4QGcdOz+UUqSnp1tfvKoRHByMUipfB2svx7Bv3z5q1arlIMcQEhLCrFmzmDt3Li4uLuzYsYPhw4ezcuVK+vXrl2e9BZElxwA4yDHs37+fNm3a5CvHkHWNjh07xvPPP2+TY1i7di0HDhxg4MCBecoxtG7dOtdnypQpucoWVlYiS45h7969vPzyy4Dm5P39/WnTpg1NmjTBxcWFIUOGsGfPHtt+uhxD0SlUqIyIXBCR+cAjaHOC5pSmUflhNpttWRAux9UgEO0NU4W1gaTTWiHPOmBKhYgftOX2C5xVpVPOuFHkGJo0aeLwsK1Xrx4tWrSgSZMmuLq6XrUcw7333su0adPYs2cPV65cISEhgQEDBuQpx1BYKrocQ4cOHYiLiyMmRutVWbduHYGB2clddDmGolOYiagBSqnnlVIHgQXAP2gh1WWC9iao3Rxx8b6M5HsApG0ApMdrhRr2hYvWtHJGd6jTtwws1SkNKrocw3vvvcfJkydtTgPA1dXVIb/a1cgxZA32v/zyyzz77LMkJSUxaNAgQkND85RjuHDhAv7+/rz99tu89NJL+Pv7Ow21ruhyDEajkXnz5tGrVy9CQkIQESZMmADocgzFJU85BlsBpbYB3wE/iEjOeTzXnJYtW8qSJQm0bx/NqwveosvkVfRgAylTx+NR/wut0FMCOybCyY+07rfbj+dfqU6e6HIM14bU1FTCw8NtAQVeXl62Fk95QZdj0OUYikqBQQgi4vzVpYwQETw9NcGuxERPGqN1u1VuW1sbpfJpCinnNOcDEFRmw1U6OgViNpu5cOECFy5cQERwcXGhfv36VKtWrUiBFNcDuhyDLsdQVPJ0QEqp70VkpFUN1b6ZpAARkdA8di1V0tPT8fFJAuDsCS8aEqEZVUs0B+RVH46+ZbXUAI3uLgszdXQKREQ4fvw4ycnJANSoUcMWcVVeGTlyZFmbUCaMGzeurE0ol+R3p0+1/i1+XGYpoJSicuV0AColJGdvuKDNbaB2JzhmTRfSYqqjJIOOznWEUooaNWpgsVho2LChw8RXHZ0bgTyDEEQka7R2koiE23+A3NPJrxEiQnKyNvvY/6IWUpnYrgeYUrQCroBoM6kJnXvtDdTRyQMRITo6mgsXLtjW+fn5ERAQoDsfnRuSwoRh93Gyrn9JG1JYRARXVy0KziNRawG5JZnBZA1bNVvjJKo0csyIoKNThiQnJ3PkyBEiIyM5e/YsGRnaZGqllJ61WueGJb8xoIloLZ0mSqkDdpu8gNxJra4Rqamp1KgRC0CLJC26za2xP1yxTkKNsKblaHhXWZino+OAyWTi3LlztnkulSpVokGDBlSqVKmAPXV0Kj75vXp9C9wOrLL+zfq0E5F7r4FtTnFxccEWOZ5hjRLy0VpEGCsB1u9Nxl5jy3RKi/IoxyAixMbGcujQIZvzqVWrFkFBQYVWKS1IjiEnpdWNt2TJEkJDQwkNDaVr167s37/faTmp4HIM69evd8i24O7uzsqVKwFdjqHY5JUmG6hq/VvN2aes0nfXqFFDUlPdRATZ7tNeBESeGKFJMCxppckuLEF0SgZdjiF/8pJjsFgscvToUdm5c6ccPnzYlra/sOQnx5AXpSXHsGXLFptswerVq6Vjx45Oy90Icgz2dfn6+upyDFf5yS9E7Fu0CLjdaGHY9pMSBGhS4t6wEGRmZmI0akEGbhlaNBx1rfmX1CXNsvrDysK0Cs+ED2JLpd5PJ1UrdNkuXbpw4IDWI5yXHEOPHj149NFHiyTHMHnyZHbt2oVSiueee47hw4fj6elpmxi6fPlyfv31VxYtWsTYsWOpVq0ae/fupXXr1qxYsYJ9+/ZRtWpVzGYzAQEBbNmyBQ8PD5566imiozUBxXfffTfXjP60tDQmTpzIrl27cHFx4e2336Znz54Ocgzvv/8+t9xyi22f6OhoHnnkEVvamw8//JCuXbs6nM/gwYOJi4sjMzOTl156icGDB5OcnMzIkSOJiorCbDYze/ZsRo0axcyZM1m1ahUuLi707ds3l+icfd2dO3d2EGizZ8mSJTz00EO25SFDhhAZGUlaWhpTp061bfP09OTJJ5/kjz/+4K233uLMmTPMnz+fjIwMOnXqxAcffIDRaGTixIns3LmT1NRURowYwQsvvJDnfVEY7OUYAJscw+jRox3KHT582Nbq7NmzJ0OGDMlV1/Lly+nfv7+DHMPYsWMxmUzlOoz+WpPnlRKRQda/ja+dOQXj4uKCwaB1s4Vl/mtduRvMQKXKmmpRvcF57q9Tfrme5Ri+++47brnlFg4fPuwgxzBz5swSkWOwZ8qUKXTv3p0VK1ZgNpuvqRzD559/Tv/+zmOQKrocQ1aOP4ClS5fy5JNP2pZ1OYbiUaCrVkrdBOwTkWSl1L1AW+BdEYkodeucYLEIRqN1nMeqvo2PK1wG0rN0gbo621XnKilKS6UkuZ7lGDIzM7nlllt466236NChA7/88gsjRoyw1Xu1cgzOWLduHV9//TWgjY9dKzmG9evX8/nnn7N582an2yu6HEMW58+f599//82VyFSXYyg6hYn//BBIUUqFAU8D4cA3pWpVvlgcluJUVUiOAvss6J669EJF4nqUY/Dw8CAmJoZDhw7RsGFDoqKicHNzY/Pmzdx5551AycgxFIfSkGM4cOAADz74ID///LNDS8Ceii7HkMX333/P0KFDc+Xp0+UYik5hHJDJOoA1GHhPRN5DC8UuE8zmDIfly0Y/SLsMHtaboc5tUM5yaOkUjutJjuH8+fOEh4djMpnw9vZmxIgRvPHGGyUix9CyZct8r8O1lmOIiIhg2LBhfPPNN7Ro0SJPuyq6HEMW3333Xa5xI9DlGIpDYRxQklJqFnAf8H9KKSNavoEywc1Ne3OKjdF8oKG2j7ahkrU/LuT5a2+UzjXjepFjcHd3x9XVlcaNG9O8eXPuueeeEpFjWLRoEW5ubvleg2stxzB37lwuX77MpEmTaN26Ne3bO0+oXNHlGADOnDlDZGQk3bt3d6hbl2MoHoWRY6gN3A3sFJFNSqkGQA8R+fpaGJiTmjWryMWL1rQ7Cq7Ua4jnk+FQ21pgZAq46M3gkkKXY9CIj49HRGzjQxaLBYvFokc82aHLMehyDEWlMJLcF4AlgLdSahCQVlbOB8CtkuYwL56x9kMHNISsSeXutXTno1OiZGRkcPLkSZtInMmkycEbDAbd+eTAXo7hRsPHx4f777+/rM0odxQmCm4k8CbwN9pcoPeVUtNFZHkp2+YUEW18x5BunQsU6JkdgNBQl17QKRlEhIsXL3L27FksFgsGg4E6derYBs91nKPLMegUhcK8wv0P6CAiFwGUUjWANUCZOCCDQWsBJYe7Ux1wrRWd7YBq9SgLk3QqGMnJyYSHh5OSonX1+vj46PnbdHRKgcI4IEOW87FymcIFL5QKlSppLaBKRmvQQS27/Fc1b3Gyh45O4RERTp8+TVpami1xaGFzt+no6BSNwjig35VSfwDfWZdHAatLz6T8MZm1FpCxivbX4n452xtWKngCoY5OTrLyUhkMBpRSNGzYkISEBL3LTUenlCnQAYnIdKXUMOBmtDGgT0RkRQG7lTrm/xRxVMU78Th4A66689EpOmlpaURERFCpUiUaNWoEgJeXV64Jozo6OiVPnl1pSqnmSqmflVIHgTuBt0TkibJ2Pq6u2hupS4ZgRDAYrBNTG+aeGKZTMSgNOQaLxcK5c+c4dOgQiYmJxMfH2yLcrheuFzmGn3/+mdDQUNscoLxS8UgFl2MAbVJu3759CQgIIDAwkDNnzgC6HEOxyStNNrAJmAC0BKYBP5V16m4RoUmTyiKCXPzET7ao1iJfWeUXjn+QK/24ztVTEeUYEhIS5N9//5WdO3fKzp075dSpU5KRkVEs2/KSY7haric5hqSkJLFYLCIisn//fmnZsqXTcjeCHEP37t3lzz//FBHtuuhyDFf3yS+YwEtEPhWRYyIyD2hU2s6wMGTJcbumZpJYqVp2J2KVMlGHuKFQqnQ+RaFLly62DMZ5yTG89tprALnkGIxGI/379+f48eOkpaXh7u5Oy5YtqVGjBg899BAhISGEhoby448/Ao4tiuXLlzN27FgAxo4dy5NPPknPnj2ZPn06jRo1cmiVNWvWjOjoaGJiYhg+fLht5v2WLbmFhNPS0hg3bhwhISG0adPGloXBXo5h06ZNDvtER0czdOhQwsLCCAsL459//nHYfuXKFXr16kXbtm0JCQnh559/BrTovoEDBxIWFkZwcDDLli0DYObMmQQGBhIaGupUsM/T09OWFy85OTnPRK9Llixh8ODsTPRDhgyhXbt2BAUF8cknnzjUN2fOHDp16sTWrVtZvHixLUPDww8/jNmsTbGYOHEi7du3JygoiOeee87pMYuCvRyDr6+vTY4hJ4cPH6ZXr16AJseQdf0OHz6MyWSyJcP19PR0kGNYs2bNddeKvt7JbwzIXSnVhmwdoMr2yyKyp7SNc0bWPCAXXzM1/czZG6rpGWgrOlcrx6CUsn3q1q1LrVq1MBgMzJgx46rlGFasWMG4cePYvn27gxzDE088USHkGFasWMGsWbO4ePGibf+cVHQ5huPHj+Pj48OwYcM4ffo0vXv35rXXXsNoNOpyDMUkPwd0HrDP3HjBblmAW0vLqPyoVElrAZn+daGyZ7x1rQHcq5eFOTcUpZC4uVBcjRxDamoqycnJVKlSBdAeOrVr18bd3d1W9mrkGABGjRrF3LlzGTduHEuXLrXlg6tIcgxDhw5l6NChbNy4kdmzZ9sSwNpT0eUYTCYTmzZtYu/evTRo0MCWuy/rhUiXYyg6+QnS9byWhhSWrHtIuQpetZK1BfdGZWaPTumTJceQkJDAoEGDWLhwIVOmTCEoKIiNGzc6lM2SY/Dw8KBRo0asXr0aT09PAgMDbelzcqbQycuR5SfHkOXQQOsWPHnyJDExMaxcuZJnn30WyJZjyC9Fv7OH4tViL8fg6upKo0aNHOQYVq9ezaxZs+jbty9z5sxhx44drF27lqVLl7JgwQLWrVuXZ93dunXjv//+49KlS1Sv7vjSlyXHYDAYHOQYPDw86NGjR75yDK+++qpDXVlyDDt37sTX15exY8fmKcdQ2BaQv7+/LVkqaHIMPXr0yLVvlhwDaN2ZP/74I97e3vj7+9OmTRuaNNG6+4cMGcK2bdtsDkiXYyg6ZTah9Goxnjbj63VBW/DpWLbG6FwTCivHMHnyZA4dOsSdd97Jl19+yaVLlxCREpVjsEcpxdChQ3nyyScrpBzDyZMnbY5yz549ZGRkONUEquhyDB06dCAuLo6YmBhAa4kGBgba9tPlGIpOqTogpVQ/pdQxpdRJpdTMfMp1UEqZlVIjCqozSw1VpQhVGlj7vj2vK9VwnVIkPzmG4OBgmjZtSs+ePcnIyCAsLIx33nmHp556iuDg4BKVY8jJqFGjKqwcw48//khwcDCtW7fm0UcfZdmyZU5bjBVdjsFoNDJv3jx69epFSEgIIsKECRMAXY6huBQox1DsijXdoONAHyAK2AmMFpHDTsr9BaQBX0gBSU7btDHK3r0WUu5wx6NtGrQAblkH9a/LHsNyT3mRYxARDh48SHp6OgaDgXr16lGzZs0iSXPrXB26HIMux1BUCmwBKY17lVJzrMsNlFKF6fPqCJwUkVMikgEsRVNVzclk4EfgopNtuTCbNZMNCZKty1qzbWF21amAZL1AKaWoU6cOvr6+BAcHU6tWLd35XGN0OQZdjqGoFKYL7gOgC5CVaiAJWFiI/eoBkXbLUdZ1NpRS9YChQO6+CcdyDymldmkf67o0AU/AAlTKO2JIp2JiMpkIDw/nwoULtnV+fn40bdpUz1pdhowcOTLfCL6Kyrhx43R9qGJQmCvWSUTaKqX2AohInFKqML9wZ6+fOfv73gVmiIg5v7dVEfkE+ASgdWtXAXBNzgB3gEpFn82oU24REWJjY4mMjMRkMmEwGKhRowYuLi56i0dHp5xRGAeUaR2nEbDpAVkKsV8UUN9u2R84l6NMe2Cp9cFRHRiglDKJyMq8q9V8mCETcAXSzHkX1alQpKWlER4eTlJSEqDNRG/YsKH+5qmjU04pzC93PrACqKmUehkYATxbiP12As2VUo2Bs8BdgINkqYjYwteUUouAX/N3PtmNnURvT6pyBbzDCmGKTnlGRDh//jznz59HRHBxccHf3x8/Pz+91aOjU44pjBzDEqXUbqAXWrfaEBE5UsBuiIhJKfUY8AdgRItwO6SUesS6Pd9xn7xQSmsBVblsnYRa2b841eiUM5KSkhARqlevTr169XB1dS1rk3R0dK6SwkTBNQBSgF+AVUCydV2BiMhqEWkhIk1F5GXruo+cOR8RGVtQCLZmj1WQzt86nFRFnwNUEcnMzCQ9PR3QZtiPHDmSMWPGMHnyZJKTk23liivHUB64XuQYsti5cydGo5Hly53/TKWCyzGEh4fTrl07WrduTVBQkMO8Ll2OoZgUlC4b+Bc4YP17AjABh8oqfXfbttpX801WGYaTP4tO6XGt5RgsFotER0fLnj175OjRo2KxWEpcjqEkuRHkGEQ02YSePXtK//795YcffnBapqLLMaSnp0taWpqIaFIMDRs2lLNnz4qILsdQ3E+BLSARCRGRUOvf5mjze5wrUl0Dsrr8DVkJgL2blZUpNx7fqtL5WElJSeHo0aNERERgNpsxGAy2lChZXI0cg4uLC5MmTcp1WleuXLFJIuhyDM5biO+//z7Dhw+3JQp1RkWXY6hUqZItS0V6errDvanLMRSPIocPicgepVSH0jCmSNRFi8XzbljWluhcJWazmXPnzhEdHQ2Aq6sr9evXx9fX1yHI4GrlGPLixRdf1OUY8pFjOHv2LCtWrGDdunXs3Lkzz2tS0eUY/Pz8iIyMZODAgZw8eZI333yTunXrAuhyDMWkQAeklHrSbtEAtAViSs2iwpKI5oBcqxRUUqekuLvk0zZZLBYOHzpkG++pWbMm9erVs2VLhquTYygMuhxD/nIMjz/+OK+//rrD/8QZFV2OAaB+/focOHCAc+fOMWTIEEaMGEGtWrUAXY6hOBSmBeRl990E/B9a6pyypQGIwflsV53yg8FgwM/Pj/j4eBo2bOggc5BFceQYvLy8CAoKYvfu3YSF5R+qn5cj0+UYNHbt2sVdd90FaJmiV69ejYuLC0OGDHEoV9HlGHKWCQoKYtOmTYwYoeVQ1uUYikF+A0Ro4dNvlvVAlf2nXTskMb6yyBgk46uaeY/C6ZQIJR2EYDab5fz583L58mWHdRaLJc997AfX9+zZI/Xr15eMjAxJSUmRxo0by19//SUiWlDCwIEDZf78+SIisn//fmnatKkcO3bMdpy33norV/0zZsyQqVOn2pazBqabNm0qhw8fFrPZLMOGDZP7779fRETuv//+XAPx06ZNk3vvvVf69+9vWzd69Gh54403bMt79+7Ndey33npLxo8fLyIix44dkwYNGkhaWpqcPn1agoKCnF6PUaNGyTvvvCMi2iB+QkKCw3V699135bHHHhMRkXXr1gkgp0+flrNnz0pqaqqIiKxYsUIGDx4sSUlJEh0dLSLaIL2vr6/TY2bh7Nyz6NSpk5w4cUJERFauXCmDBg0SEZEjR46Im5ubrF+/3sFOEZFDhw5Js2bNHGw4c+aM7Nu3T0JDQ8VsNsuFCxekZs2a8uWXX+ZrW0FcvnxZGjVqJLGxsRIbGyuNGjVyuA+ziImJEbPZLCIizzzzjMyePVtERCIjIyUlJUVEtHukefPmcuDAAdt+wcHBcu7cuauysaQo90EISikXETGjdbldV5hNCjJASWESMuhcL1y5coUjR44QFRVlCzQArRVU2C6z/OQYQkJC6NChA4899hgAoaGhvPvuu4wePZqAgABdjqGYcgyFpaLLMRw5coROnToRFhZG9+7dmTZtGiEhIYAux1Bc8pRjUErtES0H3FtAc+AHwDYBQ0R+ujYmOtK+vZI/V3tS7YUrZHQPpNLIQwXvpFNsSkKOwWQyERUVxaVLlwBwc3OjQYMGubo1dMo3uhyDLsdQVAozBlQNuAzcipaITVn/lokDArCYFbiDq2+LsjJBpxCICJcvXyYqKgqTyYRSitq1a1OnTh0MhnIrxquTB/ZyDDdaRmwfHx/uu+++sjaj3JGfA6ppjYA7SLbjyaJ0VOwKSfU6SeAKSkuHrXOdIiJcuHABk8mEl5cXDRo00AdpKzgjR44saxPKhHHjxpW1CeWS/ByQEU1xpzCyCteUM0dq0MgSA1Wvf6XOGw2LxYLFYsHFxQWDwUDDhg1JT0/XE4fq6OjkIj8HdF5E5l4zS4qAqwfgDVSpXtam6NiRkJBAREQEXl5eNGrUCAAvLy+HuSE6Ojo6WeTngK7b11VlNmuW61kQrgsyMjKIjIy0ZRAwGAyYzeYCJy7q6Ojc2OTngHpdMyuKSNyFytQ1Ah61ytqUGxoRISYmhrNnz9pyt9WtW5eaNWvqQQY6OjoFkudTQkRir6UhRcFsUprrdNW7dsoKi8XikDjU29uboKAgateuXeLOx2g00rp1a4KDg7n99tsd8pXpcgzZlJYcw99//423tzetW7emdevWzJ3rvGdepGLLMQBERETQt29fAgICCAwM5MyZM4Aux1BsynombFE/7doh+9bWF3kPkYzEPOYB65QU+WVCOH36tOzfv19iY2PzzWRwtehyDIWjtOQY1q9fLwMHDiywXEWXYxAR6d69u/z5558iokkyJCcni4gux1DcT7nsJzGbtHlAuOiJSK8VIqJpYdh9GjVuTGhYGL7VqqEMhlzbC/0pArocQ9nIMRSGii7HcPjwYUwmky0ZrqenJx4eHoAux1BciizHcD2QmWYAV0CVS/9Z7khPTyciIoLmZWyHLsegca3lGAC2bt1KWFgYdevWZd68eQQFBeUqU9HlGI4fP46Pjw/Dhg3j9OnT9O7dm9deew2j0ajLMRSTcumAzBkGMpULrmVtSAUnIyODhIQEDh06hMViYe+ePdSrV48aNWpc0zk9uhyDI9dajqFt27aEh4fj6enJ6tWrGTJkiNPxjooux2Aymdi0aRN79+6lQYMGttx9WS9EuhxD0SmXTQjJtOBaSW/qliabNm2iTZs2xMfHY7FYqFatGsHBwdSsWfOaTyjNkmMIDw8nIyPD1moICgpi165dDmWdyTEURF6OrLhyDMOGDQOy5Rj27dvHvn37OHv2bK45Uc4eileLvRzDvn37qFWrloMcQ0hICLNmzWLu3Lm4uLiwY8cOhg8fzsqVK+nXr1+u+qpWrWrrjhwwYACZmZm2vH72ZMkxAA5yDPv376dNmzb5yjFkXaNjx47x/PPP2+QY1q5dy4EDBxg4cGCecgxZwRH2nylTpuQq6+/vT2RkpG05KirKJihnT5Ycw969e3n55ZcB8Pb2xt/fnzZt2tCkSRObHMWePXts++lyDEWnXDogRCBZj4ArLVJTUxkxYgSHDx/GxcWFFi1a0KRJE1xdy7bN6e3tzfz585k3bx6ZmZncc889bN68mTVr1tjsnjJlCk8//TSgvR2/8sorHD9+HNAcwttvv52r3r59+7JgwQLbclYXXK1atThy5Iitiy0vlFIMHTqUJ598koCAAPz8/JzW66w7rVu3brYupOPHjxMREUHLli3zvQ69evXiww8/BLRuyZxRZwkJCdSsWRNXV1fWr19PeHg4AOfOncPDw4N7772XadOmsWfPHq5cuUJCQgIDBgzg3XffdWrjhQsXbI5yx44dWCwW2zna07JlS06dOmWzwdfXFw8PD44ePcq2bdvyPJfly5dz8eJFQGtFhYeHk5iYSJUqVfD29iY6OprffvvN6f7Tp0+3OS/7T87uN4DbbruNP//8k7i4OOLi4vjzzz+57bbbcpW7dOmSzZG++uqrjB8/HoAOHToQFxdHTIymx7lu3ToCAwNt+x0/ftxp16RO3pRLByQCZHqUtRkVChGxDaBWrlyZt99+mzlz5lC3bt3rKrGkLsdw7eUYli9fbrs2U6ZMYenSpU5bjBVdjsFoNDJv3jx69epFSEgIIsKECRMAXY6huOQpx3C90r69krcfbUi3VBNMiip4B50COXz4MI888gh9+vRh9uzZDttKQo5B58ZAl2PQ5RiKSrlsAWUqwFA6k+5uJFJSUnjmmWcICwtj06ZNfPbZZ6Snp5e1WTrlFHs5hhsNHx8f7r///rI2o9xRLh1QJYDADmVtRrnmt99+Izg4mFdffRWTycTDDz/Mvn37Cuz+0dHJj5EjR15XXbbXinHjxuHiUi6DisuUcumAMMPajRfK2opySXJyMnfeeScDBgzg9OnThIaG8s8///DRRx8VKvxYR0dHp6Qolw5IRDCnJZS1GeUSDw8PYmNjqVKlCvPmzWP37t106dKlrM3S0dG5ASmXbUYxuHI5RX9bLyy7du3Cx8eHZs2aoZTis88+w2g00qBBg7I2TUdH5wamXLaAMJtIM+sTvgoiISGByZMn07FjRx555BHbXI7GjRvrzkdHR6fMKZcOqIp3GrcPDilrM65bRIRly5bRqlUrFixYgMFgoG3btuU2UaIux1C2cgygzY1p3bo1QUFBdO/e3WkZuQHkGJ5++mmCgoIICAhgypQptntNl2MoJmWdjruon3btkHVv1hf5blaudOM6IidPnpTbbrtNAAGkS5cusn///mLXl58cw7VCl2MoHKUlxxAXFycBAQESHh4uIiLR0dFOy1V0OYYtW7ZI165dxWQyiclkks6dO8v69etFRJdjKO6nXLaAqKTgTGpZW3HdkZSURPv27fnjjz/w8fHh448/ZvPmzbkSOBYXpVSpfIqCLsdw7eUYvv32W4YNG2brts1KFpqTii7HoJQiLS2NjIwM0tPTyczMpFYtTZVZl2MoHqUahKCU6ge8BxiBz0TktRzb7wFmWBevABNFZH/BNQsYymX8RKni5eXFE088wcmTJ5k3b16eD4ryii7HoHGt5RiOHz9OZmYmPXr0ICkpialTpzJmzJhc5Sq6HEOXLl3o2bMnderUQUR47LHHbNkGdDmG4lFqT3GllBFYCPQBooCdSqlVInLYrthpoLuIxCml+gOfAJ0KrFwAS+2SN7qcERMTw/Tp0+nVqxf33XcfALNnzy61bNVSRmmbdDkGR661HIPJZGL37t2sXbuW1NRUunTpQufOnWnRooVDuYoux3Dy5EmOHDliGxPq06cPGzdupFu3boAux1AcSrMLriNwUkROiUgGsBQYbF9ARP4RkazXzW2Af6FqFgWdm5WkreUKi8XCZ599RsuWLfnqq6/43//+R2ZmJlC0B295QZdjKBolLcfg7+9Pv379qFKlCtWrV6dbt27s35+7o6KiyzGsWLGCzp074+npiaenJ/3793fI8q3LMRSd0nRA9YBIu+Uo67q8eABwmnNdKfWQUmqXUkp72ohwttqNKcd98OBBunXrxoQJE4iLi6N3796sXbu2zKUSrgW6HIPGtZZjGDx4MJs2bcJkMpGSksL27dudJqit6HIMDRo0YMOGDZhMJjIzM9mwYYPDddDlGIpOaTogZ6/iTl/3lFI90RzQDGfbReQTEWkvWZlcBT774kBJ2VkuSE1NZcaMGbRp04YtW7ZQq1Ytvv32W/7880+aNy9rsexrhy7HcO3lGAICAujXrx+hoaF07NiRBx98kODg4FzlKrocw4gRI2jatCkhISG2AJDbb78d0OUYik1phdcBXYA/7JZnAbOclAsF/gNaFKbedu2Qta/WlzmPf+A8/rCCkpaWJq1atRKllEyaNEni4uKuyXGvhzBsnfLBuXPnpHfv3mVtRpnw9ttvy2effVbWZtgoL2HYpRlKthNorpRqDJwF7gLuti+glGoA/ATcJyLHC1uxcgGTqvhdcFFRUXh4eFCtWjXc3NxYtGgRAJ06FRynoaNzrbGXY7jRMmL7+PjYAoF0Ck+pdcGJiAl4DPgDOAJ8LyKHlFKPKKUesRabA/gBHyil9tnGeAqqG6Fe/VqlYvf1gMlk4p133iEgIMAhwqdTp06689G5rtHlGHSKQqleMRFZDazOse4ju+8PAg8WtV4FTJrS86rtux7Zvn07Dz/8sC3KKCEhAZPJpN/cOjo6FY7ymQlBgE8PFVisPBEfH8+kSZPo0qUL+/fvp2HDhvzyyy8sX75cdz46OjoVknL5ZEszAap8+k5nxMXFERgYyIULF3BxceGpp55i9uzZDnNNdHR0dCoa5dIBVTYAhy+VtRklhq+vL/379+f48eN8+OGHhITomb51dHQqPuWyGaEQCKpe1mYUm/T0dObOncuGDRts6xYsWMDGjRt15+MEXY6hbOUY7LMNBAcHYzQaiY2NzVVOpGLLMaxfv94h24K7uzsrV64EdDmGYlPWceBF/bRrh2xY2EjEZM4nCv76Ze3atdKiRQsBJCAg4Jqmoy8O18M8IF2OoXCUlhyDPatWrZKePXs63VbR5Rhy1uXr6yvJyckiossxFPdTLrvgMi5bWLP+DL17NylrUwrNxYsXeeqpp1i8eDGgJZ784IMPbDmxygMvvPBCqdRblFT7Xbp04cABLQtGXnIMPXr04NFHHy2SHMPkyZPZtWsXSimee+45hg8fjqenpy3T9PLly/n1119ZtGgRY8eOpVq1auzdu5fWrVuzYsUK9u3bh4+PD6DJMWzZsgWDwcAjjzxCREQEAO+++26uGf1paWlMnDiRXbt24eLiwttvv03Pnj0d5Bjef/99brnlFts+0dHRPPLII7a0Nx9++CFdu3Z1OJ/BgwcTFxdHZmYmL730EoMHDyY5OZmRI0cSFRWF2Wxm9uzZjBo1ipkzZ7Jq1SpcXFzo27cv8+bNy/P6f/fdd4wePdrptiVLlvDQQw/ZlocMGUJkZCRpaWlMnTrVts3T05Mnn3ySP/74g7feeoszZ84wf/58MjIy6NSpk+13MXHiRHbu3ElqaiojRoy46vvPXo4BsMkx5Dyfw4cP21qdPXv2ZMiQIbnqWr58Of3798fDwwPQ5BjGjh2rR6wWkfJ5pQSOHr1ULhxQVuLQGTNmEB8fj7u7O88++yzTp0+nUqVKZW1euUKXY9C41nIMWaSkpPD777875Lezp6LLMWTl+ANYunQpTz75pG1Zl2MoHuXSAVlE4eJSPoavEhIS+N///kd8fDy33XYbCxcupGnTpmVtVrEoCVGw4qDLMThyreUYsvjll1+46aabbC2InFR0OYYszp8/z7///psrkakux1B0yqUDcjNm4up6/Tqg5ORkXFxccHNzw9fXl48++giz2cydd95ZIeUSSpssOYaEhAQGDRrEwoULmTJlCkFBQWzcuNGhrDM5hrCwsHzrz8uRFVeO4dlnnwWy5RjyS9Hv7KF4tdjLMbi6utKoUSMHOYbVq1cza9Ys+vbty5w5c9ixYwdr165l6dKlLFiwgHXr1jmtd+nSpXl2v0G2HIPBYHCQY/Dw8KBHjx75yjG8+uqrDnVlyTHs3LkTX19fxo4dm6ccQ2FbQP7+/rZkqaCluurRo0eufbPkGEDrzvzxxx8dnPz333/P0KFDc2Wg1+UYikFZD0IV9dOuHfLH803k2LFL+Q7ClRU///yzNGjQQObOnVvWppQI11sQwp49e6R+/fqSkZEhKSkp0rhxY/nrr79ERAtKGDhwoMyfP19ERPbv3y9NmzaVY8eOiYiI2WyWt956K1f9M2bMkKlTp9qWswammzZtKocPHxaz2SzDhg2T+++/X0RE7r//fvnhhx8c6pg2bZrce++90r9/f9u60aNHyxtvvGFb3rt3b65jv/XWWzJ+/HgRETl27Jg0aNBA0tLS5PTp0xIUFOT0eowaNUreeecdEdEG8RMSEhyu07vvviuPPfaYiIisW7dOADl9+rScPXtWUlNTRURkxYoVMnjwYElKSpLo6GgRyR5Yd0Z8fLz4+vrKlStXnG4XEenUqZOcOHFCRERWrlwpgwYNEhGRI0eOiJubm6xfv97BThGRQ4cOSbNmzRxsOHPmjOzbt09CQ0PFbDbLhQsXpGbNmvLll1/meezCcPnyZWnUqJHExsZKbGysNGrUSC5fvpyrXExMjJjNWpDTM888I7Nnz851nuvWrcu1X3BwsJw7d+6qbCwpyksQwvXbjMgHMStaVL6+9G8iIiIYMmQIgwcPJiIigj/++MOmKaJTcuhyDNdejgFgxYoV9O3bN9/J0RVdjgHgzJkzREZG0r17d4e6dTmGYlLWHrCon3btkD+faSzy68lCvAeUPhkZGfLmm2+Kh4eHAOLl5SXvvffedR9eXViuhxaQTvlAl2PQ5RiK+imXY0CWSgoMZT+WcunSJVt0DmgD0++88w716uUn/KqjUzHR5Rh0OYaiUi4dkFGZrwsH5OfnR/Xq1WncuDELFixgwIABZW2Sjk6ZMnLkyLI2oUwYN25cWZtQLimXDihDKkM9r4ILljAiwpIlS+jYsSMtWrRAKcXixYvx9va2TUjT0dHR0Skc5TMIwWjEEuhXcMES5NixY/Tu3Zv77ruPSZMmoXWpat0OuvPR0dHRKTrl0gFlmITVq69N4r+0tDSee+45QkNDWbduHX5+ftx7773X5Ng6Ojo6FZly2QVnyBQM12AMaM2aNUycOJGTJ08CMH78eN544w2HlBw6Ojo6OsWjXLaAXNwzS90BRUdHM2jQIE6ePElgYCAbN27k888/151PGaDLMZStHENCQgK33347YWFhBAUF8eWXXzotJ1Kx5RgAnn76aYKCgggICGDKlCm2e02XYygmZR0HXtRPu3bI97ND5c8/S34ekNlsFovFYlt+/fXX5dVXX5X09PQSP1Z54XqYB6TLMRSO0pJjePnll+Xpp58WEZGLFy+Kr6+v099ERZdj2LJli3Tt2lVMJpOYTCbp3LmzLbuDLsdQvE+5bAG5ubvQp0/JJvTct28fXbt2tcklgPa2M3PmTD1rtQ1VSp/C06VLF1sG47zkGF577TWAIskxjBs3jpCQEEJDQ/nxxx8BxxbF8uXLGTt2LABjx47lySefpGfPnkyfPp1GjRo5tMqaNWtGdHQ0MTExDB8+3DbzfsuWLbmOnZaWZjt2mzZtbFkY7OUYNm3a5LBPdHQ0Q4cOJSwsjLCwMP75559c59OrVy/atm1LSEgIP//8M6DlKBw4cCBhYWEEBwezbNkyAGbOnElgYCChoaFOW4hKKZKSkhARrly5QrVq1ZxKDixZsoTBgwfblocMGUK7du0ICgrik08+sa339PRkzpw5dOrUia1bt7J48WJbhoaHH34Ys9kMwMSJE2nfvj1BQUElkgjXXo7B19fXJseQk8OHD9OrVy9Ak2PIun5KKdLS0sjIyCA9PZ3MzExq1aoFaHIMa9aswWQyXbWdNxRl7QGL+mnXDlk5p43I7gsFvwYUgsTERHniiSfEYDAIIK1bt3ZoBd3oOL5Jlda/NX+y3uxNJpOMGDFCfvvtNxEReeKJJ+Tdd9/NVd7Hx0cSEhKkTZs2sm/fvgLrf/rpp53mgrNvUfzwww8OueAGDhxoe3ufMmWKfPHFFyIism3bNunVq5eIaLngNm3aJCIi4eHh0qpVq1zHnjdvnowdO/b/2zv36KrqK49/NhCNBBJcMEYxUiE8EpKQEEKbdkaSVkRERAEHx1HAmrUQysNBUXzUDgvro4JK0SUdjAo6XaIloNUZ5akBCpQgBAQDrEwRDQ8JIRCp0IDs+eOce/O6SS7CfYX9Wetw77nn9zu/fTcnZ9/f4+yvqjo506655ho9efJkk7ngRo0aVScX3LFjx+rYe/r0aW9+uPLyck1MTNSzZ8/q4sWL6/xKP3bsmFZUVGjPnj2913xlZWWD9qqqqjQ3N1evvPJKjYmJ0Q8//NCnXV26dNGqqirvvifP2nfffacpKSl65IiTvxHQd955R1Wd62vo0KFaXV2tqqoTJkzQhQsX1ql/5swZzcnJ0W3btjVo87nnntP09PQG2+TJkxuUnTVrlj755JPe/ZkzZ+qsWbMalLvzzju911VBQYECXtsffPBBjYuL09jYWH3sscfq1Bs4cKBu3rzZp2+CjfWAAsn3wInq8zqFqrJ06VJ69+7tHWO///77KSwstIzVjaIB2prGI8fQsWNHjh49GhA5hokTJ3r3f4gcg6c3UV+OYdKkSWRkZDBs2DCvHENt1q1b532CvrYcQ1OsXr2aCRMmAE3LMfTp04eBAwfWkWNYuXIl06dPZ+3atcTFxREbG+uVY1iyZInPRwqWLVtGRkYGBw4coLi4mEmTJvmc5/Elx5Cenk52drZXjsFjsy85hoyMDFatWuUV2nv33XfJzMykb9++7Ny5s460hYeHHnqI4uLiBlv9TNgev9SnMTmGwsJC+vbtS2FhoVeOobS0lJKSEsrKyti/fz+rV6+uk43dI8dg+E9EBiBF4DyCxJEjRxg2bBgjRoygrKyMrKwsioqKmDNnzkWXQiQS8Mgx7Nu3j+rqaq+IW0pKCps3b65T1pccQ3M0Fsh+qBzDiBEjgBo5Bs9Ncf/+/XVu0J62LzS15RiKi4uJj4+vI8eQlpbGo48+ysyZM2nTpg2bNm1i5MiRvPfeewwePLjB+d544w1GjBiBiNC9e3e6du3Krl27GpTzyDEAdeQYtm3bRt++fZuUY/D4aPfu3cyYMcMrx7Bq1Sq2b9/OzTff3KgcQ0ZGRoNtypQpDcomJCTw9ddfe/fLysro3Llzg3IeOYatW7fy1FNPARAXF8fSpUvJzs6mXbt2tGvXjptuuomNGzd665kcw7kTkQFIvP/8MNq3b09paSmxsbG8/PLLbNy4kczMzAtlnhEg4uLimDt3LrNnz+b06dPcddddrFu3jpUrVwJOT2nKlCk8/PDDgPPr+Omnn/b2KM6ePcsLL7zQ4LyDBg2qo/LpUUSNj4+npKTEq3jaGCLC8OHDeeCBB0hOTvaulKx/Xl/qpgMGDPDq2ezZs4evvvqKXr16NemH66+/nnnz5gGOSmz93sjx48e54ooriIqK4pNPPmHfvn0AHDhwgLZt23L33Xczbdo0tmzZwokTJzh+/DhDhgxhzpw5Pm3s0qULq1atApz5p927d9OtW0M14l69enl7L8ePH+fyyy+nbdu27Nq1q86Nuv53Wbx4MYcPHwacXtS+ffuoqqoiJiaGuLg4vvnmGz766COf9c+lB3TjjTeyfPlyKisrqaysZPny5Q1E5cD5geoJpM888wz33nuv1w+FhYWcOXOG06dPU1hYSHJysrfenj17SElJ8Wmn0QihHgM8161fP3Tpb3+qWnVuK9PWrVvnHcdVVS0uLg4b7Y5wJtxWwamqDh06VN98801VVd2+fbvm5ORoz549NTExUWfMmFFnDu+DDz7QzMxMTUpK0uTkZJ02bVqD83/77bc6ZswYTUlJ0T59+mhBQYGqOvM+3bp105ycHJ04cWKTekBFRUUKeFdPqTrzL6NGjdK0tDRNTk7W++67r0HbJ0+e1LFjx2pqaqpmZGR4dWaamgM6dOiQDhs2TFNTUzU9PV3Xr19fx0/l5eWanZ2t/fr107y8PE1KStK9e/fqxx9/rGlpaZqenq5ZWVlaVFSkBw4c0P79+2taWpqmpqbWsd/D/v379YYbbtDU1FRNSUnRt956y6ddM2fO1FdffVVVVU+dOqWDBw/WtLQ0vf322zUnJ8enHpCq6qJFizQ9PV3T0tI0MzNTN2zY4PVzUlKSDhkyRIcPH37eekCqqq+99pomJiZqYmKid95OVfWJJ57Q999/X1Wd//fu3btrjx49NC8vT0+dOqWqzlzUuHHjvNfS1KlTvfUPHTqk/fv3P2/7LhSRMgckGoAhgECSlSX66C1Z/Gzcaq66qvl8cBUVFTzyyCPk5+eTl5dHfn5+EKxsOZSUlNT5lWcYjXHw4EHGjBnDihUrQm1K0HnxxReJjY0lLy8v1KYAvv9uReQzVc0KkUk+icghuKMnovjyy2NNllFVFi5cSFJSEvn5+URFRdG5c+eAjLkbhlFXjuFio0OHDowdOzbUZkQcEZmKR7UVrVs3Hjt37drF+PHjKSwsBCA3N5d58+Z5nwcxDCMwmByDcS5EZAA6izS6CK6srIz09HSqq6vp1KkTzz//PKNHj7al1eeBNrHc2TCM8CKSRnkiMgBdGh1FfLzvvFcJCQmMHj2aVq1a8eyzz3o1340fRnR0NBUVFXTs2NGCkGGEOapKRUUF0dHRoTbFLyIyALW/7FK6dHQemDt48CBTp05l/Pjx5ObmAjB//nxatYrI6a2wIyEhgbKyMsrLy0NtimEYfhAdHU1CQkKozfCLiAxArY6d5Pudh5m3aSmPP/44VVVVlJaWUlRUhIhY8LmAREVF0bVr11CbYRhGCySgd2oRGSwiu0WkVEQe8XFcRGSue3y7iPj1NOie/f8g+5c3M3nyZKqqqrjlllsoKCiwISLDMIwIImDPAYlIa2APcANQBhQBd6rqF7XKDAEmA0OAnwC/V9WfNHXe+HjR8nJQdYaHXnrpJW699VYLPoZhGE1wsT0H9GOgVFX/pqrVwCLg1nplbgXedB/U3Qh0EJGrmjrp0aMgCA/c8ytKSkq47bbbLPgYhmFEIIGcA7oa+LrWfhlOL6e5MlcDB2sXEpFxwDh39x+gO15Y8AovLHjlwloceXQCjoTaiDDBfFGD+aIG80UNTScZDAGBDEC+uiX1x/v8KYOqzgfmA4jI5nDrRoYK80UN5osazBc1mC9qEJHNzZcKLoEcgisDrqm1nwDUF8vwp4xhGIbRAglkACoCeohIVxG5BPg34M/1yvwZGOOuhssGjqvqwfonMgzDMFoeARuCU9UzIjIJWAa0Bl5X1Z0iMt49/gfgf3FWwJUC3wH+JFSa33yRiwbzRQ3mixrMFzWYL2oIO19EnByDYRiG0TKwlAGGYRhGSLAAZBiGYYSEsA1AgUrjE4n44Yu7XB9sF5H1IpIeCjuDQXO+qFWuv4h8LyK3B9O+YOKPL0QkV0SKRWSniBQG28Zg4cffSJyIfCAi21xftEgBHxF5XUQOi8iORo6H130z1JrgvjacRQv/B3QDLgG2Ab3rlRkCfITzLFE28NdQ2x1CX/wMuNx9f9PF7Ita5VbjLHK5PdR2h/C66AB8AXRx968Itd0h9MVjwO/c9/8EHAUuCbXtAfDFACAT2NHI8bC6b4ZrDyggaXwilGZ9oarrVbXS3d2I8zxVS8Sf6wKc/IIFwOFgGhdk/PHFvwNLVPUrAFVtqf7wxxcKtBcnb1c7nAB0JrhmBh5VXYPz3RojrO6b4RqAGkvRc65lWgLn+j3zcH7htESa9YWIXA0MB/4QRLtCgT/XRU/gchH5VEQ+E5ExQbMuuPjji5eBZJwH3T8H7lfVs8ExL6wIq/tmuOoBXbA0Pi0Av7+niPwcJwD9S0AtCh3++GIOMF1Vv2/hSWr98UUboB9wPXAZsEFENqrqnkAbF2T88cWNQDHwCyARWCEia1W1KsC2hRthdd8M1wBkaXxq8Ot7ikgfIB+4SVUrgmRbsPHHF1nAIjf4dAKGiMgZVX0vKBYGD3//Ro6o6t+Bv4vIGiAdRyalJeGPL34JPKvOREipiOwFkoBNwTExbAir+2a4DsFZGp8amvWFiHQBlgCjW+Cv29o06wtV7aqq16rqtcBi4FctMPiAf38j7wPXiUgbEWmLk42+JMh2BgN/fPEVTk8QEYnHyQz9t6BaGR6E1X0zLHtAGrg0PhGHn774DdAReMX95X9GW2AGYD99cVHgjy9UtUREPga2A2eBfFX1uTw3kvHzungSWCAin+MMQ01X1RYn0yAibwO5QCcRKQP+E4iC8LxvWioewzAMIySE6xCcYRiG0cKxAGQYhmGEBAtAhmEYRkiwAGQYhmGEBAtAhmEYRkiwAGSEJW4m6+Ja27VNlD1xAdpbICJ73ba2iMhPf8A58kWkt/v+sXrH1p+vje55PH7Z4WZ37tBM+QwRGXIh2jaMC40twzbCEhE5oartLnTZJs6xAPhQVReLyCBgtqr2OY/znbdNzZ1XRBYCe1T1qSbK3wNkqeqkC22LYZwv1gMyIgIRaSciq9zeyeci0iALtohcJSJravUQrnM/HyQiG9y6fxKR5gLDGqC7W/cB91w7ROQ/3M9iROR/XG2ZHSJyh/v5pyKSJSLPApe5dvzRPXbCfX2ndo/E7XmNFJHWIjJLRIrE0Wm5zw+3bMBNJCkiPxZHC2qr+9rLzQowE7jDteUO1/bX3Xa2+vKjYQSNUGpB2GZbYxvwPU7yyGJgKU7Wjlj3WCecJ7k9PfgT7uuDwOPu+9ZAe7fsGiDG/Xw68Bsf7S3A1Q4C/hX4K04iz8+BGJwU/juBvsBI4NVadePc109xehtem2qV8dg4HFjovr8EJzPxZcA44Nfu55cCm4GuPuw8Uev7/QkY7O7HAm3c9wOBAvf9PcDLteo/Ddztvu+AkxcuJtT/37ZdnFtYpuIxDOCkqmZ4dkQkCnhaRAbgpJW5GogHDtWqUwS87pZ9T1WLRSQH6A38xU1TdAlOz8EXs0Tk10A5Tlbx64Gl6iTzRESWANcBHwOzReR3OMN2a8/he30EzBWRS4HBwBpVPekO+/WRGgXXOKAHsLde/ctEpBi4FvgMWFGr/EIR6YGT3TiqkfYHAcNEZJq7Hw10oWXmiDPCHAtARqRwF46SZT9VPS0iX+LcPL2o6ho3QN0MvCUis4BKYIWq3ulHGw+p6mLPjogM9FVIVfeISD+cnFrPiMhyVZ3pz5dQ1VMi8imOPMAdwNue5oDJqrqsmVOcVNUMEYkDPgQmAnNxcp19oqrD3QUbnzZSX4CRqrrbH3sNI5DYHJARKcQBh93g83PgR/ULiMiP3DKvAq/hSBNvBP5ZRDxzOm1FpKefba4BbnPrxOAMn60Vkc7Ad6r638Bst536nHZ7Yr5YhJME8jqcBJq4rxM8dUSkp9umT1T1ODAFmObWiQP2u4fvqVX0W5yhSA/LgMnidgdFpG9jbRhGoLEAZEQKfwSyRGQzTm9ol48yuUCxiGzFmaf5vaqW49yQ3xaR7TgBKcmfBlV1C87c0CacOaF8Vd0KpAGb3KGwx4Hf+qg+H9juWYRQj+XAAGClOhLS4Gg5fQFsEZEdwH/RzAiFa8s2HPmB53B6Y3/BmR/y8AnQ27MIAaenFOXatsPdN4yQYMuwDcMwjJBgPSDDMAwjJFgAMgzDMEKCBSDDMAwjJFgAMgzDMEKCBSDDMAwjJFgAMgzDMEKCBSDDMAwjJPw/H6ePjNMAJHAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_bin_test = label_binarize(y_test, classes = ['zone_1','zone_2','zone_3', 'zone_4', 'zone_5', 'zone_6', 'zone_7', 'zone_8', 'zone_9'])\n",
    "n_classes = y_bin_test.shape[1]\n",
    "\n",
    "y_score = pipe.predict_proba(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "lw = 2\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"blue\", \"orange\", \"red\",\"black\", \"gray\", \"yellow\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>start_pitch_zone_zone_9</td>\n",
       "      <td>0.181271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start_pitch_zone_zone_7</td>\n",
       "      <td>0.114634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start_pitch_zone_zone_1</td>\n",
       "      <td>0.111615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start_pitch_zone_zone_6</td>\n",
       "      <td>0.104527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>start_pitch_zone_zone_5</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Variable  Importance\n",
       "0  start_pitch_zone_zone_9    0.181271\n",
       "1  start_pitch_zone_zone_7    0.114634\n",
       "2  start_pitch_zone_zone_1    0.111615\n",
       "3  start_pitch_zone_zone_6    0.104527\n",
       "4  start_pitch_zone_zone_5    0.064072"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b230f2c3a454b9d31000333b2514d91645996906422c6e0b66023d65cd0ad59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

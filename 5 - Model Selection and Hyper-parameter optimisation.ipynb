{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5 of 6 - Model Selection and Hyper-parameter optimisation\n",
    "**Author:** Alexandru Mihalache \n",
    "\n",
    "**Date:** November 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plotting liibs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "#Football libs\n",
    "import socceraction\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from mplsoccer import Pitch, Sbopen, VerticalPitch\n",
    "import socceraction.spadl as spadl\n",
    "import matplotsoccer as mps\n",
    "import socceraction.xthreat as xthreat\n",
    "import socceraction.spadl as spadl\n",
    "from socceraction.vaep import VAEP\n",
    "\n",
    "# utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "# fuzz is used to compare TWO strings\n",
    "from fuzzywuzzy import fuzz\n",
    "# process is used to compare a string to MULTIPLE other strings\n",
    "from fuzzywuzzy import process\n",
    "import load_data\n",
    "import pre_processing_utils as ppu\n",
    "from itertools import cycle\n",
    "\n",
    "# ML libs\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, label_binarize, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Model scoring \n",
    "from sklearn.metrics import classification_report, roc_auc_score, plot_roc_curve, confusion_matrix, confusion_matrix, plot_confusion_matrix, mean_squared_error, r2_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pre_processing_utils' from '/Users/alexmihalache/Library/CloudStorage/OneDrive-Personal/BrainStation/Capstone/Capstone Project - FAWSL Analysis/pre_processing_utils.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(ppu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "xt, xt_test, vaep, vaep_test, games, games_test, players, players_test, target_players = load_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for modelling\n",
    "modeling_train_df = vaep.copy()\n",
    "modeling_test_df = vaep_test.copy()\n",
    "modeling_xt_train_df = xt.copy()\n",
    "modeling_xt_test_df = xt_test.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use caching to avoid memory issues - given the size of our data\n",
    "from tempfile import mkdtemp\n",
    "cachedir = mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach:**\n",
    "\n",
    "- Try a few manual models - with different feature combinations, mainly focusing on regularisation, learning rate and depth of trees\n",
    "- Try to identify ranges for the hyperparams - rather than set wide ranges that will be computationally expensive and take a long time\n",
    "- Run a gridsearch in the ranges identified for the features identified\n",
    "- Review results and if needed re-run manual checks\n",
    "- Re-do gridsearch with new params - where necessary\n",
    "\n",
    ">PLEASE NOTE EACH GRIDSEARCH IN THIS NOTEBOOK TAKES UP TO 2 HOURS TO RUN - DO NOT RUN THE NOTEBOOK IN ITS ENTIRETY IF NOT NECESSARY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the previous notebook, we decided to take forward only the team based models as they showed more consistent results overall. \n",
    "- In this notebook will expand on the previous modelling approach for a number of reasons. \n",
    "    1. **Cross-validation** - this is to improve the model through hyper-parameter tuning. Cross validation allows me to train the model across different folds of the training data - where a fold is a slice of the data that gets saved for validation, not training, meaning that we get to train and validate the model across different datasets, getting a better view of how the model might perform with new data.\n",
    "    2. **Tuning Hyperparameters** - the models we are using are designed to be flexible and applicable in a lot of different modeling scenarios. Therefore they have a lot of different configs available to enable this flexbility. I need to find the best combination of those parameters for this use case, which gives a well regularised model that isn't over-fit, but that performs well on new data. \n",
    "\n",
    "    - Cross-validation and tuning hyperparameters are normally done together as I am doing here.\n",
    "    - I will not do an exhaustive search for all possbile combinations are this would take considerably longer, and will focus on hyper-parameters that reduce over fitting and are known to give better test scores.\n",
    "\n",
    "\n",
    "The final models will be collected at the bottom of this notebook and then validated further so we can understand their performance in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Team - VAEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I will describe the high level steps taken for this first model, then replicate the approach for the remainder 3 models following. Only adding in commentary where I perform something not covered in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 - set data and column transformer**\n",
    "\n",
    "NOTE: here I use 2 different column transformers, one for a simple pipeline as the previous column transformer used in notebook 4 and one for the gridsearch - where I have more control over the steps as part of the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'vaep_value')\n",
    "\n",
    "# set column transformer mode\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-vaep')\n",
    "\n",
    "# define column transformed for pipeline\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer for GridSearchCV\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 - Run manual search for hyper-param range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Regressor - Depth 5 ***\n",
      "Random Forest Train Score:  0.8160415586816594\n",
      "Random Forest Test Score:  0.7333054326388806\n",
      " \n",
      "*** Random Forest Regressor - Depth 10 ***\n",
      "Random Forest Train Score:  0.9252032890968886\n",
      "Random Forest Test Score:  0.7696565710141716\n",
      " \n",
      "*** Random Forest Regressor - Depth 15 ***\n",
      "Random Forest Train Score:  0.9572404369298733\n",
      "Random Forest Test Score:  0.770458041532036\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 ***\n",
      "XGB Regressor Train Score:  0.9773771604640682\n",
      "XGB Regressor Test Score:  0.7774353046416602\n",
      " \n",
      "*** xGBoost Regressor - Depth 10 ***\n",
      "XGB Regressor Train Score:  0.9996424598218189\n",
      "XGB Regressor Test Score:  0.7722946268899323\n",
      " \n",
      "*** xGBoost Regressor - Depth 15 ***\n",
      "XGB Regressor Train Score:  0.9997710007647611\n",
      "XGB Regressor Test Score:  0.7744886387854324\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Random Forest Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 10 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 15 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=15))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 10 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 15 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=15))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Re-run manual search to find bounds for the ranges to use in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Regressor - Depth 17 ***\n",
      "Random Forest Train Score:  0.9614962650539055\n",
      "Random Forest Test Score:  0.7760280656011058\n",
      " \n",
      "*** Random Forest Regressor - Depth 20 ***\n",
      "Random Forest Train Score:  0.9645378642352276\n",
      "Random Forest Test Score:  0.7728209532690797\n",
      " \n",
      "*** Random Forest Regressor - Depth 25 ***\n",
      "Random Forest Train Score:  0.9710229219176514\n",
      "Random Forest Test Score:  0.7733866093735826\n",
      " \n",
      "*** xGBoost Regressor - Depth 2 ***\n",
      "XGB Regressor Train Score:  0.8462431898067477\n",
      "XGB Regressor Test Score:  0.7393302816944547\n",
      " \n",
      "*** xGBoost Regressor - Depth 3 ***\n",
      "XGB Regressor Train Score:  0.9242034953688028\n",
      "XGB Regressor Test Score:  0.769936203996455\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Random Forest Regressor - Depth 17 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=17))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 20 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=20))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 25 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=25))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 2 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=2))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 3 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=3))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The reason to running the 2 sets of manual search is to find the range of the hyper-params that achieve our objectives of regularising the model and still giving us good performance in the test dataset, but critically to allow me to limit the number of variations in the grid search. \n",
    "- This approach does carry the risk that there may be other combinations outside of the set ranges which give better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 - Run gridsearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 91 candidates, totalling 455 fits\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=80; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=sqrt, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   3.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   4.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   4.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=sqrt, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   6.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   6.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   7.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   7.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   9.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=  11.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=  11.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=sqrt, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   9.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=  15.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=100; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=sqrt, model__n_estimators=140; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  12.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  15.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  14.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  16.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  19.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=  20.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=sqrt, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  13.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  20.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  23.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  25.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  25.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  24.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=  24.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=sqrt, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  16.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  16.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  17.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  17.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=  17.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  20.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=  21.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  24.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=  25.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  28.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  30.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  30.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  29.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=  29.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=sqrt, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  18.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=  19.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  23.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=  24.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  27.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  29.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  29.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  29.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=  28.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=  33.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=120; total time=   3.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=sqrt, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  20.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  21.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  22.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  22.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=  22.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  26.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=  27.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  31.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  32.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  33.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  32.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=  32.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  36.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  37.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  38.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  37.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=  38.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   6.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   4.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   5.7s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid = [\n",
    "     {\n",
    "        'model': [RandomForestRegressor(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(2, 17, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBRegressor(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid = GridSearchCV(estimator, param_grid, cv = 5, verbose = 2)\n",
    "fitted_grid = grid.fit(X_train, y_train)\n",
    "\n",
    "# fitted_grid.best_estimator_\n",
    "# fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Explore GridSearchCV results**\n",
    "\n",
    "- Here I look at which combination gives me the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4.399968</td>\n",
       "      <td>0.042012</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.435324</td>\n",
       "      <td>-0.058706</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>0.375228</td>\n",
       "      <td>0.399281</td>\n",
       "      <td>0.277238</td>\n",
       "      <td>0.181177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4.374043</td>\n",
       "      <td>0.068614</td>\n",
       "      <td>0.033129</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.430918</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>0.267397</td>\n",
       "      <td>0.375161</td>\n",
       "      <td>0.258771</td>\n",
       "      <td>0.149852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3.211093</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.030821</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>0.212421</td>\n",
       "      <td>0.138343</td>\n",
       "      <td>0.122829</td>\n",
       "      <td>0.291122</td>\n",
       "      <td>0.237063</td>\n",
       "      <td>0.109554</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5.688128</td>\n",
       "      <td>0.137392</td>\n",
       "      <td>0.033125</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.430948</td>\n",
       "      <td>-0.143982</td>\n",
       "      <td>0.245534</td>\n",
       "      <td>0.256299</td>\n",
       "      <td>0.393311</td>\n",
       "      <td>0.236422</td>\n",
       "      <td>0.203784</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.655732</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.032792</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.404752</td>\n",
       "      <td>-0.167093</td>\n",
       "      <td>0.231453</td>\n",
       "      <td>0.184793</td>\n",
       "      <td>0.389565</td>\n",
       "      <td>0.208694</td>\n",
       "      <td>0.206619</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4.329026</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.031671</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.881851</td>\n",
       "      <td>-47.209353</td>\n",
       "      <td>-27.040913</td>\n",
       "      <td>-16.651056</td>\n",
       "      <td>-20.219825</td>\n",
       "      <td>-27.400600</td>\n",
       "      <td>10.601310</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.279602</td>\n",
       "      <td>0.104560</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.889016</td>\n",
       "      <td>-47.184387</td>\n",
       "      <td>-27.089479</td>\n",
       "      <td>-16.645945</td>\n",
       "      <td>-20.237177</td>\n",
       "      <td>-27.409201</td>\n",
       "      <td>10.590153</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3.260674</td>\n",
       "      <td>0.093230</td>\n",
       "      <td>0.031827</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.889016</td>\n",
       "      <td>-47.184387</td>\n",
       "      <td>-27.108559</td>\n",
       "      <td>-16.628963</td>\n",
       "      <td>-20.237177</td>\n",
       "      <td>-27.409620</td>\n",
       "      <td>10.593496</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4.338018</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>0.032612</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.875187</td>\n",
       "      <td>-47.395441</td>\n",
       "      <td>-26.959851</td>\n",
       "      <td>-16.655387</td>\n",
       "      <td>-20.211795</td>\n",
       "      <td>-27.419532</td>\n",
       "      <td>10.671940</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.541271</td>\n",
       "      <td>0.065275</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-25.890679</td>\n",
       "      <td>-47.723160</td>\n",
       "      <td>-26.919237</td>\n",
       "      <td>-16.636442</td>\n",
       "      <td>-20.194735</td>\n",
       "      <td>-27.472851</td>\n",
       "      <td>10.800773</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "83       4.399968      0.042012         0.032239        0.000499   \n",
       "74       4.374043      0.068614         0.033129        0.001972   \n",
       "73       3.211093      0.032683         0.030821        0.002246   \n",
       "75       5.688128      0.137392         0.033125        0.001207   \n",
       "84       5.655732      0.085976         0.032792        0.002939   \n",
       "..            ...           ...              ...             ...   \n",
       "71       4.329026      0.062792         0.031671        0.001793   \n",
       "67       3.279602      0.104560         0.031089        0.000804   \n",
       "70       3.260674      0.093230         0.031827        0.001571   \n",
       "65       4.338018      0.036118         0.032612        0.000850   \n",
       "66       5.541271      0.065275         0.032733        0.001396   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "83  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "74  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "73  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "75  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "84  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "..                                                ...                    ...   \n",
       "71  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "67  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "70  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "65  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "66  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "\n",
       "   param_model__max_features param_model__n_estimators param_model__eta  \\\n",
       "83                       NaN                       NaN              0.3   \n",
       "74                       NaN                       NaN              0.1   \n",
       "73                       NaN                       NaN              0.1   \n",
       "75                       NaN                       NaN              0.1   \n",
       "84                       NaN                       NaN              0.3   \n",
       "..                       ...                       ...              ...   \n",
       "71                       NaN                       NaN             0.01   \n",
       "67                       NaN                       NaN             0.01   \n",
       "70                       NaN                       NaN             0.01   \n",
       "65                       NaN                       NaN             0.01   \n",
       "66                       NaN                       NaN             0.01   \n",
       "\n",
       "   param_model__gamma                                             params  \\\n",
       "83                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "74                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "73                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "75                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "84                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "..                ...                                                ...   \n",
       "71                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "67                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "70                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "65                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "66                0.1  {'model': XGBRegressor(base_score=None, booste...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "83           0.435324          -0.058706           0.235063   \n",
       "74           0.430918          -0.001321           0.221700   \n",
       "73           0.420600           0.212421           0.138343   \n",
       "75           0.430948          -0.143982           0.245534   \n",
       "84           0.404752          -0.167093           0.231453   \n",
       "..                ...                ...                ...   \n",
       "71         -25.881851         -47.209353         -27.040913   \n",
       "67         -25.889016         -47.184387         -27.089479   \n",
       "70         -25.889016         -47.184387         -27.108559   \n",
       "65         -25.875187         -47.395441         -26.959851   \n",
       "66         -25.890679         -47.723160         -26.919237   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "83           0.375228           0.399281         0.277238        0.181177   \n",
       "74           0.267397           0.375161         0.258771        0.149852   \n",
       "73           0.122829           0.291122         0.237063        0.109554   \n",
       "75           0.256299           0.393311         0.236422        0.203784   \n",
       "84           0.184793           0.389565         0.208694        0.206619   \n",
       "..                ...                ...              ...             ...   \n",
       "71         -16.651056         -20.219825       -27.400600       10.601310   \n",
       "67         -16.645945         -20.237177       -27.409201       10.590153   \n",
       "70         -16.628963         -20.237177       -27.409620       10.593496   \n",
       "65         -16.655387         -20.211795       -27.419532       10.671940   \n",
       "66         -16.636442         -20.194735       -27.472851       10.800773   \n",
       "\n",
       "    rank_test_score  \n",
       "83                1  \n",
       "74                2  \n",
       "73                3  \n",
       "75                4  \n",
       "84                5  \n",
       "..              ...  \n",
       "71               87  \n",
       "67               88  \n",
       "70               89  \n",
       "65               90  \n",
       "66               91  \n",
       "\n",
       "[91 rows x 19 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.DataFrame(fitted_grid.cv_results_)\n",
    "grid_search_results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The scores returned by the gridsearch are far lower than the manual search - therefore will use the results as a guideline to do another manual search further tuning the model manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='/var/folders/t5/kc4tlr5n2yn5jkkh1t9rk9500000gn/T/tmpieqziszu',\n",
      "         steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['start_x', 'start_y',\n",
      "                                                   'end_x', 'end_y', 'x_dif',\n",
      "                                                   'y_dif', 'time_seconds',\n",
      "                                                   'n-1_x_distance',\n",
      "                                                   'n-1_y_distance',\n",
      "                                                   'n-1_start_x', 'n-1_start_y',\n",
      "                                                   'n-1_end_x', 'n-1_end_y',\n",
      "                                                   'n-2_x_di...\n",
      "                              importance_type=None, interaction_constraints='',\n",
      "                              learning_rate=0.300000012, max_delta_step=0,\n",
      "                              max_depth=3, min_child_weight=1, missing=nan,\n",
      "                              monotone_constraints='()', n_estimators=100,\n",
      "                              n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                              random_state=1, reg_alpha=0, reg_lambda=1,\n",
      "                              scale_pos_weight=1, subsample=1,\n",
      "                              tree_method='exact', validate_parameters=1,\n",
      "                              verbosity=None))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22566229633244372"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fitted_grid.best_estimator_)\n",
    "fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Max_features sqrt has a big impact on accuracy - therefore, none or auto are the best options - will remove ```sqrt``` from the max features options. \n",
    "- Initially introduced those as a feature selection attempt to limit the number of features to only the most important. As most of the models I am using are tree based, they perform feature selection as part of the training process.\n",
    "- for xgb reg_alpha helps with regularisation - small increments above 1 have a big impact in reducing train scores, without reducing test scores by much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5 - Run another round of manual tweaks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Random Forest Regressor - Depth 17 ***\n",
      "Random Forest Train Score:  0.9605924868379286\n",
      "Random Forest Test Score:  0.7727033214856343\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 ***\n",
      "XGB Regressor Train Score:  0.9773771604640682\n",
      "XGB Regressor Test Score:  0.7774353046416602\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Random Forest Regressor - Depth 17 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=150, oob_score=True, n_jobs=-1, random_state=1))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final model search will lower gamma, and introduce alpha for regularisation. Gamma is known to help with shallow trees, which we will have in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search - Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  24.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  22.7s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  23.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  23.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=None; total time=  23.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  21.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  22.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  22.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  22.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=10, model__max_features=auto; total time=  23.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  26.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  29.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  32.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  31.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=None; total time=  31.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  28.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.2s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=11, model__max_features=auto; total time=  30.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  31.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  33.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  33.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  29.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=None; total time=  28.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  26.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.2s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=12, model__max_features=auto; total time=  28.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  29.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  30.7s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  30.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  30.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=None; total time=  31.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  29.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.2s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=13, model__max_features=auto; total time=  30.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  30.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  32.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  31.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=None; total time=  31.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  30.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  31.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  31.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=14, model__max_features=auto; total time=  32.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  32.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.1s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.6s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=None; total time=  34.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  32.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=15, model__max_features=auto; total time=  34.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  34.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  36.3s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  37.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  36.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=None; total time=  36.4s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  37.0s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  36.8s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  37.5s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  36.9s\n",
      "[CV] END model=RandomForestRegressor(n_estimators=120, n_jobs=-1, oob_score=True,\n",
      "                      random_state=1), model__max_depth=16, model__max_features=auto; total time=  36.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1; total time=   6.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   6.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.1; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   6.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=4, model__reg_alpha=1.2; total time=   7.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   8.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   8.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   9.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=   9.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1; total time=  11.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  12.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  11.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  10.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.1; total time=  11.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=   9.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=5, model__reg_alpha=1.2; total time=  10.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1; total time=  10.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  10.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  11.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  11.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.1; total time=  25.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  11.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  11.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  10.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  10.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=6, model__reg_alpha=1.2; total time=  10.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  12.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  13.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  14.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  12.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1; total time=  14.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  13.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  13.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  15.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.1; total time=  13.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  12.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  13.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  14.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  13.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__max_depth=7, model__reg_alpha=1.2; total time=  13.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   7.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   9.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   8.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   9.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1; total time=   9.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=  10.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=   9.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=   9.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=  10.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.1; total time=   9.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=   9.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=  10.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=  10.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=   9.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=4, model__reg_alpha=1.2; total time=  10.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  11.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  12.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  11.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  12.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1; total time=  13.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.1; total time=  11.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  10.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=5, model__reg_alpha=1.2; total time=  11.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  13.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1; total time=  14.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  13.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.1; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=6, model__reg_alpha=1.2; total time=  14.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  15.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  16.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  16.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  16.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1; total time=  17.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.1; total time=  16.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  17.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  16.8s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  17.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  16.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=0.01, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__max_depth=7, model__reg_alpha=1.2; total time=  16.5s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid = [\n",
    "     {\n",
    "        'model': [RandomForestRegressor(random_state=1, oob_score=True, n_estimators=120, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(10, 17, 1)),\n",
    "        'model__max_features': [None, 'auto']},\n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBRegressor(random_state=1, gamma=0.01)],\n",
    "        'model__max_depth': list(range(4, 8, 1)),\n",
    "        'model__eta': [0.1, 0.3],\n",
    "        'model__reg_alpha': [1, 1.1, 1.2]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid = GridSearchCV(estimator, param_grid, cv = 5, verbose = 2)\n",
    "fitted_grid = grid.fit(X_train, y_train)\n",
    "\n",
    "# fitted_grid.best_estimator_\n",
    "# fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='/var/folders/t5/kc4tlr5n2yn5jkkh1t9rk9500000gn/T/tmpieqziszu',\n",
      "         steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('standardscaler',\n",
      "                                                  StandardScaler(),\n",
      "                                                  ['start_x', 'start_y',\n",
      "                                                   'end_x', 'end_y', 'x_dif',\n",
      "                                                   'y_dif', 'time_seconds',\n",
      "                                                   'n-1_x_distance',\n",
      "                                                   'n-1_y_distance',\n",
      "                                                   'n-1_start_x', 'n-1_start_y',\n",
      "                                                   'n-1_end_x', 'n-1_end_y',\n",
      "                                                   'n-2_x_distance',\n",
      "                                                   'n-2_y_dis...\n",
      "                              importance_type=None, interaction_constraints='',\n",
      "                              learning_rate=0.100000001, max_delta_step=0,\n",
      "                              max_depth=4, min_child_weight=1, missing=nan,\n",
      "                              monotone_constraints='()', n_estimators=100,\n",
      "                              n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "                              random_state=1, reg_alpha=1.1, reg_lambda=1,\n",
      "                              scale_pos_weight=1, subsample=1,\n",
      "                              tree_method='exact', validate_parameters=1,\n",
      "                              verbosity=None))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31658251673709203"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fitted_grid.best_estimator_)\n",
    "fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__reg_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.970470</td>\n",
       "      <td>0.146105</td>\n",
       "      <td>0.042224</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.489041</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>0.249863</td>\n",
       "      <td>0.339120</td>\n",
       "      <td>0.394873</td>\n",
       "      <td>0.316988</td>\n",
       "      <td>0.128581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.990853</td>\n",
       "      <td>0.103030</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.488619</td>\n",
       "      <td>0.053167</td>\n",
       "      <td>0.242089</td>\n",
       "      <td>0.338860</td>\n",
       "      <td>0.404852</td>\n",
       "      <td>0.305518</td>\n",
       "      <td>0.149806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.665684</td>\n",
       "      <td>0.233123</td>\n",
       "      <td>0.039346</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.496290</td>\n",
       "      <td>0.019671</td>\n",
       "      <td>0.259478</td>\n",
       "      <td>0.380897</td>\n",
       "      <td>0.361093</td>\n",
       "      <td>0.303486</td>\n",
       "      <td>0.160606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.143548</td>\n",
       "      <td>0.299014</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.454715</td>\n",
       "      <td>0.078265</td>\n",
       "      <td>0.201029</td>\n",
       "      <td>0.354615</td>\n",
       "      <td>0.422365</td>\n",
       "      <td>0.302198</td>\n",
       "      <td>0.142007</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.461165</td>\n",
       "      <td>0.257819</td>\n",
       "      <td>0.055376</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.451530</td>\n",
       "      <td>0.050477</td>\n",
       "      <td>0.220305</td>\n",
       "      <td>0.379015</td>\n",
       "      <td>0.398107</td>\n",
       "      <td>0.299887</td>\n",
       "      <td>0.146590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.697891</td>\n",
       "      <td>0.684169</td>\n",
       "      <td>0.051127</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.473782</td>\n",
       "      <td>-0.053094</td>\n",
       "      <td>0.257793</td>\n",
       "      <td>0.432291</td>\n",
       "      <td>0.386083</td>\n",
       "      <td>0.299371</td>\n",
       "      <td>0.190560</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14.547758</td>\n",
       "      <td>0.213805</td>\n",
       "      <td>0.059216</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.455640</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.227711</td>\n",
       "      <td>0.353132</td>\n",
       "      <td>0.411260</td>\n",
       "      <td>0.292239</td>\n",
       "      <td>0.159035</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.172207</td>\n",
       "      <td>0.245823</td>\n",
       "      <td>0.044415</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.485158</td>\n",
       "      <td>-0.014924</td>\n",
       "      <td>0.231482</td>\n",
       "      <td>0.334761</td>\n",
       "      <td>0.409253</td>\n",
       "      <td>0.289146</td>\n",
       "      <td>0.173615</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.948411</td>\n",
       "      <td>0.566847</td>\n",
       "      <td>0.056049</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.459045</td>\n",
       "      <td>-0.025285</td>\n",
       "      <td>0.236809</td>\n",
       "      <td>0.388240</td>\n",
       "      <td>0.378042</td>\n",
       "      <td>0.287370</td>\n",
       "      <td>0.172150</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.755482</td>\n",
       "      <td>0.280951</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.461504</td>\n",
       "      <td>-0.077909</td>\n",
       "      <td>0.259754</td>\n",
       "      <td>0.372114</td>\n",
       "      <td>0.371115</td>\n",
       "      <td>0.277316</td>\n",
       "      <td>0.188787</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.473103</td>\n",
       "      <td>0.916867</td>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.494848</td>\n",
       "      <td>-0.030843</td>\n",
       "      <td>0.219688</td>\n",
       "      <td>0.323455</td>\n",
       "      <td>0.374493</td>\n",
       "      <td>0.276328</td>\n",
       "      <td>0.177297</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14.228845</td>\n",
       "      <td>0.422806</td>\n",
       "      <td>0.054930</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.472827</td>\n",
       "      <td>0.035152</td>\n",
       "      <td>0.168870</td>\n",
       "      <td>0.333253</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.271148</td>\n",
       "      <td>0.152469</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16.462852</td>\n",
       "      <td>0.493183</td>\n",
       "      <td>0.060337</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.457436</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>0.155508</td>\n",
       "      <td>0.290716</td>\n",
       "      <td>0.379315</td>\n",
       "      <td>0.268982</td>\n",
       "      <td>0.144156</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.578927</td>\n",
       "      <td>0.142364</td>\n",
       "      <td>0.041213</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.498142</td>\n",
       "      <td>-0.067118</td>\n",
       "      <td>0.214198</td>\n",
       "      <td>0.344013</td>\n",
       "      <td>0.351429</td>\n",
       "      <td>0.268133</td>\n",
       "      <td>0.190212</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.311747</td>\n",
       "      <td>0.926352</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.494764</td>\n",
       "      <td>-0.041594</td>\n",
       "      <td>0.214933</td>\n",
       "      <td>0.318742</td>\n",
       "      <td>0.349703</td>\n",
       "      <td>0.267310</td>\n",
       "      <td>0.178513</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16.760272</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.061917</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.441854</td>\n",
       "      <td>-0.066077</td>\n",
       "      <td>0.229616</td>\n",
       "      <td>0.380083</td>\n",
       "      <td>0.347994</td>\n",
       "      <td>0.266694</td>\n",
       "      <td>0.180144</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.386537</td>\n",
       "      <td>0.788227</td>\n",
       "      <td>0.056386</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.479611</td>\n",
       "      <td>-0.042436</td>\n",
       "      <td>0.235961</td>\n",
       "      <td>0.281458</td>\n",
       "      <td>0.365138</td>\n",
       "      <td>0.263946</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.931450</td>\n",
       "      <td>0.323952</td>\n",
       "      <td>0.047563</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.483524</td>\n",
       "      <td>-0.051109</td>\n",
       "      <td>0.222735</td>\n",
       "      <td>0.282292</td>\n",
       "      <td>0.370284</td>\n",
       "      <td>0.261545</td>\n",
       "      <td>0.179325</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.887010</td>\n",
       "      <td>5.664058</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.488489</td>\n",
       "      <td>-0.081432</td>\n",
       "      <td>0.210590</td>\n",
       "      <td>0.317260</td>\n",
       "      <td>0.364586</td>\n",
       "      <td>0.259899</td>\n",
       "      <td>0.192583</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14.322789</td>\n",
       "      <td>0.319564</td>\n",
       "      <td>0.057813</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.450281</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>0.177970</td>\n",
       "      <td>0.292480</td>\n",
       "      <td>0.330662</td>\n",
       "      <td>0.256672</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14.105374</td>\n",
       "      <td>0.916028</td>\n",
       "      <td>0.058856</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.489366</td>\n",
       "      <td>-0.121584</td>\n",
       "      <td>0.224825</td>\n",
       "      <td>0.320796</td>\n",
       "      <td>0.366251</td>\n",
       "      <td>0.255931</td>\n",
       "      <td>0.207053</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16.372869</td>\n",
       "      <td>0.214013</td>\n",
       "      <td>0.061697</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.454933</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.159301</td>\n",
       "      <td>0.255663</td>\n",
       "      <td>0.369403</td>\n",
       "      <td>0.248279</td>\n",
       "      <td>0.158718</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.511820</td>\n",
       "      <td>0.389142</td>\n",
       "      <td>0.053139</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.483234</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.221793</td>\n",
       "      <td>0.246593</td>\n",
       "      <td>0.370094</td>\n",
       "      <td>0.240128</td>\n",
       "      <td>0.203389</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.301066</td>\n",
       "      <td>0.921592</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.467521</td>\n",
       "      <td>-0.106890</td>\n",
       "      <td>0.227051</td>\n",
       "      <td>0.266799</td>\n",
       "      <td>0.345308</td>\n",
       "      <td>0.239958</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33.953997</td>\n",
       "      <td>0.725346</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.442721</td>\n",
       "      <td>0.073010</td>\n",
       "      <td>0.150109</td>\n",
       "      <td>0.047272</td>\n",
       "      <td>0.335539</td>\n",
       "      <td>0.209730</td>\n",
       "      <td>0.154112</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33.980948</td>\n",
       "      <td>0.857570</td>\n",
       "      <td>0.036574</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.442721</td>\n",
       "      <td>0.073010</td>\n",
       "      <td>0.150109</td>\n",
       "      <td>0.047272</td>\n",
       "      <td>0.335539</td>\n",
       "      <td>0.209730</td>\n",
       "      <td>0.154112</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.583106</td>\n",
       "      <td>0.550561</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.434824</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>0.134774</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>0.326637</td>\n",
       "      <td>0.200261</td>\n",
       "      <td>0.154235</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.658470</td>\n",
       "      <td>0.656271</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>14</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.434824</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>0.134774</td>\n",
       "      <td>0.055411</td>\n",
       "      <td>0.326637</td>\n",
       "      <td>0.200261</td>\n",
       "      <td>0.154235</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.113632</td>\n",
       "      <td>0.868880</td>\n",
       "      <td>0.036556</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.446799</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.122834</td>\n",
       "      <td>0.065182</td>\n",
       "      <td>0.313062</td>\n",
       "      <td>0.200250</td>\n",
       "      <td>0.154481</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.941752</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>16</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.446799</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.122834</td>\n",
       "      <td>0.065182</td>\n",
       "      <td>0.313062</td>\n",
       "      <td>0.200250</td>\n",
       "      <td>0.154481</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.512605</td>\n",
       "      <td>0.622566</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444562</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.133035</td>\n",
       "      <td>0.060128</td>\n",
       "      <td>0.320523</td>\n",
       "      <td>0.199847</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.072868</td>\n",
       "      <td>0.439424</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>13</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444562</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.133035</td>\n",
       "      <td>0.060128</td>\n",
       "      <td>0.320523</td>\n",
       "      <td>0.199847</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.208310</td>\n",
       "      <td>0.710552</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>11</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444629</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>0.044967</td>\n",
       "      <td>0.314886</td>\n",
       "      <td>0.196638</td>\n",
       "      <td>0.158036</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.987358</td>\n",
       "      <td>2.188787</td>\n",
       "      <td>0.038094</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.444629</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>0.044967</td>\n",
       "      <td>0.314886</td>\n",
       "      <td>0.196638</td>\n",
       "      <td>0.158036</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.817038</td>\n",
       "      <td>0.668538</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>12</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441234</td>\n",
       "      <td>0.044871</td>\n",
       "      <td>0.113632</td>\n",
       "      <td>0.058471</td>\n",
       "      <td>0.315847</td>\n",
       "      <td>0.194811</td>\n",
       "      <td>0.156866</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.419379</td>\n",
       "      <td>2.237077</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441234</td>\n",
       "      <td>0.044871</td>\n",
       "      <td>0.113632</td>\n",
       "      <td>0.058471</td>\n",
       "      <td>0.315847</td>\n",
       "      <td>0.194811</td>\n",
       "      <td>0.156866</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.395389</td>\n",
       "      <td>0.720538</td>\n",
       "      <td>0.039316</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441763</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.308431</td>\n",
       "      <td>0.191760</td>\n",
       "      <td>0.158913</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.655425</td>\n",
       "      <td>0.723017</td>\n",
       "      <td>0.036653</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>RandomForestRegressor(n_estimators=120, n_jobs...</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(n_estimators=1...</td>\n",
       "      <td>0.441763</td>\n",
       "      <td>0.040049</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>0.308431</td>\n",
       "      <td>0.191760</td>\n",
       "      <td>0.158913</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15       6.970470      0.146105         0.042224        0.002061   \n",
       "16       6.990853      0.103030         0.041237        0.001504   \n",
       "14       6.665684      0.233123         0.039346        0.003204   \n",
       "31      11.143548      0.299014         0.051227        0.002575   \n",
       "30      11.461165      0.257819         0.055376        0.002785   \n",
       "26       8.697891      0.684169         0.051127        0.005480   \n",
       "34      14.547758      0.213805         0.059216        0.001967   \n",
       "19      10.172207      0.245823         0.044415        0.004373   \n",
       "28       9.948411      0.566847         0.056049        0.004292   \n",
       "27       9.755482      0.280951         0.054687        0.005319   \n",
       "17       9.473103      0.916867         0.046530        0.004487   \n",
       "32      14.228845      0.422806         0.054930        0.003807   \n",
       "35      16.462852      0.493183         0.060337        0.002324   \n",
       "20      10.578927      0.142364         0.041213        0.002588   \n",
       "23      13.311747      0.926352         0.049187        0.006349   \n",
       "37      16.760272      0.367647         0.061917        0.002259   \n",
       "18      11.386537      0.788227         0.056386        0.007012   \n",
       "22      10.931450      0.323952         0.047563        0.005462   \n",
       "21      13.887010      5.664058         0.051313        0.011814   \n",
       "33      14.322789      0.319564         0.057813        0.003183   \n",
       "24      14.105374      0.916028         0.058856        0.009900   \n",
       "36      16.372869      0.214013         0.061697        0.002934   \n",
       "25      13.511820      0.389142         0.053139        0.006965   \n",
       "29      12.301066      0.921592         0.058332        0.003976   \n",
       "11      33.953997      0.725346         0.036767        0.001670   \n",
       "10      33.980948      0.857570         0.036574        0.000763   \n",
       "8       31.583106      0.550561         0.036543        0.000892   \n",
       "9       31.658470      0.656271         0.036400        0.000922   \n",
       "12      36.113632      0.868880         0.036556        0.001107   \n",
       "13      36.941752      0.297908         0.038325        0.002188   \n",
       "6       30.512605      0.622566         0.036400        0.001333   \n",
       "7       30.072868      0.439424         0.037346        0.001080   \n",
       "3       30.208310      0.710552         0.036697        0.000827   \n",
       "2       29.987358      2.188787         0.038094        0.001315   \n",
       "5       27.817038      0.668538         0.038829        0.006366   \n",
       "4       31.419379      2.237077         0.037332        0.001180   \n",
       "0       23.395389      0.720538         0.039316        0.004975   \n",
       "1       22.655425      0.723017         0.036653        0.000759   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "15  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "16  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "14  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "31  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "30  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "26  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "34  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "19  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "28  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "27  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "17  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "32  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "35  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "20  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "23  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "37  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "18  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "22  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "21  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "33  XGBRegressor(base_score=None, booster=None, co...                      6   \n",
       "24  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "36  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "25  XGBRegressor(base_score=None, booster=None, co...                      7   \n",
       "29  XGBRegressor(base_score=None, booster=None, co...                      5   \n",
       "11  RandomForestRegressor(n_estimators=120, n_jobs...                     15   \n",
       "10  RandomForestRegressor(n_estimators=120, n_jobs...                     15   \n",
       "8   RandomForestRegressor(n_estimators=120, n_jobs...                     14   \n",
       "9   RandomForestRegressor(n_estimators=120, n_jobs...                     14   \n",
       "12  RandomForestRegressor(n_estimators=120, n_jobs...                     16   \n",
       "13  RandomForestRegressor(n_estimators=120, n_jobs...                     16   \n",
       "6   RandomForestRegressor(n_estimators=120, n_jobs...                     13   \n",
       "7   RandomForestRegressor(n_estimators=120, n_jobs...                     13   \n",
       "3   RandomForestRegressor(n_estimators=120, n_jobs...                     11   \n",
       "2   RandomForestRegressor(n_estimators=120, n_jobs...                     11   \n",
       "5   RandomForestRegressor(n_estimators=120, n_jobs...                     12   \n",
       "4   RandomForestRegressor(n_estimators=120, n_jobs...                     12   \n",
       "0   RandomForestRegressor(n_estimators=120, n_jobs...                     10   \n",
       "1   RandomForestRegressor(n_estimators=120, n_jobs...                     10   \n",
       "\n",
       "   param_model__max_features param_model__eta param_model__reg_alpha  \\\n",
       "15                       NaN              0.1                    1.1   \n",
       "16                       NaN              0.1                    1.2   \n",
       "14                       NaN              0.1                      1   \n",
       "31                       NaN              0.3                    1.2   \n",
       "30                       NaN              0.3                    1.1   \n",
       "26                       NaN              0.3                      1   \n",
       "34                       NaN              0.3                    1.2   \n",
       "19                       NaN              0.1                    1.2   \n",
       "28                       NaN              0.3                    1.2   \n",
       "27                       NaN              0.3                    1.1   \n",
       "17                       NaN              0.1                      1   \n",
       "32                       NaN              0.3                      1   \n",
       "35                       NaN              0.3                      1   \n",
       "20                       NaN              0.1                      1   \n",
       "23                       NaN              0.1                      1   \n",
       "37                       NaN              0.3                    1.2   \n",
       "18                       NaN              0.1                    1.1   \n",
       "22                       NaN              0.1                    1.2   \n",
       "21                       NaN              0.1                    1.1   \n",
       "33                       NaN              0.3                    1.1   \n",
       "24                       NaN              0.1                    1.1   \n",
       "36                       NaN              0.3                    1.1   \n",
       "25                       NaN              0.1                    1.2   \n",
       "29                       NaN              0.3                      1   \n",
       "11                      auto              NaN                    NaN   \n",
       "10                      None              NaN                    NaN   \n",
       "8                       None              NaN                    NaN   \n",
       "9                       auto              NaN                    NaN   \n",
       "12                      None              NaN                    NaN   \n",
       "13                      auto              NaN                    NaN   \n",
       "6                       None              NaN                    NaN   \n",
       "7                       auto              NaN                    NaN   \n",
       "3                       auto              NaN                    NaN   \n",
       "2                       None              NaN                    NaN   \n",
       "5                       auto              NaN                    NaN   \n",
       "4                       None              NaN                    NaN   \n",
       "0                       None              NaN                    NaN   \n",
       "1                       auto              NaN                    NaN   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "15  {'model': XGBRegressor(base_score=None, booste...           0.489041   \n",
       "16  {'model': XGBRegressor(base_score=None, booste...           0.488619   \n",
       "14  {'model': XGBRegressor(base_score=None, booste...           0.496290   \n",
       "31  {'model': XGBRegressor(base_score=None, booste...           0.454715   \n",
       "30  {'model': XGBRegressor(base_score=None, booste...           0.451530   \n",
       "26  {'model': XGBRegressor(base_score=None, booste...           0.473782   \n",
       "34  {'model': XGBRegressor(base_score=None, booste...           0.455640   \n",
       "19  {'model': XGBRegressor(base_score=None, booste...           0.485158   \n",
       "28  {'model': XGBRegressor(base_score=None, booste...           0.459045   \n",
       "27  {'model': XGBRegressor(base_score=None, booste...           0.461504   \n",
       "17  {'model': XGBRegressor(base_score=None, booste...           0.494848   \n",
       "32  {'model': XGBRegressor(base_score=None, booste...           0.472827   \n",
       "35  {'model': XGBRegressor(base_score=None, booste...           0.457436   \n",
       "20  {'model': XGBRegressor(base_score=None, booste...           0.498142   \n",
       "23  {'model': XGBRegressor(base_score=None, booste...           0.494764   \n",
       "37  {'model': XGBRegressor(base_score=None, booste...           0.441854   \n",
       "18  {'model': XGBRegressor(base_score=None, booste...           0.479611   \n",
       "22  {'model': XGBRegressor(base_score=None, booste...           0.483524   \n",
       "21  {'model': XGBRegressor(base_score=None, booste...           0.488489   \n",
       "33  {'model': XGBRegressor(base_score=None, booste...           0.450281   \n",
       "24  {'model': XGBRegressor(base_score=None, booste...           0.489366   \n",
       "36  {'model': XGBRegressor(base_score=None, booste...           0.454933   \n",
       "25  {'model': XGBRegressor(base_score=None, booste...           0.483234   \n",
       "29  {'model': XGBRegressor(base_score=None, booste...           0.467521   \n",
       "11  {'model': RandomForestRegressor(n_estimators=1...           0.442721   \n",
       "10  {'model': RandomForestRegressor(n_estimators=1...           0.442721   \n",
       "8   {'model': RandomForestRegressor(n_estimators=1...           0.434824   \n",
       "9   {'model': RandomForestRegressor(n_estimators=1...           0.434824   \n",
       "12  {'model': RandomForestRegressor(n_estimators=1...           0.446799   \n",
       "13  {'model': RandomForestRegressor(n_estimators=1...           0.446799   \n",
       "6   {'model': RandomForestRegressor(n_estimators=1...           0.444562   \n",
       "7   {'model': RandomForestRegressor(n_estimators=1...           0.444562   \n",
       "3   {'model': RandomForestRegressor(n_estimators=1...           0.444629   \n",
       "2   {'model': RandomForestRegressor(n_estimators=1...           0.444629   \n",
       "5   {'model': RandomForestRegressor(n_estimators=1...           0.441234   \n",
       "4   {'model': RandomForestRegressor(n_estimators=1...           0.441234   \n",
       "0   {'model': RandomForestRegressor(n_estimators=1...           0.441763   \n",
       "1   {'model': RandomForestRegressor(n_estimators=1...           0.441763   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.112044           0.249863           0.339120   \n",
       "16           0.053167           0.242089           0.338860   \n",
       "14           0.019671           0.259478           0.380897   \n",
       "31           0.078265           0.201029           0.354615   \n",
       "30           0.050477           0.220305           0.379015   \n",
       "26          -0.053094           0.257793           0.432291   \n",
       "34           0.013450           0.227711           0.353132   \n",
       "19          -0.014924           0.231482           0.334761   \n",
       "28          -0.025285           0.236809           0.388240   \n",
       "27          -0.077909           0.259754           0.372114   \n",
       "17          -0.030843           0.219688           0.323455   \n",
       "32           0.035152           0.168870           0.333253   \n",
       "35           0.061936           0.155508           0.290716   \n",
       "20          -0.067118           0.214198           0.344013   \n",
       "23          -0.041594           0.214933           0.318742   \n",
       "37          -0.066077           0.229616           0.380083   \n",
       "18          -0.042436           0.235961           0.281458   \n",
       "22          -0.051109           0.222735           0.282292   \n",
       "21          -0.081432           0.210590           0.317260   \n",
       "33           0.031966           0.177970           0.292480   \n",
       "24          -0.121584           0.224825           0.320796   \n",
       "36           0.002093           0.159301           0.255663   \n",
       "25          -0.121073           0.221793           0.246593   \n",
       "29          -0.106890           0.227051           0.266799   \n",
       "11           0.073010           0.150109           0.047272   \n",
       "10           0.073010           0.150109           0.047272   \n",
       "8            0.049659           0.134774           0.055411   \n",
       "9            0.049659           0.134774           0.055411   \n",
       "12           0.053375           0.122834           0.065182   \n",
       "13           0.053375           0.122834           0.065182   \n",
       "6            0.040985           0.133035           0.060128   \n",
       "7            0.040985           0.133035           0.060128   \n",
       "3            0.048304           0.130403           0.044967   \n",
       "2            0.048304           0.130403           0.044967   \n",
       "5            0.044871           0.113632           0.058471   \n",
       "4            0.044871           0.113632           0.058471   \n",
       "0            0.040049           0.129182           0.039375   \n",
       "1            0.040049           0.129182           0.039375   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15           0.394873         0.316988        0.128581                1  \n",
       "16           0.404852         0.305518        0.149806                2  \n",
       "14           0.361093         0.303486        0.160606                3  \n",
       "31           0.422365         0.302198        0.142007                4  \n",
       "30           0.398107         0.299887        0.146590                5  \n",
       "26           0.386083         0.299371        0.190560                6  \n",
       "34           0.411260         0.292239        0.159035                7  \n",
       "19           0.409253         0.289146        0.173615                8  \n",
       "28           0.378042         0.287370        0.172150                9  \n",
       "27           0.371115         0.277316        0.188787               10  \n",
       "17           0.374493         0.276328        0.177297               11  \n",
       "32           0.345635         0.271148        0.152469               12  \n",
       "35           0.379315         0.268982        0.144156               13  \n",
       "20           0.351429         0.268133        0.190212               14  \n",
       "23           0.349703         0.267310        0.178513               15  \n",
       "37           0.347994         0.266694        0.180144               16  \n",
       "18           0.365138         0.263946        0.174190               17  \n",
       "22           0.370284         0.261545        0.179325               18  \n",
       "21           0.364586         0.259899        0.192583               19  \n",
       "33           0.330662         0.256672        0.142076               20  \n",
       "24           0.366251         0.255931        0.207053               21  \n",
       "36           0.369403         0.248279        0.158718               22  \n",
       "25           0.370094         0.240128        0.203389               23  \n",
       "29           0.345308         0.239958        0.191872               24  \n",
       "11           0.335539         0.209730        0.154112               25  \n",
       "10           0.335539         0.209730        0.154112               25  \n",
       "8            0.326637         0.200261        0.154235               27  \n",
       "9            0.326637         0.200261        0.154235               28  \n",
       "12           0.313062         0.200250        0.154481               29  \n",
       "13           0.313062         0.200250        0.154481               30  \n",
       "6            0.320523         0.199847        0.157271               31  \n",
       "7            0.320523         0.199847        0.157271               32  \n",
       "3            0.314886         0.196638        0.158036               33  \n",
       "2            0.314886         0.196638        0.158036               33  \n",
       "5            0.315847         0.194811        0.156866               35  \n",
       "4            0.315847         0.194811        0.156866               36  \n",
       "0            0.308431         0.191760        0.158913               37  \n",
       "1            0.308431         0.191760        0.158913               38  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.DataFrame(fitted_grid.cv_results_)\n",
    "grid_search_results.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Initially before using the manual approach - I ran a Randomized Grid Search - however the results were not great and due to run time, it made it difficult to make quick tweaks and iterate at pace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a parameter grid\n",
    "# param_grid = [\n",
    "#      {\n",
    "#         'model': [RandomForestRegressor(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "#         'model__max_depth': list(range(2, 17, 2)),\n",
    "#         'model__max_features': ['sqrt', 'auto', 'log2'],\n",
    "#         'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "#      {\n",
    "#         'model': [xgb.XGBRegressor(random_state=1)],\n",
    "#         'model__max_depth': list(range(2, 5, 1)),\n",
    "#         'model__gamma': [0.1, 0.5, 0.9],\n",
    "#         'model__eta': [0.01, 0.1, 0.3]\n",
    "#         },\n",
    "\n",
    "# ]\n",
    "\n",
    "# # Instantiate a gridsearch\n",
    "# grid = RandomizedSearchCV(estimator, param_grid, cv = 5, n_jobs=-1,verbose = 2)\n",
    "# fitted_grid = grid.fit(X_train, y_train)\n",
    "\n",
    "# # fitted_grid.best_estimator_\n",
    "# # fitted_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search_results = pd.DataFrame(fitted_grid.cv_results_)\n",
    "# # random_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Team - xT\n",
    "\n",
    "- will follow a similar approach as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_xt_train_df, modeling_xt_test_df, 'xT_value')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-xt')\n",
    "\n",
    "# pipeline column transformer\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define gridsearch column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Decision Tree Regressor ***\n",
      "DT Train Score:  0.9999999999999997\n",
      "DT Test Score:  0.8941230264107702\n",
      " \n",
      "*** Decision Tree Regressor - Depth 10 ***\n",
      "DT Train Score:  0.9679232190410411\n",
      "DT Test Score:  0.881375744651935\n",
      " \n",
      "*** Random Forest Regressor - Depth 17 ***\n",
      "Random Forest Train Score:  0.9548638157772583\n",
      "Random Forest Test Score:  0.8336408872610948\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 ***\n",
      "XGB Regressor Train Score:  0.9958911469867335\n",
      "XGB Regressor Test Score:  0.8942143933500908\n",
      " \n",
      "*** xGBoost Regressor - Depth 5 Optimised ***\n",
      "XGB Regressor Train Score:  0.9265065158190492\n",
      "XGB Regressor Test Score:  0.8085949010492468\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Decision Tree Regressor ***')\n",
    "pipe = make_pipeline(ct, DecisionTreeRegressor())\n",
    "pipe.fit(X_train, y_train)\n",
    "print('DT Train Score: ', pipe.score(X_train, y_train))\n",
    "print('DT Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Decision Tree Regressor - Depth 10 ***')\n",
    "pipe = make_pipeline(ct, DecisionTreeRegressor(max_depth=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('DT Train Score: ', pipe.score(X_train, y_train))\n",
    "print('DT Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** Random Forest Regressor - Depth 17 ***')\n",
    "pipe = make_pipeline(ct, RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=150, oob_score=True, n_jobs=-1, random_state=1))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Random Forest Train Score: ', pipe.score(X_train, y_train))\n",
    "print('Random Forest Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "print('*** xGBoost Regressor - Depth 5 Optimised ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5, reg_lambda=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will use 3 different models, rather than the top 2 from the previous notebook, as the performance was very close and therefore with tuning there may be better performance from the 3rd best performing baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 89 candidates, totalling 445 fits\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=None; total time=   2.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=5, model__max_features=auto; total time=   1.0s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=None; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=7, model__max_features=auto; total time=   1.1s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=None; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=DecisionTreeRegressor(random_state=1), model__max_depth=9, model__max_features=auto; total time=   1.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   6.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=100; total time=   5.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=None, model__n_estimators=140; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=100; total time=   5.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=120; total time=   6.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=5, model__max_features=auto, model__n_estimators=140; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=80; total time=   5.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=100; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=7, model__max_features=auto, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=100; total time=   9.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=None, model__n_estimators=140; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   9.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   9.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=100; total time=   8.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=120; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=9, model__max_features=auto, model__n_estimators=140; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=100; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=120; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=None, model__n_estimators=140; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=120; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=11, model__max_features=auto, model__n_estimators=140; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=120; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  17.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=None, model__n_estimators=140; total time=  16.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=  10.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=80; total time=   9.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=120; total time=  14.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  16.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  17.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  17.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  16.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=13, model__max_features=auto, model__n_estimators=140; total time=  17.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  12.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  14.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  14.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=100; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  19.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  19.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  19.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  18.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=None, model__n_estimators=140; total time=  18.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=80; total time=  11.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  13.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=100; total time=  13.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=120; total time=  16.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  18.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  19.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  19.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  18.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=15, model__max_features=auto, model__n_estimators=140; total time=  18.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=80; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.5s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=100; total time=  15.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  17.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  18.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  17.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  20.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  21.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  21.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  20.8s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=None, model__n_estimators=140; total time=  21.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=80; total time=  12.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.6s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=100; total time=  15.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.2s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.3s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  17.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  20.9s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  21.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  21.4s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  20.7s\n",
      "[CV] END model=RandomForestRegressor(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=17, model__max_features=auto, model__n_estimators=140; total time=  21.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.6s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.2s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=   3.3s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.9s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.5s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.1s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   2.0s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=   2.7s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n",
      "[CV] END model=XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "             validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=   3.4s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid_xt = [\n",
    "     {\n",
    "        'model': [DecisionTreeRegressor(random_state=1)],\n",
    "        'model__max_depth': list(range(5, 10, 2)),\n",
    "        'model__max_features': [None, 'auto']}, \n",
    "     \n",
    "     {\n",
    "        'model': [RandomForestRegressor(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(5, 18, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBRegressor(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid_xt = GridSearchCV(estimator, param_grid_xt, cv = 5, verbose = 2)\n",
    "fitted_grid_xt = grid_xt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>17.939394</td>\n",
       "      <td>0.260279</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.412713</td>\n",
       "      <td>0.285764</td>\n",
       "      <td>0.200786</td>\n",
       "      <td>0.353443</td>\n",
       "      <td>0.249308</td>\n",
       "      <td>0.300403</td>\n",
       "      <td>0.075067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>18.023579</td>\n",
       "      <td>0.201526</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.412713</td>\n",
       "      <td>0.285764</td>\n",
       "      <td>0.200786</td>\n",
       "      <td>0.353443</td>\n",
       "      <td>0.249308</td>\n",
       "      <td>0.300403</td>\n",
       "      <td>0.075067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>21.065515</td>\n",
       "      <td>0.283021</td>\n",
       "      <td>0.030969</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.411430</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.201698</td>\n",
       "      <td>0.352688</td>\n",
       "      <td>0.245080</td>\n",
       "      <td>0.299732</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>21.081727</td>\n",
       "      <td>0.222234</td>\n",
       "      <td>0.031277</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.411430</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.201698</td>\n",
       "      <td>0.352688</td>\n",
       "      <td>0.245080</td>\n",
       "      <td>0.299732</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>12.171634</td>\n",
       "      <td>0.142245</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>RandomForestRegressor(max_depth=17, max_featur...</td>\n",
       "      <td>17</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestRegressor(max_depth=17, ...</td>\n",
       "      <td>0.409540</td>\n",
       "      <td>0.253771</td>\n",
       "      <td>0.197908</td>\n",
       "      <td>0.347294</td>\n",
       "      <td>0.270464</td>\n",
       "      <td>0.295795</td>\n",
       "      <td>0.074269</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.294630</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>0.022757</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.987896</td>\n",
       "      <td>0.022096</td>\n",
       "      <td>0.022176</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2.472307</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.022557</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2.289520</td>\n",
       "      <td>0.052499</td>\n",
       "      <td>0.022625</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.985148</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, co...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>-170.761104</td>\n",
       "      <td>-230.994639</td>\n",
       "      <td>-428.074352</td>\n",
       "      <td>-194.165267</td>\n",
       "      <td>-267.433965</td>\n",
       "      <td>-258.285865</td>\n",
       "      <td>91.026001</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "56      17.939394      0.260279         0.029468        0.000626   \n",
       "60      18.023579      0.201526         0.029104        0.000494   \n",
       "61      21.065515      0.283021         0.030969        0.000760   \n",
       "57      21.081727      0.222234         0.031277        0.000760   \n",
       "58      12.171634      0.142245         0.026271        0.000666   \n",
       "..            ...           ...              ...             ...   \n",
       "69       2.294630      0.061198         0.022757        0.000798   \n",
       "68       1.987896      0.022096         0.022176        0.000888   \n",
       "67       2.472307      0.062073         0.022557        0.000865   \n",
       "66       2.289520      0.052499         0.022625        0.000850   \n",
       "65       1.985148      0.014928         0.023185        0.001693   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "56  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "60  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "61  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "57  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "58  RandomForestRegressor(max_depth=17, max_featur...                     17   \n",
       "..                                                ...                    ...   \n",
       "69  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "68  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "67  XGBRegressor(base_score=None, booster=None, co...                      4   \n",
       "66  XGBRegressor(base_score=None, booster=None, co...                      3   \n",
       "65  XGBRegressor(base_score=None, booster=None, co...                      2   \n",
       "\n",
       "   param_model__max_features param_model__n_estimators param_model__eta  \\\n",
       "56                      None                       120              NaN   \n",
       "60                      auto                       120              NaN   \n",
       "61                      auto                       140              NaN   \n",
       "57                      None                       140              NaN   \n",
       "58                      auto                        80              NaN   \n",
       "..                       ...                       ...              ...   \n",
       "69                       NaN                       NaN             0.01   \n",
       "68                       NaN                       NaN             0.01   \n",
       "67                       NaN                       NaN             0.01   \n",
       "66                       NaN                       NaN             0.01   \n",
       "65                       NaN                       NaN             0.01   \n",
       "\n",
       "   param_model__gamma                                             params  \\\n",
       "56                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "60                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "61                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "57                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "58                NaN  {'model': RandomForestRegressor(max_depth=17, ...   \n",
       "..                ...                                                ...   \n",
       "69                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "68                0.9  {'model': XGBRegressor(base_score=None, booste...   \n",
       "67                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "66                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "65                0.5  {'model': XGBRegressor(base_score=None, booste...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "56           0.412713           0.285764           0.200786   \n",
       "60           0.412713           0.285764           0.200786   \n",
       "61           0.411430           0.287766           0.201698   \n",
       "57           0.411430           0.287766           0.201698   \n",
       "58           0.409540           0.253771           0.197908   \n",
       "..                ...                ...                ...   \n",
       "69        -170.761104        -230.994639        -428.074352   \n",
       "68        -170.761104        -230.994639        -428.074352   \n",
       "67        -170.761104        -230.994639        -428.074352   \n",
       "66        -170.761104        -230.994639        -428.074352   \n",
       "65        -170.761104        -230.994639        -428.074352   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "56           0.353443           0.249308         0.300403        0.075067   \n",
       "60           0.353443           0.249308         0.300403        0.075067   \n",
       "61           0.352688           0.245080         0.299732        0.074862   \n",
       "57           0.352688           0.245080         0.299732        0.074862   \n",
       "58           0.347294           0.270464         0.295795        0.074269   \n",
       "..                ...                ...              ...             ...   \n",
       "69        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "68        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "67        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "66        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "65        -194.165267        -267.433965      -258.285865       91.026001   \n",
       "\n",
       "    rank_test_score  \n",
       "56                1  \n",
       "60                1  \n",
       "61                3  \n",
       "57                3  \n",
       "58                5  \n",
       "..              ...  \n",
       "69               84  \n",
       "68               84  \n",
       "67               84  \n",
       "66               84  \n",
       "65               84  \n",
       "\n",
       "[89 rows x 19 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results_xt = pd.DataFrame(fitted_grid_xt.cv_results_)\n",
    "grid_search_results_xt.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Again we see lower cross-val scores than in the baseline models. And will do a final manual tuning close to the top model in the grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Team - Next Action\n",
    "\n",
    "- will follow a similar approach as before, but will use classification models here instead of regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'type_name_encoded')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-action')\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVC, I've introduced a PCA step to limit some of the dimensionality of the data. As our data has high dimensionality, I'll aim to reduce this down using PCA and as part of the grid search will look for the best performing PCA level based on the % of the variation it captures from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.01; total time=  10.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   7.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   8.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   8.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   7.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=0.1; total time=   8.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   6.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.8, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.001; total time=  11.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  11.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  10.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  11.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  10.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.01; total time=  10.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.7s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.6s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=0.1; total time=   8.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.85, model=SVC(random_state=1), model__C=1; total time=   7.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  12.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.001; total time=  12.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.6s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.01; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   8.6s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.3s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.4s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.9, model=SVC(random_state=1), model__C=1; total time=   7.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.7s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.001; total time=  12.2s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.9s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  12.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.01; total time=  11.8s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.0s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=0.1; total time=   9.1s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END dim_reducer=PCA(), dim_reducer__n_components=0.95, model=SVC(random_state=1), model__C=1; total time=   7.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   6.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   6.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   7.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   8.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  11.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  12.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  12.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   9.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=  10.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  12.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  15.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  16.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  11.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  15.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  18.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  21.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  14.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  14.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  22.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  15.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  18.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  19.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  22.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  22.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  23.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  23.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  23.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  25.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  26.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  21.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  24.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  24.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  25.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  25.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  24.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  29.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  29.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  30.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  30.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  30.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  34.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  34.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  35.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  35.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  32.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  21.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  22.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  23.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  28.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  29.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  29.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  30.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  29.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  35.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  35.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  36.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  37.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  37.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  42.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  43.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  44.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  45.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  44.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.7s\n",
      "[18:40:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=   9.6s\n",
      "[18:40:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=   9.9s\n",
      "[18:41:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=   9.9s\n",
      "[18:41:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  10.0s\n",
      "[18:41:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  10.2s\n",
      "[18:41:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  14.9s\n",
      "[18:41:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  15.6s\n",
      "[18:42:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  15.9s\n",
      "[18:42:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  16.1s\n",
      "[18:42:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  16.2s\n",
      "[18:42:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  20.6s\n",
      "[18:43:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  21.3s\n",
      "[18:43:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  21.2s\n",
      "[18:44:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  20.9s\n",
      "[18:44:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  21.2s\n",
      "[18:44:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  10.6s\n",
      "[18:44:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  11.0s\n",
      "[18:45:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.6s\n",
      "[18:45:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.9s\n",
      "[18:46:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  16.0s\n",
      "[18:46:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.8s\n",
      "[18:46:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  15.9s\n",
      "[18:46:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  20.4s\n",
      "[18:47:16] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.0s\n",
      "[18:47:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.4s\n",
      "[18:47:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.1s\n",
      "[18:48:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  21.3s\n",
      "[18:48:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  10.6s\n",
      "[18:48:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.1s\n",
      "[18:49:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.3s\n",
      "[18:49:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.1s\n",
      "[18:49:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  11.1s\n",
      "[18:49:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.5s\n",
      "[18:49:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.4s\n",
      "[18:50:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.3s\n",
      "[18:50:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.3s\n",
      "[18:50:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  16.2s\n",
      "[18:50:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  20.6s\n",
      "[18:51:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.2s\n",
      "[18:51:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.2s\n",
      "[18:52:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.2s\n",
      "[18:52:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  21.4s\n",
      "[18:52:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  10.7s\n",
      "[18:52:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.2s\n",
      "[18:53:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.2s\n",
      "[18:53:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.1s\n",
      "[18:53:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  11.1s\n",
      "[18:53:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  15.9s\n",
      "[18:53:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.2s\n",
      "[18:54:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.4s\n",
      "[18:54:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.4s\n",
      "[18:54:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  16.4s\n",
      "[18:55:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.0s\n",
      "[18:55:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.6s\n",
      "[18:55:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.5s\n",
      "[18:56:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.4s\n",
      "[18:56:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  21.4s\n",
      "[18:56:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.5s\n",
      "[18:56:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.7s\n",
      "[18:57:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.6s\n",
      "[18:57:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.7s\n",
      "[18:57:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  10.8s\n",
      "[18:57:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  14.9s\n",
      "[18:57:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.0s\n",
      "[18:58:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.0s\n",
      "[18:58:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.0s\n",
      "[18:58:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  15.1s\n",
      "[18:58:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  22.4s\n",
      "[18:59:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  26.9s\n",
      "[18:59:46] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  28.5s\n",
      "[19:00:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  24.8s\n",
      "[19:00:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  23.4s\n",
      "[19:01:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.4s\n",
      "[19:01:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.6s\n",
      "[19:01:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.7s\n",
      "[19:01:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.9s\n",
      "[19:01:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  11.7s\n",
      "[19:02:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  18.1s\n",
      "[19:02:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  18.1s\n",
      "[19:02:36] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  17.6s\n",
      "[19:02:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  17.2s\n",
      "[19:03:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  16.9s\n",
      "[19:03:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  21.7s\n",
      "[19:03:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  22.5s\n",
      "[19:04:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  22.5s\n",
      "[19:04:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  23.0s\n",
      "[19:04:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  22.8s\n",
      "[19:05:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.2s\n",
      "[19:05:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.5s\n",
      "[19:05:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.6s\n",
      "[19:05:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.4s\n",
      "[19:06:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  11.4s\n",
      "[19:06:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.4s\n",
      "[19:06:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.8s\n",
      "[19:06:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  17.0s\n",
      "[19:07:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.8s\n",
      "[19:07:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  16.9s\n",
      "[19:07:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  22.1s\n",
      "[19:08:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  23.2s\n",
      "[19:08:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  23.1s\n",
      "[19:08:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  23.1s\n",
      "[19:09:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  22.5s\n",
      "[19:09:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  11.1s\n",
      "[19:09:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.9s\n",
      "[19:09:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.9s\n",
      "[19:10:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.8s\n",
      "[19:10:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  10.9s\n",
      "[19:10:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.4s\n",
      "[19:10:46] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.8s\n",
      "[19:11:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.6s\n",
      "[19:11:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.7s\n",
      "[19:11:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  15.6s\n",
      "[19:11:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.2s\n",
      "[19:12:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.8s\n",
      "[19:12:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.8s\n",
      "[19:12:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.8s\n",
      "[19:13:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  20.6s\n",
      "[19:13:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.1s\n",
      "[19:13:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.3s\n",
      "[19:13:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.5s\n",
      "[19:14:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.3s\n",
      "[19:14:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  10.4s\n",
      "[19:14:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  14.9s\n",
      "[19:14:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.3s\n",
      "[19:14:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.3s\n",
      "[19:15:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.2s\n",
      "[19:15:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  15.2s\n",
      "[19:15:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  19.9s\n",
      "[19:15:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  20.5s\n",
      "[19:16:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  20.7s\n",
      "[19:16:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  21.8s\n",
      "[19:17:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  21.3s\n",
      "[19:17:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.4s\n",
      "[19:17:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.6s\n",
      "[19:17:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.7s\n",
      "[19:17:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.6s\n",
      "[19:18:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  10.7s\n",
      "[19:18:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  15.5s\n",
      "[19:18:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  12.8s\n",
      "[19:18:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  13.1s\n",
      "[19:18:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  12.1s\n",
      "[19:19:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  11.8s\n",
      "[19:19:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  16.9s\n",
      "[19:19:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  17.4s\n",
      "[19:19:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  17.3s\n",
      "[19:20:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  16.8s\n",
      "[19:20:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  18.1s\n",
      "[19:20:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   8.7s\n",
      "[19:20:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.2s\n",
      "[19:21:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.3s\n",
      "[19:21:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.3s\n",
      "[19:21:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=   9.5s\n",
      "[19:21:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  13.5s\n",
      "[19:21:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  14.5s\n",
      "[19:22:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  15.9s\n",
      "[19:22:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  15.9s\n",
      "[19:22:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  15.0s\n",
      "[19:22:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  18.5s\n",
      "[19:23:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  19.7s\n",
      "[19:23:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  20.2s\n",
      "[19:23:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  20.1s\n",
      "[19:24:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  20.7s\n",
      "[19:24:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=   9.9s\n",
      "[19:24:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.8s\n",
      "[19:24:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.4s\n",
      "[19:25:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.2s\n",
      "[19:25:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  10.6s\n",
      "[19:25:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.8s\n",
      "[19:25:36] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.5s\n",
      "[19:25:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.7s\n",
      "[19:26:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  16.1s\n",
      "[19:26:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  15.5s\n",
      "[19:26:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  20.2s\n",
      "[19:26:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  19.4s\n",
      "[19:27:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  20.1s\n",
      "[19:27:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  18.5s\n",
      "[19:27:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  19.5s\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid_action = [\n",
    "     {\n",
    "        'model': [svm.SVC(random_state=1)],\n",
    "        'dim_reducer': [PCA()], \n",
    "        'dim_reducer__n_components': [0.8, 0.85, 0.9, 0.95],\n",
    "        'model__C': [0.001, 0.01, 0.1, 1]},\n",
    "     \n",
    "     {\n",
    "        'model': [RandomForestClassifier(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(2, 17, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBClassifier(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0, 0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid_action = GridSearchCV(estimator, param_grid_action, cv = 5, verbose = 2)\n",
    "fitted_grid_action = grid_action.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dim_reducer</th>\n",
       "      <th>param_dim_reducer__n_components</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>...</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.455999</td>\n",
       "      <td>0.031822</td>\n",
       "      <td>2.045810</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.95</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.775779</td>\n",
       "      <td>0.795763</td>\n",
       "      <td>0.789768</td>\n",
       "      <td>0.739408</td>\n",
       "      <td>0.812550</td>\n",
       "      <td>0.782654</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>13.017176</td>\n",
       "      <td>1.312634</td>\n",
       "      <td>0.037486</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.770184</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>0.736611</td>\n",
       "      <td>0.811751</td>\n",
       "      <td>0.774580</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>20.770916</td>\n",
       "      <td>0.654539</td>\n",
       "      <td>0.049602</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.774580</td>\n",
       "      <td>0.777378</td>\n",
       "      <td>0.779376</td>\n",
       "      <td>0.731415</td>\n",
       "      <td>0.808553</td>\n",
       "      <td>0.774261</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>20.585251</td>\n",
       "      <td>0.226014</td>\n",
       "      <td>0.047692</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.772582</td>\n",
       "      <td>0.779776</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.737410</td>\n",
       "      <td>0.797762</td>\n",
       "      <td>0.773621</td>\n",
       "      <td>0.019906</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>25.132153</td>\n",
       "      <td>2.251778</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.772982</td>\n",
       "      <td>0.782174</td>\n",
       "      <td>0.777378</td>\n",
       "      <td>0.735412</td>\n",
       "      <td>0.797362</td>\n",
       "      <td>0.773062</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.883615</td>\n",
       "      <td>0.086223</td>\n",
       "      <td>0.042993</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.554357</td>\n",
       "      <td>0.602318</td>\n",
       "      <td>0.598321</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>0.599520</td>\n",
       "      <td>0.573381</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.026851</td>\n",
       "      <td>0.102224</td>\n",
       "      <td>3.036139</td>\n",
       "      <td>0.074396</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.046372</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>3.211035</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.95</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.426208</td>\n",
       "      <td>0.068349</td>\n",
       "      <td>3.032837</td>\n",
       "      <td>0.123106</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.85</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.256927</td>\n",
       "      <td>0.082737</td>\n",
       "      <td>2.805307</td>\n",
       "      <td>0.032524</td>\n",
       "      <td>PCA(n_components=0.95)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>SVC(C=1, random_state=1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'dim_reducer': PCA(n_components=0.95), 'dim_r...</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.414468</td>\n",
       "      <td>0.369305</td>\n",
       "      <td>0.404476</td>\n",
       "      <td>0.405436</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "15        5.455999      0.031822         2.045810        0.028411   \n",
       "108      13.017176      1.312634         0.037486        0.002990   \n",
       "106      20.770916      0.654539         0.049602        0.001100   \n",
       "103      20.585251      0.226014         0.047692        0.001775   \n",
       "94       25.132153      2.251778         0.065572        0.009444   \n",
       "..             ...           ...              ...             ...   \n",
       "18        5.883615      0.086223         0.042993        0.001623   \n",
       "8         9.026851      0.102224         3.036139        0.074396   \n",
       "12        9.046372      0.208015         3.211035        0.041036   \n",
       "4         8.426208      0.068349         3.032837        0.123106   \n",
       "0         9.256927      0.082737         2.805307        0.032524   \n",
       "\n",
       "          param_dim_reducer param_dim_reducer__n_components  \\\n",
       "15   PCA(n_components=0.95)                            0.95   \n",
       "108                     NaN                             NaN   \n",
       "106                     NaN                             NaN   \n",
       "103                     NaN                             NaN   \n",
       "94                      NaN                             NaN   \n",
       "..                      ...                             ...   \n",
       "18                      NaN                             NaN   \n",
       "8    PCA(n_components=0.95)                             0.9   \n",
       "12   PCA(n_components=0.95)                            0.95   \n",
       "4    PCA(n_components=0.95)                            0.85   \n",
       "0    PCA(n_components=0.95)                             0.8   \n",
       "\n",
       "                                           param_model param_model__C  \\\n",
       "15                            SVC(C=1, random_state=1)              1   \n",
       "108  XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "106  XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "103  XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "94   XGBClassifier(base_score=None, booster=None, c...            NaN   \n",
       "..                                                 ...            ...   \n",
       "18   RandomForestClassifier(n_jobs=-1, oob_score=Tr...            NaN   \n",
       "8                             SVC(C=1, random_state=1)          0.001   \n",
       "12                            SVC(C=1, random_state=1)          0.001   \n",
       "4                             SVC(C=1, random_state=1)          0.001   \n",
       "0                             SVC(C=1, random_state=1)          0.001   \n",
       "\n",
       "    param_model__max_depth param_model__max_features  ... param_model__gamma  \\\n",
       "15                     NaN                       NaN  ...                NaN   \n",
       "108                      3                       NaN  ...                0.1   \n",
       "106                      4                       NaN  ...                  0   \n",
       "103                      4                       NaN  ...                0.9   \n",
       "94                       4                       NaN  ...                  0   \n",
       "..                     ...                       ...  ...                ...   \n",
       "18                       2                      None  ...                NaN   \n",
       "8                      NaN                       NaN  ...                NaN   \n",
       "12                     NaN                       NaN  ...                NaN   \n",
       "4                      NaN                       NaN  ...                NaN   \n",
       "0                      NaN                       NaN  ...                NaN   \n",
       "\n",
       "                                                params split0_test_score  \\\n",
       "15   {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.775779   \n",
       "108  {'model': XGBClassifier(base_score=None, boost...          0.777778   \n",
       "106  {'model': XGBClassifier(base_score=None, boost...          0.774580   \n",
       "103  {'model': XGBClassifier(base_score=None, boost...          0.772582   \n",
       "94   {'model': XGBClassifier(base_score=None, boost...          0.772982   \n",
       "..                                                 ...               ...   \n",
       "18   {'model': RandomForestClassifier(n_jobs=-1, oo...          0.554357   \n",
       "8    {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "12   {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "4    {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "0    {'dim_reducer': PCA(n_components=0.95), 'dim_r...          0.408074   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "15           0.795763           0.789768           0.739408   \n",
       "108          0.770184           0.776579           0.736611   \n",
       "106          0.777378           0.779376           0.731415   \n",
       "103          0.779776           0.780576           0.737410   \n",
       "94           0.782174           0.777378           0.735412   \n",
       "..                ...                ...                ...   \n",
       "18           0.602318           0.598321           0.512390   \n",
       "8            0.430855           0.414468           0.369305   \n",
       "12           0.430855           0.414468           0.369305   \n",
       "4            0.430855           0.414468           0.369305   \n",
       "0            0.430855           0.414468           0.369305   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "15            0.812550         0.782654        0.024632                1  \n",
       "108           0.811751         0.774580        0.023903                2  \n",
       "106           0.808553         0.774261        0.024689                3  \n",
       "103           0.797762         0.773621        0.019906                4  \n",
       "94            0.797362         0.773062        0.020541                5  \n",
       "..                 ...              ...             ...              ...  \n",
       "18            0.599520         0.573381        0.035283              112  \n",
       "8             0.404476         0.405436        0.020204              113  \n",
       "12            0.404476         0.405436        0.020204              113  \n",
       "4             0.404476         0.405436        0.020204              113  \n",
       "0             0.404476         0.405436        0.020204              113  \n",
       "\n",
       "[116 rows x 22 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results_action = pd.DataFrame(fitted_grid_action.cv_results_)\n",
    "grid_search_results_action.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='/var/folders/t5/kc4tlr5n2yn5jkkh1t9rk9500000gn/T/tmpieqziszu',\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['start_x', 'start_y',\n",
       "                                                   'time_seconds',\n",
       "                                                   'n-1_x_distance',\n",
       "                                                   'n-1_y_distance',\n",
       "                                                   'n-1_start_x', 'n-1_start_y',\n",
       "                                                   'n-1_end_x', 'n-1_end_y',\n",
       "                                                   'n-1_offensive_value',\n",
       "                                                   'n-1_defensive_valu...\n",
       "                                                   'team_id', 'end_x', 'end_y',\n",
       "                                                   'type_id', 'result_id',\n",
       "                                                   'bodypart_id', 'action_id',\n",
       "                                                   'type_name', 'result_name',\n",
       "                                                   'bodypart_name',\n",
       "                                                   'offensive_value',\n",
       "                                                   'defensive_value',\n",
       "                                                   'vaep_value', 'x_dif',\n",
       "                                                   'y_dif', 'n-1_same_player',\n",
       "                                                   'n-2_same_player',\n",
       "                                                   'n-3_same_player',\n",
       "                                                   'n-4_same_player',\n",
       "                                                   'n-5_same_player'])])),\n",
       "                ('dim_reducer', PCA(n_components=0.95)),\n",
       "                ('model', SVC(C=1, random_state=1))])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_action.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_grid_action.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM NEXT ACTION MODEL\n",
    "\n",
    "This was orignally my candidate for the final model for next action - however when performing the model evaluation you can see below, I saw that the AUC-ROC curve was not ideal as the false positive rate increases quicker than true positives.\n",
    "\n",
    "This meant I moved to the second best model in the gridsearch which was an xGBoost classifier - when checking the accuracy scores, they were higher on the second model, after a few small tweaks, and decided to go forward using the xgb model - details can be found in the final section. However the ROC-AUC curve did not show much improvement even after using the new model. \n",
    "\n",
    "Therefore it may be that the current set of next action models will need further tuning to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Support Vector Machine ***\n",
      "SVM Train Score:  0.8457234212629896\n",
      "SVM Test Score:  0.7791626717801214\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** Support Vector Machine ***')\n",
    "pipe_svm = make_pipeline(ct, PCA(n_components=0.95), svm.SVC(C=1, probability=True))\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "print('SVM Train Score: ', pipe_svm.score(X_train, y_train))\n",
    "print('SVM Test Score: ', pipe_svm.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915067856814977"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pipe_svm.predict_proba(X_test), multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_svm.predict(X_test)\n",
    "y_proba = pipe_svm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     dribble       0.80      0.88      0.83      8378\n",
      "       other       0.64      0.62      0.63      4117\n",
      "        pass       0.83      0.76      0.79      9408\n",
      "\n",
      "    accuracy                           0.78     21903\n",
      "   macro avg       0.75      0.75      0.75     21903\n",
      "weighted avg       0.78      0.78      0.78     21903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(pipe_svm, X_test, y_test, cmap='Blues', normalize='true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Between the classification report and confusion matrix, we can see that we get good performance for dribble classification, but not as good for passes or other. \n",
    "- The other category was expected to not perform as well due to the class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_bin_test = label_binarize(y_test, classes = ['pass','dribble','other'])\n",
    "n_classes = y_bin_test.shape[1]\n",
    "\n",
    "y_score = pipe_svm.decision_function(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "lw = 2\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Scores\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the curves show a larger increase in the false positive rate, than would be ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Team - End Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'end_pitch_zone')\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-end')\n",
    "\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "\n",
    "# define column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   6.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=80; total time=   3.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=100; total time=   4.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   4.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=120; total time=   5.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=None, model__n_estimators=140; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=80; total time=   1.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=100; total time=   1.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=120; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=2, model__max_features=auto, model__n_estimators=140; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   5.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=80; total time=   6.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=100; total time=   7.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   8.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=120; total time=   9.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=   9.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=None, model__n_estimators=140; total time=  10.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=80; total time=   1.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=100; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=120; total time=   1.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=4, model__max_features=auto, model__n_estimators=140; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   7.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=80; total time=   8.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  11.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  11.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=100; total time=  11.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  12.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=120; total time=  13.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  15.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  15.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  14.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  14.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=None, model__n_estimators=140; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=80; total time=   1.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=100; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=120; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=6, model__max_features=auto, model__n_estimators=140; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=80; total time=  10.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  12.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  13.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=100; total time=  14.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  15.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=120; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  18.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  19.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  19.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=None, model__n_estimators=140; total time=  19.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=80; total time=   1.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=100; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=120; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=8, model__max_features=auto, model__n_estimators=140; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  12.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=80; total time=  13.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  15.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=100; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  18.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  20.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=120; total time=  19.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=None, model__n_estimators=140; total time=  21.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=80; total time=   2.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=100; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=120; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=10, model__max_features=auto, model__n_estimators=140; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  13.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=80; total time=  14.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  16.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  18.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=100; total time=  17.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  20.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=120; total time=  21.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  24.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  26.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=None, model__n_estimators=140; total time=  27.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=100; total time=   2.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=12, model__max_features=auto, model__n_estimators=140; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  14.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  15.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  16.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  15.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=80; total time=  15.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  18.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=100; total time=  19.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  22.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  23.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  24.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=120; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  27.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  28.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  26.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  25.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=None, model__n_estimators=140; total time=  25.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=100; total time=   2.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   2.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=120; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=14, model__max_features=auto, model__n_estimators=140; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  15.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  16.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  16.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  16.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=80; total time=  17.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  20.6s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  20.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  23.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  22.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=100; total time=  22.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  23.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  24.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  26.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  26.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=120; total time=  28.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  30.9s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  31.0s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  30.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  28.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=None, model__n_estimators=140; total time=  28.2s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.3s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=80; total time=   2.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.8s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=100; total time=   2.7s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=120; total time=   3.1s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.4s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.5s\n",
      "[CV] END model=RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1), model__max_depth=16, model__max_features=auto, model__n_estimators=140; total time=   3.4s\n",
      "[22:31:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  19.3s\n",
      "[22:31:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  20.1s\n",
      "[22:31:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  20.4s\n",
      "[22:32:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  20.8s\n",
      "[22:32:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=2; total time=  21.0s\n",
      "[22:32:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.0s\n",
      "[22:33:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.0s\n",
      "[22:33:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.5s\n",
      "[22:34:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  32.6s\n",
      "[22:34:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=3; total time=  29.8s\n",
      "[22:35:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  34.9s\n",
      "[22:35:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  35.2s\n",
      "[22:36:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  34.8s\n",
      "[22:37:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  35.5s\n",
      "[22:37:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[22:38:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  16.9s\n",
      "[22:38:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.5s\n",
      "[22:38:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.1s\n",
      "[22:39:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.1s\n",
      "[22:39:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=2; total time=  17.7s\n",
      "[22:39:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  25.7s\n",
      "[22:40:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.8s\n",
      "[22:40:36] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.5s\n",
      "[22:41:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.9s\n",
      "[22:41:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=3; total time=  26.9s\n",
      "[22:41:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  35.7s\n",
      "[22:42:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.2s\n",
      "[22:43:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.1s\n",
      "[22:43:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.6s\n",
      "[22:44:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.1, model__max_depth=4; total time=  37.7s\n",
      "[22:45:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.1s\n",
      "[22:45:20] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.7s\n",
      "[22:45:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.4s\n",
      "[22:45:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.4s\n",
      "[22:46:16] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=2; total time=  18.4s\n",
      "[22:46:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  26.5s\n",
      "[22:47:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  27.9s\n",
      "[22:47:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  27.8s\n",
      "[22:47:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  28.1s\n",
      "[22:48:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=3; total time=  28.0s\n",
      "[22:48:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  36.2s\n",
      "[22:49:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  37.9s\n",
      "[22:50:07] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  37.6s\n",
      "[22:50:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  38.0s\n",
      "[22:51:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.5, model__max_depth=4; total time=  37.9s\n",
      "[22:52:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  17.7s\n",
      "[22:52:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  20.2s\n",
      "[22:52:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  18.5s\n",
      "[22:52:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  18.7s\n",
      "[22:53:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=2; total time=  18.6s\n",
      "[22:53:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  27.5s\n",
      "[22:54:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  29.1s\n",
      "[22:54:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  28.3s\n",
      "[22:54:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  28.4s\n",
      "[22:55:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=3; total time=  28.8s\n",
      "[22:55:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  36.9s\n",
      "[22:56:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.3s\n",
      "[22:57:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.0s\n",
      "[22:57:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.3s\n",
      "[22:58:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.01, model__gamma=0.9, model__max_depth=4; total time=  38.3s\n",
      "[22:59:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  18.1s\n",
      "[22:59:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  18.5s\n",
      "[22:59:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  17.7s\n",
      "[23:00:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  17.2s\n",
      "[23:00:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=2; total time=  17.1s\n",
      "[23:00:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  25.2s\n",
      "[23:01:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  27.9s\n",
      "[23:01:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  28.2s\n",
      "[23:01:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  27.9s\n",
      "[23:02:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=3; total time=  27.6s\n",
      "[23:02:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[23:03:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.3s\n",
      "[23:04:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.3s\n",
      "[23:04:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.5s\n",
      "[23:05:13] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[23:05:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  16.8s\n",
      "[23:06:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.3s\n",
      "[23:06:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.5s\n",
      "[23:06:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.3s\n",
      "[23:06:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=2; total time=  17.3s\n",
      "[23:07:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  24.8s\n",
      "[23:07:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.8s\n",
      "[23:08:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.6s\n",
      "[23:08:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.6s\n",
      "[23:08:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=3; total time=  25.5s\n",
      "[23:09:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  33.4s\n",
      "[23:09:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  34.4s\n",
      "[23:10:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  34.8s\n",
      "[23:11:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  35.1s\n",
      "[23:11:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.1, model__max_depth=4; total time=  34.8s\n",
      "[23:12:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  16.4s\n",
      "[23:12:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  17.0s\n",
      "[23:12:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  16.8s\n",
      "[23:13:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  17.0s\n",
      "[23:13:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=2; total time=  17.1s\n",
      "[23:13:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  24.9s\n",
      "[23:14:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.8s\n",
      "[23:14:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.9s\n",
      "[23:14:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.9s\n",
      "[23:15:22] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=3; total time=  25.8s\n",
      "[23:15:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  33.8s\n",
      "[23:16:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  35.3s\n",
      "[23:16:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  34.5s\n",
      "[23:17:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  34.3s\n",
      "[23:18:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.5, model__max_depth=4; total time=  34.0s\n",
      "[23:18:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  15.9s\n",
      "[23:18:55] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.5s\n",
      "[23:19:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.5s\n",
      "[23:19:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.6s\n",
      "[23:19:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=2; total time=  16.5s\n",
      "[23:20:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.0s\n",
      "[23:20:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.5s\n",
      "[23:20:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.9s\n",
      "[23:21:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  26.0s\n",
      "[23:21:44] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=3; total time=  25.8s\n",
      "[23:22:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  33.6s\n",
      "[23:22:43] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  34.8s\n",
      "[23:23:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  36.0s\n",
      "[23:23:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  34.1s\n",
      "[23:24:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.1, model__gamma=0.9, model__max_depth=4; total time=  33.9s\n",
      "[23:25:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  15.8s\n",
      "[23:25:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.6s\n",
      "[23:25:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.7s\n",
      "[23:25:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.7s\n",
      "[23:26:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=2; total time=  16.7s\n",
      "[23:26:25] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  24.5s\n",
      "[23:26:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.8s\n",
      "[23:27:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.5s\n",
      "[23:27:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.6s\n",
      "[23:28:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=3; total time=  25.8s\n",
      "[23:28:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  33.8s\n",
      "[23:29:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  35.2s\n",
      "[23:29:41] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  35.6s\n",
      "[23:30:16] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  35.4s\n",
      "[23:30:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0, model__max_depth=4; total time=  37.4s\n",
      "[23:31:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  18.6s\n",
      "[23:31:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  19.8s\n",
      "[23:32:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  20.0s\n",
      "[23:32:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  20.3s\n",
      "[23:32:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=2; total time=  19.9s\n",
      "[23:33:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  29.4s\n",
      "[23:33:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  30.2s\n",
      "[23:34:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  30.4s\n",
      "[23:34:38] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  31.3s\n",
      "[23:35:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=3; total time=  30.9s\n",
      "[23:35:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  40.2s\n",
      "[23:36:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  41.7s\n",
      "[23:37:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  37.9s\n",
      "[23:37:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  36.8s\n",
      "[23:38:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.1, model__max_depth=4; total time=  36.9s\n",
      "[23:38:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  17.5s\n",
      "[23:39:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.2s\n",
      "[23:39:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.3s\n",
      "[23:39:48] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.1s\n",
      "[23:40:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=2; total time=  18.2s\n",
      "[23:40:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  26.2s\n",
      "[23:40:50] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.1s\n",
      "[23:41:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.3s\n",
      "[23:41:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.3s\n",
      "[23:42:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=3; total time=  27.2s\n",
      "[23:42:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  35.3s\n",
      "[23:43:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.5s\n",
      "[23:43:51] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.3s\n",
      "[23:44:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.8s\n",
      "[23:45:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.5, model__max_depth=4; total time=  36.4s\n",
      "[23:45:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  16.8s\n",
      "[23:45:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.3s\n",
      "[23:46:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.3s\n",
      "[23:46:32] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.2s\n",
      "[23:46:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=2; total time=  17.2s\n",
      "[23:47:06] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  25.1s\n",
      "[23:47:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.3s\n",
      "[23:47:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.7s\n",
      "[23:48:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.6s\n",
      "[23:48:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=3; total time=  27.3s\n",
      "[23:49:21] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  35.6s\n",
      "[23:49:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  37.1s\n",
      "[23:50:34] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  37.7s\n",
      "[23:51:12] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  37.8s\n",
      "[23:51:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), model__eta=0.3, model__gamma=0.9, model__max_depth=4; total time=  38.2s\n",
      "[23:52:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid\n",
    "param_grid_end = [\n",
    "   \n",
    "     {\n",
    "        'model': [RandomForestClassifier(random_state=1, oob_score=True, n_jobs=-1)],\n",
    "        'model__max_depth': list(range(2, 17, 2)),\n",
    "        'model__max_features': [None, 'auto'],\n",
    "        'model__n_estimators': list(range(80, 150, 20))}, \n",
    "    \n",
    "     {\n",
    "        'model': [xgb.XGBClassifier(random_state=1)],\n",
    "        'model__max_depth': list(range(2, 5, 1)),\n",
    "        'model__gamma': [0, 0.1, 0.5, 0.9],\n",
    "        'model__eta': [0.01, 0.1, 0.3]\n",
    "        },\n",
    "\n",
    "]\n",
    "\n",
    "# Instantiate a gridsearch\n",
    "grid_end = GridSearchCV(estimator, param_grid_end, cv = 5, verbose = 2)\n",
    "fitted_grid_end = grid_end.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__max_features</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>30.424726</td>\n",
       "      <td>0.650538</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.683054</td>\n",
       "      <td>0.684253</td>\n",
       "      <td>0.668665</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>0.693046</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>35.460561</td>\n",
       "      <td>1.165587</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.692246</td>\n",
       "      <td>0.685052</td>\n",
       "      <td>0.661871</td>\n",
       "      <td>0.667466</td>\n",
       "      <td>0.695444</td>\n",
       "      <td>0.680416</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>26.958471</td>\n",
       "      <td>0.399852</td>\n",
       "      <td>0.031620</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.681055</td>\n",
       "      <td>0.680256</td>\n",
       "      <td>0.668665</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>0.694644</td>\n",
       "      <td>0.679616</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>19.683138</td>\n",
       "      <td>0.586587</td>\n",
       "      <td>0.032026</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.677458</td>\n",
       "      <td>0.684652</td>\n",
       "      <td>0.667066</td>\n",
       "      <td>0.673062</td>\n",
       "      <td>0.692646</td>\n",
       "      <td>0.678977</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17.141578</td>\n",
       "      <td>0.201692</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'model': XGBClassifier(base_score=None, boost...</td>\n",
       "      <td>0.682254</td>\n",
       "      <td>0.687050</td>\n",
       "      <td>0.664668</td>\n",
       "      <td>0.674660</td>\n",
       "      <td>0.685851</td>\n",
       "      <td>0.678897</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.209941</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>0.032672</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.397282</td>\n",
       "      <td>0.417666</td>\n",
       "      <td>0.354516</td>\n",
       "      <td>0.367306</td>\n",
       "      <td>0.378497</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.022287</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.213472</td>\n",
       "      <td>1.035617</td>\n",
       "      <td>0.034561</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.325739</td>\n",
       "      <td>0.365308</td>\n",
       "      <td>0.271783</td>\n",
       "      <td>0.306155</td>\n",
       "      <td>0.308953</td>\n",
       "      <td>0.315588</td>\n",
       "      <td>0.030420</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.338059</td>\n",
       "      <td>0.064258</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.324940</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.307754</td>\n",
       "      <td>0.314788</td>\n",
       "      <td>0.028941</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.997581</td>\n",
       "      <td>0.098873</td>\n",
       "      <td>0.038319</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.325739</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.272582</td>\n",
       "      <td>0.305356</td>\n",
       "      <td>0.306555</td>\n",
       "      <td>0.314468</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.683861</td>\n",
       "      <td>0.114062</td>\n",
       "      <td>0.041629</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, oob_score=Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': RandomForestClassifier(n_jobs=-1, oo...</td>\n",
       "      <td>0.326139</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.271383</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.314149</td>\n",
       "      <td>0.029583</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "92      30.424726      0.650538         0.033494        0.001955   \n",
       "90      35.460561      1.165587         0.029699        0.001232   \n",
       "95      26.958471      0.399852         0.031620        0.001454   \n",
       "91      19.683138      0.586587         0.032026        0.001173   \n",
       "97      17.141578      0.201692         0.027977        0.001288   \n",
       "..            ...           ...              ...             ...   \n",
       "4        1.209941      0.013858         0.032672        0.000936   \n",
       "0        4.213472      1.035617         0.034561        0.003887   \n",
       "1        4.338059      0.064258         0.035688        0.000977   \n",
       "2        4.997581      0.098873         0.038319        0.001049   \n",
       "3        5.683861      0.114062         0.041629        0.001129   \n",
       "\n",
       "                                          param_model param_model__max_depth  \\\n",
       "92  XGBClassifier(base_score=None, booster=None, c...                      3   \n",
       "90  XGBClassifier(base_score=None, booster=None, c...                      4   \n",
       "95  XGBClassifier(base_score=None, booster=None, c...                      3   \n",
       "91  XGBClassifier(base_score=None, booster=None, c...                      2   \n",
       "97  XGBClassifier(base_score=None, booster=None, c...                      2   \n",
       "..                                                ...                    ...   \n",
       "4   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "0   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "1   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "2   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "3   RandomForestClassifier(n_jobs=-1, oob_score=Tr...                      2   \n",
       "\n",
       "   param_model__max_features param_model__n_estimators param_model__eta  \\\n",
       "92                       NaN                       NaN              0.3   \n",
       "90                       NaN                       NaN              0.3   \n",
       "95                       NaN                       NaN              0.3   \n",
       "91                       NaN                       NaN              0.3   \n",
       "97                       NaN                       NaN              0.3   \n",
       "..                       ...                       ...              ...   \n",
       "4                       auto                        80              NaN   \n",
       "0                       None                        80              NaN   \n",
       "1                       None                       100              NaN   \n",
       "2                       None                       120              NaN   \n",
       "3                       None                       140              NaN   \n",
       "\n",
       "   param_model__gamma                                             params  \\\n",
       "92                0.1  {'model': XGBClassifier(base_score=None, boost...   \n",
       "90                  0  {'model': XGBClassifier(base_score=None, boost...   \n",
       "95                0.5  {'model': XGBClassifier(base_score=None, boost...   \n",
       "91                0.1  {'model': XGBClassifier(base_score=None, boost...   \n",
       "97                0.9  {'model': XGBClassifier(base_score=None, boost...   \n",
       "..                ...                                                ...   \n",
       "4                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "0                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "1                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "2                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "3                 NaN  {'model': RandomForestClassifier(n_jobs=-1, oo...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "92           0.683054           0.684253           0.668665   \n",
       "90           0.692246           0.685052           0.661871   \n",
       "95           0.681055           0.680256           0.668665   \n",
       "91           0.677458           0.684652           0.667066   \n",
       "97           0.682254           0.687050           0.664668   \n",
       "..                ...                ...                ...   \n",
       "4            0.397282           0.417666           0.354516   \n",
       "0            0.325739           0.365308           0.271783   \n",
       "1            0.324940           0.362110           0.273381   \n",
       "2            0.325739           0.362110           0.272582   \n",
       "3            0.326139           0.361711           0.271383   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "92           0.673461           0.693046         0.680496        0.008574   \n",
       "90           0.667466           0.695444         0.680416        0.013408   \n",
       "95           0.673461           0.694644         0.679616        0.008788   \n",
       "91           0.673062           0.692646         0.678977        0.008924   \n",
       "97           0.674660           0.685851         0.678897        0.008325   \n",
       "..                ...                ...              ...             ...   \n",
       "4            0.367306           0.378497         0.383054        0.022287   \n",
       "0            0.306155           0.308953         0.315588        0.030420   \n",
       "1            0.305755           0.307754         0.314788        0.028941   \n",
       "2            0.305356           0.306555         0.314468        0.029315   \n",
       "3            0.305755           0.305755         0.314149        0.029583   \n",
       "\n",
       "    rank_test_score  \n",
       "92                1  \n",
       "90                2  \n",
       "95                3  \n",
       "91                4  \n",
       "97                5  \n",
       "..              ...  \n",
       "4                96  \n",
       "0                97  \n",
       "1                98  \n",
       "2                99  \n",
       "3               100  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results_end = pd.DataFrame(fitted_grid_end.cv_results_)\n",
    "grid_search_results_end.sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final models were chosen based on their accuracy score or R2 for regression models against the test set. So the models need as a baseline to perform well at predicting the output of the team they were trained on. Further the models need to show a level of generalisation through regularisation. \n",
    "\n",
    "The hyper parameters were tweaked to reduce the training data set scores, while improving or only very minimally decreasing test scores.\n",
    "\n",
    "For the classification models further analysis was done to validate their ability to predict a class as seen in the Next Action example above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='finalvaep'></a>\n",
    "### FINAL VAEP MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'vaep_value')\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-vaep')\n",
    "\n",
    "# define column transformed for pipeline\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer for GridSearchCV\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Regressor - Depth 8 ***\n",
      "XGB Regressor Train Score:  0.8406537986332749\n",
      "XGB Regressor Test Score:  0.7623045325905606\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Regressor - Depth 8 ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=8, gamma=0.01, reg_alpha=1.1, eta=0.1))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type_name_shot</td>\n",
       "      <td>0.457126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_name_success</td>\n",
       "      <td>0.134707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type_name_cross</td>\n",
       "      <td>0.043451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_name_shot_freekick</td>\n",
       "      <td>0.023027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>end_x</td>\n",
       "      <td>0.017588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Variable  Importance\n",
       "0           type_name_shot    0.457126\n",
       "1      result_name_success    0.134707\n",
       "2          type_name_cross    0.043451\n",
       "3  type_name_shot_freekick    0.023027\n",
       "4                    end_x    0.017588"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Explainability**\n",
    "\n",
    "For predicting VAEP, we can see the 5 most important features are, whether the action was a shot, whether it was successful or whether it was a longer ball delivery such as a cross or freekick and finally the end location of the ball as measured by the x coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL xT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_xt_train_df, modeling_xt_test_df, 'xT_value')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-xt')\n",
    "\n",
    "# pipeline column transformer\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define gridsearch column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Regressor - Depth 5 Optimised ***\n",
      "XGB Regressor Train Score:  0.9265065158190492\n",
      "XGB Regressor Test Score:  0.8085949010492468\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Regressor - Depth 5 Optimised ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBRegressor(max_depth=5, reg_lambda=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Regressor Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Regressor Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type_name_cross</td>\n",
       "      <td>0.230911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>end_pitch_zone_zone_8</td>\n",
       "      <td>0.100993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start_pitch_zone_zone_8</td>\n",
       "      <td>0.063345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x_dif</td>\n",
       "      <td>0.046887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>end_x</td>\n",
       "      <td>0.044581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Variable  Importance\n",
       "0          type_name_cross    0.230911\n",
       "1    end_pitch_zone_zone_8    0.100993\n",
       "2  start_pitch_zone_zone_8    0.063345\n",
       "3                    x_dif    0.046887\n",
       "4                    end_x    0.044581"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Explainability**\n",
    "\n",
    "For xT we can see that start and ending in zone * are important features, but not as important as action type being a cross - maybe due to crosses being longer ball delivery option moving the ball into zone 8. Therefore the top 3 features making sense together. \n",
    "\n",
    "To further back this view up we see that x_dif is also in the top 5 - meaning that longer balls increase the value of xT likely due to the higher likelyhood for the ball to end in a dangerous zone of the pitch, especially as end_x is also in the top 5 for this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL NEXT ACTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'type_name_encoded')\n",
    "\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-action')\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "# define column transformer\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Classifier ***\n",
      "[21:23:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Train Score:  0.872501998401279\n",
      "XGB Test Score:  0.8036798612062275\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Classifier ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBClassifier(max_depth=3, eta=0.3, gamma=0.01))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214789707522385"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pipe.predict_proba(X_test), multi_class='ovo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can already see a better score than in the SVM model - on top of the better accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     dribble       0.80      0.91      0.85      8378\n",
      "       other       0.74      0.63      0.69      4117\n",
      "        pass       0.83      0.79      0.81      9408\n",
      "\n",
      "    accuracy                           0.80     21903\n",
      "   macro avg       0.79      0.78      0.78     21903\n",
      "weighted avg       0.80      0.80      0.80     21903\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', normalize='true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the classification report and confusion matrix, we also see better performance in predicting the 3 classes. However we again see a similar pattern where dribbles have a far greater performance than the other 2 categories. \n",
    "\n",
    "This model will likely need further iteration to refine and improve the outcomes. Either through tuning or up/down sampling the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_bin_test = label_binarize(y_test, classes = ['pass','dribble','other'])\n",
    "n_classes = y_bin_test.shape[1]\n",
    "\n",
    "y_score = pipe.predict_proba(X_test)\n",
    "# y_score = pipe_svm.predict_proba(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "lw = 2\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"AUC-ROC Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with the SVM model again we see that the curves are not showing ideal performance and the rate of false positives is too high - which further backs the view that this model will need further research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-1_type_name_encoded_dribble</td>\n",
       "      <td>0.199941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-1_same_team_False</td>\n",
       "      <td>0.150945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-1_type_name_encoded_pass</td>\n",
       "      <td>0.043632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-1_result_name_success</td>\n",
       "      <td>0.040079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-2_type_name_encoded_dribble</td>\n",
       "      <td>0.030164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Variable  Importance\n",
       "0  n-1_type_name_encoded_dribble    0.199941\n",
       "1            n-1_same_team_False    0.150945\n",
       "2     n-1_type_name_encoded_pass    0.043632\n",
       "3        n-1_result_name_success    0.040079\n",
       "4  n-2_type_name_encoded_dribble    0.030164"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Explainability**\n",
    "\n",
    "The key determinants of the next action in this model - are the previous 2 actions. Especially if those were dribbles. Interestingly whether the previous action was made by the other team ranked highly in this model, perhaps suggesting that a pass or dribble follows a period of possesion by the other team(which is quite an expected outcome). \n",
    "\n",
    "We also see that prior action outcome was also importance alongside whether they were passes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL END ZONE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ppu.create_team_data('team_id',1475, modeling_train_df, modeling_test_df, 'end_pitch_zone')\n",
    "numeric_features, categorical_features, drop_features = ppu.set_ct_mode('team-end')\n",
    "\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    # ('passthrough', passthrough_features),\n",
    "    ('drop', drop_features))\n",
    "\n",
    "\n",
    "# define column transformer\n",
    "cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "num_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numeric_features),\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('drop', 'drop', drop_features)])\n",
    "\n",
    "estimator = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('dim_reducer', PCA()),\n",
    "                       ('model', LinearRegression())], memory=cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xGBoost Classifier ***\n",
      "[21:30:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Train Score:  0.8621902478017586\n",
      "XGB Test Score:  0.7228690133771629\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('*** xGBoost Classifier ***')\n",
    "pipe = make_pipeline(ct, xgb.XGBClassifier(max_depth=3, eta=0.3, gamma=0.01))\n",
    "pipe.fit(X_train, y_train)\n",
    "print('XGB Train Score: ', pipe.score(X_train, y_train))\n",
    "print('XGB Test Score: ', pipe.score(X_test, y_test))\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_end = pipe.predict(X_test)\n",
    "y_proba_end = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625525120169188"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_proba_end, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      zone_1       0.69      0.63      0.66      1589\n",
      "      zone_2       0.64      0.70      0.67      2231\n",
      "      zone_3       0.69      0.67      0.68      1730\n",
      "      zone_4       0.74      0.76      0.75      3383\n",
      "      zone_5       0.65      0.57      0.61      2486\n",
      "      zone_6       0.72      0.76      0.74      3441\n",
      "      zone_7       0.78      0.78      0.78      2293\n",
      "      zone_8       0.79      0.73      0.76      2213\n",
      "      zone_9       0.78      0.81      0.80      2537\n",
      "\n",
      "    accuracy                           0.72     21903\n",
      "   macro avg       0.72      0.71      0.72     21903\n",
      "weighted avg       0.72      0.72      0.72     21903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', normalize='true', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the classification report and the confusion matrix we see that performance varies between different end zones. Perhaps expected as we didnt have perfectly balanced end zones in the input data.\n",
    "- Zone 5 performing the worst. \n",
    "- We care about zones 7,8,9 the most as those are the high value zones, so we could focus on those - or recut the dataset to focus on those 3 zones vs the rest in a future iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_bin_test = label_binarize(y_test, classes = ['zone_1','zone_2','zone_3', 'zone_4', 'zone_5', 'zone_6', 'zone_7', 'zone_8', 'zone_9'])\n",
    "n_classes = y_bin_test.shape[1]\n",
    "\n",
    "y_score = pipe.predict_proba(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "lw = 2\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"blue\", \"orange\", \"red\",\"black\", \"gray\", \"yellow\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this model we have a nearly ideal ROC-AUC curve - Showing that we have good performance on getting true positives for all classes.\n",
    "\n",
    "- However based on the classification report and confusion matrix, the 2 validation methods don't tell a consistent story - and would like need to review how this model is built in a future iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>start_pitch_zone_zone_9</td>\n",
       "      <td>0.181271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>start_pitch_zone_zone_7</td>\n",
       "      <td>0.114634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start_pitch_zone_zone_1</td>\n",
       "      <td>0.111615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start_pitch_zone_zone_6</td>\n",
       "      <td>0.104527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>start_pitch_zone_zone_5</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Variable  Importance\n",
       "0  start_pitch_zone_zone_9    0.181271\n",
       "1  start_pitch_zone_zone_7    0.114634\n",
       "2  start_pitch_zone_zone_1    0.111615\n",
       "3  start_pitch_zone_zone_6    0.104527\n",
       "4  start_pitch_zone_zone_5    0.064072"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features \n",
    "    # + passthrough_features\n",
    "    + ct.named_transformers_['onehotencoder'].get_feature_names_out().tolist())\n",
    "# Put the variable names and their feature importances into a data frame\n",
    "importances_df = pd.DataFrame({'Variable': column_names,\n",
    "                               'Importance': pipe[1].feature_importances_})\n",
    "\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Explainability**\n",
    "\n",
    "For this model, explainability tells a very simple story - where the ball starts is the best indicator of where it will end up. \n",
    "\n",
    "The only interesting insight here is that zone 1 ranks so highly given it's not the most frequented area on the pitch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b230f2c3a454b9d31000333b2514d91645996906422c6e0b66023d65cd0ad59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
